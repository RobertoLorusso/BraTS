{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub1h-Y7DIpYf"
      },
      "source": [
        "## README â—\n",
        "\n",
        "Set a manual_seed for reproducibility.\n",
        "\n",
        "References:\n",
        "\n",
        "- See [Reproducibility](https://pytorch.org/docs/stable/notes/randomness.html)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwFJcAuef07T"
      },
      "source": [
        "## Environment setup ðŸ›\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45BU03HjgAgT",
        "outputId": "add018d1-6e46-46c7-839c-5a97eb10f619"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (1.0.0)\n",
            "Requirement already satisfied: monai in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from monai) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.9 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from monai) (2.1.2)\n",
            "Requirement already satisfied: filelock in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.9->monai) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.9->monai) (4.7.1)\n",
            "Requirement already satisfied: sympy in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.9->monai) (1.12)\n",
            "Requirement already satisfied: networkx in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.9->monai) (3.1)\n",
            "Requirement already satisfied: jinja2 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.9->monai) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.9->monai) (2023.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from jinja2->torch>=1.9->monai) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sympy->torch>=1.9->monai) (1.3.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement shutil (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for shutil\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: torchmetrics in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>1.20.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torchmetrics) (1.25.2)\n",
            "Requirement already satisfied: packaging>17.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torchmetrics) (23.1)\n",
            "Requirement already satisfied: torch>=1.8.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torchmetrics) (2.1.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torchmetrics) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (68.0.0)\n",
            "Requirement already satisfied: typing-extensions in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.7.1)\n",
            "Requirement already satisfied: filelock in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.8.1->torchmetrics) (3.12.2)\n",
            "Requirement already satisfied: sympy in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.8.1->torchmetrics) (2023.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Looking in links: https://data.dgl.ai/wheels/cu121/repo.html\n",
            "Requirement already satisfied: dgl in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dgl) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dgl) (1.11.2)\n",
            "Requirement already satisfied: networkx>=2.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dgl) (3.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dgl) (4.66.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from requests>=2.19.0->dgl) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from requests>=2.19.0->dgl) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from requests>=2.19.0->dgl) (2023.7.22)\n",
            "Looking in links: https://data.dgl.ai/wheels-test/repo.html\n",
            "Requirement already satisfied: dglgo in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (0.0.2)\n",
            "Requirement already satisfied: typer>=0.4.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dglgo) (0.9.0)\n",
            "Requirement already satisfied: isort>=5.10.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dglgo) (5.13.2)\n",
            "Requirement already satisfied: autopep8>=1.6.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dglgo) (2.0.4)\n",
            "Requirement already satisfied: numpydoc>=1.1.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dglgo) (1.6.0)\n",
            "Requirement already satisfied: pydantic>=1.9.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dglgo) (2.5.3)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.20 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dglgo) (0.18.5)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dglgo) (6.0.1)\n",
            "Requirement already satisfied: ogb>=1.3.3 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dglgo) (1.3.6)\n",
            "Requirement already satisfied: rdkit-pypi in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dglgo) (2022.9.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dglgo) (1.3.2)\n",
            "Requirement already satisfied: pycodestyle>=2.10.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from autopep8>=1.6.0->dglgo) (2.11.1)\n",
            "Requirement already satisfied: sphinx>=5 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from numpydoc>=1.1.0->dglgo) (7.2.6)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from numpydoc>=1.1.0->dglgo) (3.1.2)\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from numpydoc>=1.1.0->dglgo) (0.9.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from ogb>=1.3.3->dglgo) (2.1.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from ogb>=1.3.3->dglgo) (1.25.2)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from ogb>=1.3.3->dglgo) (4.66.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from ogb>=1.3.3->dglgo) (2.1.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from ogb>=1.3.3->dglgo) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from ogb>=1.3.3->dglgo) (2.0.4)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from ogb>=1.3.3->dglgo) (0.2.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from pydantic>=1.9.0->dglgo) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from pydantic>=1.9.0->dglgo) (2.14.6)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from pydantic>=1.9.0->dglgo) (4.7.1)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from ruamel.yaml>=0.17.20->dglgo) (0.2.8)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from scikit-learn>=0.20.0->dglgo) (1.11.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from scikit-learn>=0.20.0->dglgo) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from scikit-learn>=0.20.0->dglgo) (3.2.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from typer>=0.4.0->dglgo) (8.1.7)\n",
            "Requirement already satisfied: Pillow in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from rdkit-pypi->dglgo) (10.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.3)\n",
            "Requirement already satisfied: setuptools>=44 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (68.0.0)\n",
            "Requirement already satisfied: littleutils in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (0.2.2)\n",
            "Requirement already satisfied: requests in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2023.4)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.7)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.5)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.1.9)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.6)\n",
            "Requirement already satisfied: Pygments>=2.14 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.16.1)\n",
            "Requirement already satisfied: docutils<0.21,>=0.18.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (0.20.1)\n",
            "Requirement already satisfied: snowballstemmer>=2.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.9 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.14.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (0.7.13)\n",
            "Requirement already satisfied: imagesize>=1.3 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.4.1)\n",
            "Requirement already satisfied: packaging>=21.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (23.1)\n",
            "Requirement already satisfied: filelock in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.12.2)\n",
            "Requirement already satisfied: sympy in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (1.12)\n",
            "Requirement already satisfied: networkx in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.1)\n",
            "Requirement already satisfied: fsspec in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (2023.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sympy->torch>=1.6.0->ogb>=1.3.3->dglgo) (1.3.0)\n",
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "! pip install python-dotenv\n",
        "! pip install monai\n",
        "! pip install shutil\n",
        "! pip install mlflow --quiet\n",
        "! pip install pyngrok --quiet\n",
        "! pip install torchmetrics\n",
        "#! pip install dgl\n",
        "! pip install  dgl -f https://data.dgl.ai/wheels/cu121/repo.html\n",
        "! pip install  dglgo -f https://data.dgl.ai/wheels-test/repo.html\n",
        "\n",
        "\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "\n",
        "sys.path.append('/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/')\n",
        "\n",
        "from src.preprocess import evaluation\n",
        "from src.preprocess.image_processing import *\n",
        "from src.preprocess.nifti_io import *\n",
        "from src.preprocess.graphgen import *\n",
        "from src.preprocess.graph_io import *\n",
        "\n",
        "from mlflow.models.signature import infer_signature\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "from pyngrok import ngrok\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dotenv import load_dotenv\n",
        "import concurrent.futures\n",
        "import tarfile\n",
        "import nibabel as nib\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "from distutils.dir_util import copy_tree\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import SequentialSampler\n",
        "from torchvision import utils\n",
        "\n",
        "from monai.networks.nets import AutoEncoder\n",
        "from monai.losses import DiceCELoss, DiceFocalLoss, DiceLoss, FocalLoss\n",
        "\n",
        "from dgl import from_networkx as to_dgl_graph\n",
        "from dgl import batch as dgl_batch\n",
        "\n",
        "#torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE7OwGBES7sa"
      },
      "source": [
        "## MLFlow server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "M4-kysoZS-i4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages/pydantic/_internal/_config.py:321: UserWarning: Valid config keys have changed in V2:\n",
            "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
            "  warnings.warn(message, UserWarning)\n",
            "[2024-01-11 15:40:29 +0100] [82531] [INFO] Starting gunicorn 21.2.0\n",
            "[2024-01-11 15:40:29 +0100] [82531] [ERROR] Connection in use: ('127.0.0.1', 5000)\n",
            "[2024-01-11 15:40:29 +0100] [82531] [ERROR] Retrying in 1 second.\n",
            "[2024-01-11 15:40:30 +0100] [82531] [ERROR] Connection in use: ('127.0.0.1', 5000)\n",
            "[2024-01-11 15:40:30 +0100] [82531] [ERROR] Retrying in 1 second.\n",
            "[2024-01-11 15:40:31 +0100] [82531] [ERROR] Connection in use: ('127.0.0.1', 5000)\n",
            "[2024-01-11 15:40:31 +0100] [82531] [ERROR] Retrying in 1 second.\n",
            "[2024-01-11 15:40:32 +0100] [82531] [ERROR] Connection in use: ('127.0.0.1', 5000)\n",
            "[2024-01-11 15:40:32 +0100] [82531] [ERROR] Retrying in 1 second.\n",
            "[2024-01-11 15:40:33 +0100] [82531] [ERROR] Connection in use: ('127.0.0.1', 5000)\n",
            "[2024-01-11 15:40:33 +0100] [82531] [ERROR] Retrying in 1 second.\n",
            "[2024-01-11 15:40:34 +0100] [82531] [ERROR] Can't connect to ('127.0.0.1', 5000)\n",
            "Running the mlflow server failed. Please see the logs above for details.\n"
          ]
        }
      ],
      "source": [
        "mlflow.set_tracking_uri('file:///Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/mlruns')\n",
        "# run tracking UI in the background\n",
        "get_ipython().system_raw(\"mlflow ui --backend-store-uri file:///Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/mlruns --port 5000 & \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7ygOSsiEAWs"
      },
      "source": [
        "## Utils ðŸ› "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Lrs_wCJEAJpS"
      },
      "outputs": [],
      "source": [
        "class Logger:\n",
        "    def __init__(self,filename):\n",
        "        self.filename = filename\n",
        "        try:  #try to open file in 'r' (read) mode, if file does not exists the statement will throw an IOexception\n",
        "            log_file = open(self.filename, \"r\")\n",
        "            log_file.close()\n",
        "        except Exception as e: #catch the Exception raised from the block above and create the missing file in the specified path\n",
        "            log_file = open(self.filename, \"w\")\n",
        "            log_file.close()\n",
        "\n",
        "    def log_msg(self,*args):\n",
        "        try:\n",
        "            with open(self.filename, \"a+\") as log_file:\n",
        "                for el in args:\n",
        "                    if(type(el) is list or type(el) is tuple):\n",
        "                        for subel in el:\n",
        "                            log_file.write(subel)\n",
        "                            log_file.write('\\n')\n",
        "                    else:\n",
        "                        log_file.write(el)\n",
        "                        log_file.write('\\n')\n",
        "        except Exception as e:\n",
        "            print('Exception in Logger.log_msg')\n",
        "            print(e)\n",
        "\n",
        "    def read_msg(self):\n",
        "        content = []\n",
        "        try:\n",
        "            with open(self.filename) as file:\n",
        "                for el in file:\n",
        "                    content.append(el)\n",
        "        except Exception as e:\n",
        "            print('Exception in Logger.read_msg')\n",
        "            print(e)\n",
        "        finally:\n",
        "            return content\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def untar_brats(tar_path, extract_path):\n",
        "    tar = tarfile.open(tar_path)\n",
        "    tar.extractall(extract_path)\n",
        "    tar.close()\n",
        "\n",
        "def plot_reconstruction(im_orig, im_rec, ax:int = 0, slice_index:int = 100):\n",
        "\n",
        "    f, ax_array = plt.subplots(1,2, figsize=(10,10))\n",
        "    ax_array[0].imshow(np.take(im_orig, indices = slice_index, axis = ax), cmap='gray')\n",
        "    ax_array[1].imshow(np.take( im_rec , indices=slice_index, axis = ax), cmap='gray')\n",
        "\n",
        "def plot_brain_sections(images,ax = 1,slice_index = 90):\n",
        "\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "\n",
        "    d1,d2,d3 = np.shape(images[1])\n",
        "    dims = [d1,d2,d3]\n",
        "    dims.pop(ax)\n",
        "    color_segmentation = np.zeros((dims[0],dims[1],3))\n",
        "\n",
        "    gray_segmentation = np.take(images[1],slice_index,axis = ax)\n",
        "    color_segmentation[gray_segmentation == 1] = [255,0,0] # Red (necrotic tumor core)\n",
        "    color_segmentation[gray_segmentation == 2] = [0,255,0] # Green (peritumoral edematous/invaded tissue)\n",
        "    color_segmentation[gray_segmentation == 4] = [0,0,255] # Blue (enhancing tumor)\n",
        "\n",
        "    t1 = images[0][0]\n",
        "    flair = images[0][1]\n",
        "    t2 = images[0][2]\n",
        "    t1ce = images[0][3]\n",
        "\n",
        "    image = t1+t2+flair+t1ce\n",
        "\n",
        "    plt.figure(figsize=(15,15))\n",
        "    plt.subplot(1,4,1)\n",
        "    plt.imshow(np.take(image,slice_index,axis = 0),cmap='gray')\n",
        "\n",
        "    plt.subplot(1,4,2)\n",
        "    plt.imshow(np.take(image,slice_index,axis = 1),cmap='gray')\n",
        "\n",
        "    plt.subplot(1,4,3)\n",
        "    plt.imshow(np.take(image,slice_index,axis = 2),cmap='gray')\n",
        "\n",
        "    plt.subplot(1,4,4)\n",
        "    plt.imshow(color_segmentation,cmap='gray')\n",
        "    plt.xlabel('Segmentation')\n",
        "\n",
        "\n",
        "def visTensor(tensor, ch=0, allkernels=False, nrow=8, padding=1):\n",
        "    n,c,w,h = tensor.shape\n",
        "    if allkernels: tensor = tensor.view(n*c, -1, w, h)\n",
        "    elif c != 3: tensor = tensor[:,ch,:,:].unsqueeze(dim=1)\n",
        "    rows = np.min((tensor.shape[0] // nrow + 1, 64))\n",
        "    grid = utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n",
        "    plt.figure( figsize=(nrow,rows) )\n",
        "    plt.imshow(grid.cpu().permute((1, 2, 0)))\n",
        "\n",
        "\n",
        "def count_labels(triple_list):\n",
        "    label_counts = {}\n",
        "    labels = [triple[3] for triple in triple_list]\n",
        "\n",
        "    # Concatenate all the arrays into one\n",
        "    all_labels = np.concatenate(labels)\n",
        "\n",
        "    # Count the occurrences of each label\n",
        "    counter = Counter(all_labels)\n",
        "\n",
        "    # Create a dict with the counts for labels 1 to 4\n",
        "    counts_dict = {i: counter[i] for i in counter.keys()}\n",
        "    return counts_dict\n",
        "\n",
        "\n",
        "def class_weights_tensor(label_weights):\n",
        "    num_classes = max(label_weights.keys())+1\n",
        "    weight_tensor = torch.zeros(num_classes, dtype=torch.float32)\n",
        "    # Sort the dictionary by keys (labels)\n",
        "    sorted_label_weights = sorted(label_weights.items(), key=lambda x: x[0])\n",
        "    for label, weight in sorted_label_weights:\n",
        "        weight_tensor[label] = weight  # Subtract 1 from label if your labels start from 1\n",
        "    return weight_tensor\n",
        "\n",
        "\n",
        "def compute_average_weights(graphs):\n",
        "    label_counts = count_labels(graphs)\n",
        "    total_count = sum(label_counts.values())\n",
        "    class_weights = {label: total_count / count for label, count in label_counts.items()}\n",
        "    weight_tensor = class_weights_tensor(class_weights)\n",
        "    return weight_tensor\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKEY_j_lCzCa"
      },
      "source": [
        "## Dataset class  ðŸ’¾\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-Pa_KNzpRi0d"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Preprocessing script to convert from data provided by BraTS to data used by our model. Should be the first thing you run.\n",
        "Fulfills the following four functions:\n",
        "1. Normalize and standardize each image of each MRI modality\n",
        "2. Combine multiple MRI modalitities into one image array\n",
        "3. Swap labels from BraTS order (0,2,1,4) to more intuitive order (0,1,2,3)\n",
        "4. Convert image into a graph\n",
        "    Using Simple Linear Iterative Clustering algorithm\n",
        "    Parameters passed on command line\n",
        "\n",
        "If no labels are present (e.g. at test time, in deployment) can also build graph without labels.\n",
        "\n",
        "Saves the following in the specified output directory for each sample\n",
        "MRI_ID/\n",
        "    _input.nii.gz (processed and combined modalities for a sample as nifti file)\n",
        "    _label.nii.gz\n",
        "    _nxgraph.json (networkx graph containing both graph topography and features and labels for each node)\n",
        "    _supervoxels.nii.gz (supervoxel partitioning produced by SLIC)\n",
        "    _crop.npy (optionally the crop of the processed data relative to the original data) (crops out empty image planes)\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "class DataPreprocessor(Dataset):\n",
        "    def __init__(self, dotenv_path = \"/content/drive/MyDrive/Lorusso/BraTS/.env\", transform:bool = True, INPUT_PATH = None,\n",
        "                 num_nodes = 15000, boxiness_coef = 0.5, num_neighbors = 0, **kwargs):\n",
        "\n",
        "        load_dotenv(dotenv_path)\n",
        "        # Data mean and variance\n",
        "        data_stats = ([0.4645, 0.6625, 0.4064, 0.3648],\n",
        "                      [0.1593, 0.1703, 0.1216, 0.1627])\n",
        "        self.N_THREADS = 8\n",
        "        self.num_nodes = num_nodes\n",
        "        self.boxiness_coef = boxiness_coef\n",
        "        self.num_neighbors = num_neighbors\n",
        "\n",
        "        if(INPUT_PATH is not None and os.path.exists(INPUT_PATH)):\n",
        "            self.data_dir = INPUT_PATH\n",
        "        else:\n",
        "            self.data_dir = os.getenv('INPUT_DATA_DIR')\n",
        "\n",
        "        self.output_dir = os.getenv('PROCESSED_DATA_DIR')\n",
        "        self.graph_dir = f\"{self.output_dir}_{self.num_nodes}_{self.boxiness_coef}_{self.num_neighbors}{os.sep}{os.path.basename(self.data_dir)}\"\n",
        "        self.logger = Logger(filename=os.path.join(os.getenv('LOG_PATH'), os.path.basename(self.data_dir)+'_logs.txt'))\n",
        "\n",
        "        self.mri_prefix = 'BraTS2021_'\n",
        "        self.modality_extensions = [\"_flair.nii.gz\", \"_t1.nii.gz\", \"_t1ce.nii.gz\", \"_t2.nii.gz\"]\n",
        "        self.label_extension = \"_seg.nii.gz\"\n",
        "        self.include_labels = self.label_extension is not None\n",
        "        self.LABEL_MAP = {4: 3, 2: 1, 1: 2}\n",
        "        self.dataset_mean = np.array(data_stats[0], dtype=np.float32)\n",
        "        self.dataset_std = np.array(data_stats[1], dtype=np.float32)\n",
        "        self.transform = transform\n",
        "        self.force_conversion = False\n",
        "\n",
        "        # Set or overwrite additional attributes\n",
        "        for el in kwargs.keys():\n",
        "            setattr(self,str(el),kwargs[el])\n",
        "\n",
        "        self.all_ids, self.id_to_fp = self.get_all_mris_in_dataset()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.all_ids)\n",
        "\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        # DO NOT APPLY PADDING!! See this issue:\n",
        "        # https://github.com/RobertoLorusso/BraTS/issues/10#issue-2065431255\n",
        "        #imstack, labels = self.padding(imstack, labels)\n",
        "\n",
        "        imstack = self.read_in_patient_sample(idx)\n",
        "        labels = self.read_in_labels(idx)\n",
        "        crop_idxs = None\n",
        "\n",
        "        if (self.transform):\n",
        "            imstack,labels,crop_idxs = self.get_standardized_image(imstack, labels)\n",
        "        return imstack, labels, crop_idxs\n",
        "\n",
        "\n",
        "    def read_in_patient_sample(self, mri_id):\n",
        "        scan_dir = self.data_dir + os.sep + mri_id\n",
        "        modality_exts = self.modality_extensions\n",
        "        num_modalities=len(modality_exts)\n",
        "        modality_imgs = []\n",
        "        for root, _, files in os.walk(scan_dir):\n",
        "            for ext in modality_exts:\n",
        "                for filename in files:\n",
        "                    if filename.endswith(ext):\n",
        "                        filepath = os.path.join(root, filename)\n",
        "                        mod_img = nib.load(filepath)\n",
        "                        #data is actually stored as int16\n",
        "                        img_data = np.array(mod_img.dataobj,dtype=np.float32)\n",
        "                        modality_imgs.append(img_data)\n",
        "        #check that all the modalities were present in the folder\n",
        "        assert(len(modality_imgs)==num_modalities)\n",
        "\n",
        "        patient_sample = np.stack(modality_imgs,3) if num_modalities>1 else modality_imgs[0]\n",
        "        return patient_sample\n",
        "\n",
        "\n",
        "    def read_in_labels(self,mri_id):\n",
        "        scan_dir = self.data_dir + os.sep + mri_id\n",
        "        for filename in os.listdir(scan_dir):\n",
        "            if filename.endswith(self.label_extension):\n",
        "                label_nib = nib.load(scan_dir+os.sep+filename)\n",
        "                #potentially also return affine if they are different between images (which they are not for brats)\n",
        "                return np.array(label_nib.dataobj,dtype=np.int16)\n",
        "        raise FileNotFoundError(f\"Label image not found in folder: {scan_dir}\")\n",
        "\n",
        "\n",
        "    def get_all_mris_in_dataset(self):\n",
        "        mri_folders = glob.glob(f\"{self.data_dir}**/{self.mri_prefix}*/\",\n",
        "                                recursive=True)\n",
        "        mri_folders = self.remove_incomplete_mris(mri_folders)\n",
        "        scan_dic = {os.path.split(fp)[0].split(\"/\")[-1]: fp for fp in mri_folders}\n",
        "        if(len(mri_folders) == 0):\n",
        "            print(\"No MRI found at \" + self.data_dir)\n",
        "        return list(scan_dic.keys()), scan_dic\n",
        "\n",
        "\n",
        "    def remove_incomplete_mris(self, mri_folders):\n",
        "        # if there are any you want to ignore just add them to this list\n",
        "        removed_mris = []\n",
        "        return [fp for fp in mri_folders if fp.split(\"/\")[-2] not in removed_mris]\n",
        "\n",
        "    def padding(self,image, labels):\n",
        "        n_channels = np.shape(image)[0]\n",
        "        max_val = max(np.shape(image))\n",
        "        pad_list = np.zeros([n_channels,max_val,max_val,max_val],dtype=np.float32)\n",
        "\n",
        "        for channel in range(0, n_channels): # pad every channel\n",
        "            pad_list[channel] = np.pad(image[channel],[(42,43),(0,0),(0,0)],'constant')\n",
        "        labels = np.pad(labels, [(42,43),(0,0),(0,0)],'constant')\n",
        "\n",
        "        return pad_list, labels\n",
        "\n",
        "\n",
        "    def get_standardized_image(self, image_data, label_data):\n",
        "\n",
        "        #standardized_labels = self.swap_labels_from_brats(label_data)\n",
        "\n",
        "        crop_idxs = self.determine_brain_crop(image_data)\n",
        "        cropped_data = image_data[crop_idxs]\n",
        "        if(self.label_extension):\n",
        "            cropped_labels = label_data[crop_idxs]\n",
        "            standardized_labels= self.swap_labels_from_brats(cropped_labels)\n",
        "        else:\n",
        "            standardized_labels = None\n",
        "\n",
        "        normalized_data = self.normalize_img_quantile(cropped_data)\n",
        "        standardized_data = self.standardize_img(normalized_data)\n",
        "        return standardized_data,standardized_labels,crop_idxs\n",
        "\n",
        "\n",
        "    def determine_brain_crop(self,multi_modal_data):\n",
        "        if(len(multi_modal_data.shape)==4):\n",
        "            max_intensity_vals = np.amax(multi_modal_data,axis=3)\n",
        "        elif(len(multi_modal_data.shape)==3):\n",
        "            max_intensity_vals = multi_modal_data\n",
        "        else:\n",
        "            raise Exception(f\"Expected input shape of either nxmxr or nxmxrxC. Instead got {multi_modal_data.shape}\")\n",
        "        mask = max_intensity_vals>0.01\n",
        "        ix = np.ix_(mask.any(axis=(1,2)),mask.any(axis=(0,2)),mask.any(axis=(0,1)))\n",
        "\n",
        "        return ix\n",
        "\n",
        "    def normalize_img(self, img_array):\n",
        "        new_image = np.zeros(img_array.shape, dtype=np.float32)\n",
        "        n_channel = img_array.shape[3] # channel-first images\n",
        "\n",
        "        for channel in range(0, n_channel): # normalize every channel\n",
        "\n",
        "            maxval, minval= np.max(img_array[channel]), np.min(img_array[channel])\n",
        "            new_image[channel] = (img_array[channel] - minval)/(maxval-minval)\n",
        "        return new_image\n",
        "\n",
        "\n",
        "    def normalize_img_quantile(self, img_array):\n",
        "        # Exclude the channel axis, for channel-first images is zero\n",
        "        quantile = np.quantile(img_array, 0.995, axis = (0,1,2) ).astype(np.float32)\n",
        "        img_array = img_array/quantile\n",
        "        return img_array\n",
        "\n",
        "\n",
        "\n",
        "    def standardize_img(self,img_array):\n",
        "        centered = img_array-self.dataset_mean\n",
        "        standardized = centered/self.dataset_std\n",
        "        return standardized\n",
        "\n",
        "\n",
        "    def get_status_ids(self):\n",
        "\n",
        "        common_ids = set()\n",
        "        converting_ids = set()\n",
        "        finished_ids = set()\n",
        "\n",
        "        finished = []\n",
        "        pending = []\n",
        "\n",
        "        try:\n",
        "            regex= r'(Converting|Finished) '+ self.mri_prefix + '(\\d+)'\n",
        "\n",
        "            content = self.logger.read_msg()\n",
        "            # Define the regular expression pattern\n",
        "            pattern = re.compile(regex)\n",
        "\n",
        "            # Find all occurrences in the list\n",
        "            matches = [match.groups() for s in content if (match := pattern.match(s))]\n",
        "\n",
        "            for action, brats_id in matches:\n",
        "                if action == 'Converting':\n",
        "                    converting_ids.add(self.mri_prefix + brats_id)\n",
        "                elif action == 'Finished':\n",
        "                    finished_ids.add(self.mri_prefix + brats_id)\n",
        "\n",
        "            # Find finished and pending conversions\n",
        "            common_ids = converting_ids.intersection(finished_ids)\n",
        "            finished = [el for el in common_ids]\n",
        "            pending = [el for el in converting_ids.difference(common_ids)]\n",
        "\n",
        "        except Exception as e:\n",
        "            print('Exception in Logger.get_status_ids')\n",
        "            print(e)\n",
        "\n",
        "        return {'Finished':finished, 'Pending':pending}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def remove_pending_graphs(self):\n",
        "\n",
        "        pending = self.get_status_ids()['Pending']\n",
        "\n",
        "        for mri_id in pending:\n",
        "            remove_path = f\"{self.graph_dir}{os.sep}{mri_id}\"\n",
        "            try:\n",
        "                print('Removing pending graph: ' + remove_path)\n",
        "                shutil.rmtree(remove_path)\n",
        "            except Exception as e:\n",
        "                print('Exception in DataPreprocessor.remove_pending_graphs:')\n",
        "                print(e)\n",
        "\n",
        "\n",
        "\n",
        "    def split_dataset(self, fixed = (1001, 125, 125),seed = 42):\n",
        "\n",
        "        random.seed(seed)\n",
        "        pos = random.sample(range(0,len(self.all_ids)), len(self.all_ids))\n",
        "\n",
        "        if fixed:\n",
        "            if(np.sum(fixed) != len(self.all_ids)):\n",
        "                print(\"Error: fixed ratio does not sum up to one.\\nSwitching to default (1001,125,125))\")\n",
        "                fixed = (1001,125,125)\n",
        "\n",
        "            train_length = fixed[0]\n",
        "            val_length = fixed[1]\n",
        "            test_length = fixed[2]\n",
        "\n",
        "\n",
        "        split_dict = {\n",
        "            'train': [self.all_ids[i] for i in pos[:train_length]],\n",
        "            'val': [self.all_ids[i] for i in pos[train_length :train_length + val_length]],\n",
        "            'test': [self.all_ids[i] for i in pos[train_length + val_length:]]\n",
        "        }\n",
        "\n",
        "        for k in split_dict.keys():\n",
        "            parent = '/'.join(self.data_dir.split('/')[:-1])\n",
        "            dst = os.path.join(parent,k)\n",
        "\n",
        "            try:\n",
        "              # create train,val,test dirs\n",
        "              if(not os.path.exists(dst)):\n",
        "                os.mkdir(dst)\n",
        "\n",
        "              # copy splitted data inside folders\n",
        "              for id in split_dict[k]:\n",
        "                if(not os.path.exists(os.path.join(dst,id))):\n",
        "                   os.mkdir(os.path.join(dst,id))\n",
        "                copy_tree(self.id_to_fp[id],os.path.join(dst,id))\n",
        "\n",
        "            except Exception as e:\n",
        "              print(f\"Exception thrown in class {self.__class__.__name__ }, method split_dataset\")\n",
        "              print(e)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def image_to_graph(self, mri_id):\n",
        "\n",
        "\n",
        "        save_path = f\"{self.graph_dir}{os.sep}{mri_id}\"\n",
        "        finished = self.get_status_ids()['Finished']\n",
        "\n",
        "        if(mri_id not in finished):\n",
        "            self.logger.log_msg('Converting ' + str(mri_id))\n",
        "        print('Converting ' + str(mri_id))\n",
        "\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "\n",
        "        if(not os.path.exists(f\"{save_path}{os.sep}{mri_id}_input.nii.gz\") or self.force_conversion == True):\n",
        "            imstack, labels, crop_idxs = self.__getitem__(mri_id)\n",
        "        else:\n",
        "            imstack, labels = self.get_image(mri_id)\n",
        "\n",
        "        # Load supervoxels, if already exist, and save computational time avoiding the runnning of slic\n",
        "        sv_partitioning = None\n",
        "        if(os.path.exists(f\"{save_path}{os.sep}{mri_id}_supervoxels.nii.gz\")):\n",
        "            sv_partitioning = self.get_supervoxel_partitioning(mri_id)\n",
        "            print('Loading supervoxels...')\n",
        "        #print('Run: ' +str(imstack.shape) +' ' +str(labels.shape))\n",
        "        # TRANSPOSE variable imstack because img2graph expects channel-first images\n",
        "        nx_graph,node_feats,region_img = img2graph(imstack,labels,sv_partitioning,self.num_nodes,self.boxiness_coef,self.num_neighbors)\n",
        "\n",
        "        save_networkx_graph(nx_graph, f\"{save_path}{os.sep}{mri_id}_nxgraph.json\")\n",
        "        save_as_nifti(imstack,f\"{save_path}{os.sep}{mri_id}_input.nii.gz\")\n",
        "        save_as_nifti(labels,f\"{save_path}{os.sep}{mri_id}_label.nii.gz\")\n",
        "        save_as_nifti(region_img,f\"{save_path}{os.sep}{mri_id}_supervoxels.nii.gz\")\n",
        "        with open(f\"{save_path}{os.sep}{mri_id}_crop.pkl\", \"wb\") as f:\n",
        "            pickle.dump(crop_idxs, f)\n",
        "\n",
        "        return mri_id\n",
        "\n",
        "    def get_voxel_labels(self,mri_id):\n",
        "        fp=f\"{self.graph_dir}{os.sep}{mri_id}{os.sep}{mri_id}_label.nii.gz\"\n",
        "        return read_nifti(fp,np.int16)\n",
        "\n",
        "    def get_image(self,mri_id):\n",
        "        fp = f\"{self.graph_dir}{os.sep}{mri_id}{os.sep}{mri_id}_input.nii.gz\"\n",
        "        img = read_nifti(fp,np.float32)\n",
        "        return img,self.get_voxel_labels(mri_id)\n",
        "\n",
        "\n",
        "    def get_supervoxel_partitioning(self,mri_id):\n",
        "        fp=f\"{self.graph_dir}{os.sep}{mri_id}{os.sep}{mri_id}_supervoxels.nii.gz\"\n",
        "        return read_nifti(fp,np.int16)\n",
        "\n",
        "    def run(self):\n",
        "\n",
        "        self.remove_pending_graphs()\n",
        "\n",
        "        with concurrent.futures.ThreadPoolExecutor(max_workers=self.N_THREADS) as executor:\n",
        "            futures = [executor.submit(self.image_to_graph, mri_id) for mri_id in self.all_ids]\n",
        "            print(\"Set up Threads, starting execution\")\n",
        "            for future in concurrent.futures.as_completed(futures):\n",
        "                try:\n",
        "                    mri_id = future.result()\n",
        "                except Exception as exc:\n",
        "                    print(\"Exception caught in DataPreprocessor.run\")\n",
        "                    print(f\"{exc}\")\n",
        "                else:\n",
        "                    if(mri_id not in self.get_status_ids()['Finished']):\n",
        "                        # Log message\n",
        "                        self.logger.log_msg('Finished ' + str(mri_id))\n",
        "                    print(\"Finished \"+ str(mri_id))\n",
        "\n",
        "    def swap_labels_from_brats(self,label_data):\n",
        "        uniques = np.unique(label_data)\n",
        "        for u in uniques:\n",
        "            if u not in [0, 1, 2, 4]:\n",
        "                raise RuntimeError('unexpected label')\n",
        "        new_label_data = np.zeros_like(label_data, dtype=np.int16)\n",
        "        new_label_data[label_data == 4] = self.LABEL_MAP[4]\n",
        "        new_label_data[label_data == 2] = self.LABEL_MAP[2]\n",
        "        new_label_data[label_data == 1] = self.LABEL_MAP[1]\n",
        "        return new_label_data\n",
        "\n",
        "    def swap_labels_to_brats(self,label_data):\n",
        "        uniques = np.unique(label_data)\n",
        "        for u in uniques:\n",
        "            if u not in [0, 1, 2, 3]:\n",
        "                raise RuntimeError('unexpected label')\n",
        "        new_label_data = np.zeros_like(label_data, dtype=np.int16)\n",
        "        new_label_data[label_data == self.LABEL_MAP[4]] = 4\n",
        "        new_label_data[label_data == self.LABEL_MAP[2]] = 2\n",
        "        new_label_data[label_data == self.LABEL_MAP[1]] = 1\n",
        "        return new_label_data\n",
        "\n",
        "\n",
        "'''\n",
        "A Dataset similar to a torch dataset which iterates over all samples in a directory and returns the contents as numpy arrays.\n",
        "Expects to receive a filepath to the output of the preprocess script which should have the following:\n",
        "1.processed image (nifti)\n",
        "2.label image (nifti)\n",
        "3.networkx graph (json)\n",
        "4.supervoxel partitioning (nifti)\n",
        "5. (optionally) a .npy file containing the crop of the processed image relative to the original image\n",
        "\n",
        "\n",
        "#Input#\n",
        "dataset_root_dir: filepath to preprocessed dataset (generated by running preprocess script)\n",
        "mri_start_string: a prefix that every image folder starts with (can be empty string)\n",
        "read_image: whether to read in and return preprocessed images for each sample (only necessary for CNN model)\n",
        "read_graph: whether to return graphs for each sample (for training GNN)\n",
        "read_label: whether to read in labels. Will be returned in vector form (one label per node if )\n",
        "\n",
        "#Output#\n",
        "\n",
        "If graph:\n",
        "Returns a DGL Graph, features for each node, and (optionally) labels for each node\n",
        "If image:\n",
        "Returns a numpy image array and (optionally) a numpy label array\n",
        "\n",
        "'''\n",
        "\n",
        "class ImageGraphDataset(Dataset):\n",
        "    def __init__(self, dataset_root_dir,mri_start_string,read_image=True,read_graph=True,read_label=True):\n",
        "        self.dataset_root_dir=dataset_root_dir\n",
        "        self.all_ids = self.get_all_mris_in_dataset(dataset_root_dir,mri_start_string)\n",
        "        self.read_image=read_image\n",
        "        self.read_graph=read_graph\n",
        "        self.read_label = read_label\n",
        "        assert(self.read_graph or self.read_image)\n",
        "\n",
        "    def get_all_mris_in_dataset(self,dataset_root_dir,mri_start_string):\n",
        "        mri_folders = glob.glob(f\"{dataset_root_dir}**/{mri_start_string}*/\",recursive=True)\n",
        "        mri_ids = [fp.split(os.sep)[-2] for fp in mri_folders]\n",
        "        print(f\"Found {len(mri_folders)} MRIs\")\n",
        "        return mri_ids\n",
        "\n",
        "    def get_one(self,mri_id):\n",
        "        if(self.read_graph and not self.read_image):\n",
        "            return (mri_id, *self.get_graph(mri_id))\n",
        "        elif(self.read_image  and not self.read_graph):\n",
        "            return (mri_id, *self.get_image(mri_id))\n",
        "        elif(self.read_image and self.read_graph):\n",
        "            return (mri_id, *self.get_graph(mri_id), *self.get_image(mri_id))\n",
        "        else:\n",
        "            print(\"Invalid combination of flags\")\n",
        "\n",
        "    '''\n",
        "    Reads in the saved networkx graph, converts it to a DGLGraph, normalizes the graph (not actually sure how useful this is),\n",
        "    and returns the DGLGraph as well as a vector of node features and optionally labels.\n",
        "    '''\n",
        "    def get_graph(self,mri_id):\n",
        "        nx_graph = load_networkx_graph(f\"{self.dataset_root_dir}{os.sep}{mri_id}{os.sep}{mri_id}_nxgraph.json\")\n",
        "        features = np.array([nx_graph.nodes[n]['features'] for n in nx_graph.nodes])\n",
        "        if(self.read_label):\n",
        "            labels = np.array([nx_graph.nodes[n]['label'] for n in nx_graph.nodes])\n",
        "\n",
        "        G = to_dgl_graph(nx_graph)\n",
        "        n_edges = G.number_of_edges()\n",
        "        # normalization\n",
        "        degs = G.in_degrees().float()\n",
        "        norm = torch.pow(degs, -0.5)\n",
        "        norm[torch.isinf(norm)] = 0\n",
        "        G.ndata['norm'] = norm.unsqueeze(1)\n",
        "        #G.ndata['feat'] = features\n",
        "        if(self.read_label):\n",
        "            #G.ndata['label'] = labels\n",
        "            return G, features, labels\n",
        "        return G, features\n",
        "\n",
        "    def get_voxel_labels(self,mri_id):\n",
        "        fp=f\"{self.dataset_root_dir}{os.sep}{mri_id}{os.sep}{mri_id}_label.nii.gz\"\n",
        "        return read_nifti(fp,np.int16)\n",
        "\n",
        "    def get_image(self,mri_id):\n",
        "        fp = f\"{self.dataset_root_dir}{os.sep}{mri_id}{os.sep}{mri_id}_input.nii.gz\"\n",
        "        img = read_nifti(fp,np.float32)\n",
        "        if(self.read_label):\n",
        "            return img,self.get_voxel_labels(mri_id)\n",
        "        else:\n",
        "            return (img,)\n",
        "\n",
        "    def get_supervoxel_partitioning(self,mri_id):\n",
        "        fp=f\"{self.dataset_root_dir}{os.sep}{mri_id}{os.sep}{mri_id}_supervoxels.nii.gz\"\n",
        "        return read_nifti(fp,np.int16)\n",
        "\n",
        "    def get_crop(self,mri_id):\n",
        "        fp=f\"{self.dataset_root_dir}{os.sep}{mri_id}{os.sep}{mri_id}_crop.npy\"\n",
        "        return tuple(np.load(fp,allow_pickle=True))\n",
        "\n",
        "    def __iter__(self):\n",
        "        for mri_id in self.all_ids:\n",
        "            yield self.get_one(mri_id)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        mri_id = self.all_ids[index]\n",
        "        #print(index)\n",
        "        #mri_id = [el for el in self.all_ids if el == index][0]\n",
        "        return self.get_one(mri_id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.all_ids)\n",
        "\n",
        "\n",
        "\n",
        "class SeqSampler(SequentialSampler):\n",
        "    \"\"\"Samples elements sequentially, always in the same order.\n",
        "\n",
        "    Args:\n",
        "        data_source (Dataset): dataset to sample from\n",
        "    \"\"\"\n",
        "    def __init__(self, data_source:Dataset):\n",
        "        self.data_source = data_source\n",
        "        self.indexDict = [id for id in data_source.all_ids]\n",
        "    def __iter__(self):\n",
        "        return iter(self.indexDict)\n",
        "    def __len__(self):\n",
        "        return len(self.indexDict)\n",
        "\n",
        "\n",
        "def minibatch_graphs(samples):\n",
        "    mri_ids,graphs,features, labels = map(list, zip(*samples))\n",
        "    #print(\"Batch Mri Ids:\",mri_ids)\n",
        "    batched_graph = dgl_batch(graphs)\n",
        "    return mri_ids,batched_graph, torch.FloatTensor(np.concatenate(features)), torch.LongTensor(np.concatenate(labels))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgINpL8BK3hL"
      },
      "source": [
        "## Models ðŸ“ª\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "78WIjwSZRkGN"
      },
      "outputs": [],
      "source": [
        "\n",
        "from dgl.nn.pytorch import GATConv, GraphConv\n",
        "from dgl.nn.pytorch.conv import SAGEConv\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "'''\n",
        "Contains the actual neural network architectures.\n",
        "Supports GraphSAGE with either the pool,mean,gcn, or lstm aggregator as well as GAT.\n",
        "The input, output, and intermediate layer sizes can all be specified.\n",
        "Typically will call init_graph_net and pass along the desired model and hyperparameters.\n",
        "\n",
        "Also contains the CNN Refinement net which is a very simple 2 layer 3D convolutional neural network.\n",
        "As input, it expects 8 channels, which are the concatenated 4 input modalities and 4 output logits of the GNN predictions.\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "class GraphSage(nn.Module):\n",
        "    def __init__(self,in_feats,layer_sizes,n_classes,aggregator_type,dropout):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        # input layer\n",
        "        self.layers.append(SAGEConv(in_feats, layer_sizes[0], aggregator_type, feat_drop=dropout, activation=F.relu))\n",
        "        # hidden layers\n",
        "        for i in range(1,len(layer_sizes)):\n",
        "            self.layers.append(SAGEConv(layer_sizes[i-1], layer_sizes[i], aggregator_type, feat_drop=dropout, activation=F.relu))\n",
        "        # output layer\n",
        "        self.layers.append(SAGEConv(layer_sizes[-1], n_classes, aggregator_type, feat_drop=0, activation=None))\n",
        "\n",
        "    def forward(self,graph,features):\n",
        "        h = features\n",
        "        for layer in self.layers:\n",
        "            h = layer(graph, h)\n",
        "        return h\n",
        "\n",
        "\n",
        "class GAT(nn.Module):\n",
        "    def __init__(self,in_feats,layer_sizes,n_classes,heads,residuals,\n",
        "                activation=F.elu,feat_drop=0,attn_drop=0,negative_slope=0.2):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.activation = activation\n",
        "        # input projection (no residual)\n",
        "        self.layers.append(GATConv(\n",
        "            in_feats, layer_sizes[0], heads[0],\n",
        "            feat_drop, attn_drop, negative_slope, False, self.activation))\n",
        "        # hidden layers\n",
        "        for i in range(1, len(layer_sizes)):\n",
        "            # due to multi-head, the in_dim = num_hidden * num_heads\n",
        "            self.layers.append(GATConv(\n",
        "                layer_sizes[i-1] * heads[i-1], layer_sizes[i], heads[i],\n",
        "                feat_drop, attn_drop, negative_slope, residuals[i], self.activation))\n",
        "        # output projection\n",
        "        self.layers.append(GATConv(\n",
        "            layer_sizes[-1] * heads[-1], n_classes, 1,\n",
        "            feat_drop, attn_drop, negative_slope, False, None))\n",
        "\n",
        "    def forward(self,g, inputs):\n",
        "        h = inputs\n",
        "        for l in range(len(self.layers)-1):\n",
        "            h = self.layers[l](g, h).flatten(1)\n",
        "        # output projection\n",
        "        logits = self.layers[-1](g, h).mean(1)\n",
        "        return logits\n",
        "\n",
        "\n",
        "class GIN(nn.Module):\n",
        "    def __init__(self, in_feats, layer_sizes, n_classes, dropout):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # input layer\n",
        "        self.layers.append(GINConv(apply_func=nn.Linear(in_feats, layer_sizes[0]), aggregator_type='sum'))\n",
        "        # hidden layers\n",
        "        for i in range(1, len(layer_sizes)):\n",
        "            self.layers.append(GINConv(apply_func=nn.Linear(layer_sizes[i-1], layer_sizes[i]), aggregator_type='sum'))\n",
        "        # output layer\n",
        "        self.layers.append(GINConv(apply_func=nn.Linear(layer_sizes[-1], n_classes), aggregator_type='sum'))\n",
        "\n",
        "    def forward(self, g, feat):\n",
        "        h = feat\n",
        "        for layer in self.layers[:-1]:\n",
        "            h = layer(g, h)\n",
        "            h = F.relu(h)\n",
        "            h = F.dropout(h, p=self.dropout, training=self.training)\n",
        "        h = self.layers[-1](g, h)\n",
        "        return h\n",
        "\n",
        "\n",
        "class ChebNet(nn.Module):\n",
        "    def __init__(self, in_feats, layer_sizes, n_classes, k, dropout):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # Input layer\n",
        "        self.layers.append(ChebConv(in_feats, layer_sizes[0], k))\n",
        "\n",
        "        # Hidden layers\n",
        "        for i in range(1, len(layer_sizes)):\n",
        "            self.layers.append(ChebConv(layer_sizes[i-1], layer_sizes[i], k))\n",
        "\n",
        "        # Output layer\n",
        "        self.layers.append(ChebConv(layer_sizes[-1], n_classes, k))\n",
        "\n",
        "    def forward(self, g, inputs):\n",
        "        h = inputs\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            h = layer(g, h)\n",
        "            if i != len(self.layers) - 1: # No activation and dropout on the output layer\n",
        "                h = F.relu(h)\n",
        "                h = self.dropout(h)\n",
        "        return h\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u3q4OhjYyGq"
      },
      "source": [
        "## Model Wrapper ðŸ“¨\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "biiQzha9JP8G"
      },
      "outputs": [],
      "source": [
        "class ModelWrapper():\n",
        "    \"\"\"\n",
        "    Allows train, evaluation, prediction and I/O operations on generic PyTorch models\n",
        "    The model is saved at every epoch.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model: nn.Module, optimizer: nn.Module, loss_fn: nn.Module,\n",
        "                 num_epochs: int, supervised: bool = True, dict_params:dict = {}, eval_metrics = None, isgnn:bool = True, LOAD_MODEL: bool = False,\n",
        "                 model_path: str  = '/content/drive/MyDrive/Lorusso/models',):\n",
        "\n",
        "        self.device = (\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "        self.model = model\n",
        "        self.model = self.model.to(self.device)\n",
        "        self.model = self.model.to(torch.float)\n",
        "        self.num_epochs = num_epochs\n",
        "        self.loss_fn = loss_fn\n",
        "        self.loss_fn = self.loss_fn.to(self.device)\n",
        "        self.eval_metrics = eval_metrics\n",
        "        self.optimizer = optimizer\n",
        "        self.model_path = model_path\n",
        "        self.save_path = self.model_path + '/' + self.model.__class__.__name__ + '/model.pt'\n",
        "\n",
        "        self.LOAD_MODEL = LOAD_MODEL\n",
        "        self.isgnn = isgnn\n",
        "        self.supervised = supervised\n",
        "        self.training_loss = []\n",
        "        self.validation_loss = []\n",
        "        self.dict_metrics = {}\n",
        "        self.elapsed_epochs = 0\n",
        "        self.elapsed_seconds = 0\n",
        "\n",
        "        self.dict_params = dict_params\n",
        "        self.update_params({'loss_fn':self.loss_fn.__class__.__name__})\n",
        "        self.update_params({'optimizer':self.optimizer.__class__.__name__})\n",
        "        self.update_params({'learning_rate':self.optimizer.state_dict()['param_groups'][0]['lr']})\n",
        "        self.update_params({'weight_decay':self.optimizer.state_dict()['param_groups'][0]['weight_decay']})\n",
        "\n",
        "        if(self.LOAD_MODEL):\n",
        "          self.load_checkpoint()\n",
        "        self.scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma = 0.98)\n",
        "        # Create directory for model loading\n",
        "        #try:\n",
        "        #  if(not os.path.exists(self.model_path + '/' + self.model.__class__.__name__)):\n",
        "        #    os.mkdir(self.model_path + '/' + self.model.__class__.__name__)\n",
        "        #except Exception as e:\n",
        "        #  print(f\"Exception thrown in class {self.__class__.__name__ }, method __init__\")\n",
        "        #  print(e)\n",
        "        #  print('\\n')\n",
        "\n",
        "\n",
        "    def update_params(self, new_params):\n",
        "        try:\n",
        "            self.dict_params.update(new_params)\n",
        "        except Exception as e:\n",
        "            print('Exception raised in WrapperModel.update_params')\n",
        "            print(e)\n",
        "\n",
        "    def log_checkpoint(self, info: dict):\n",
        "        mlflow.pytorch.log_state_dict(info, artifact_path='checkpoint')\n",
        "        #torch.save(info, self.save_path)\n",
        "\n",
        "    def load_checkpoint(self, run_id = None):\n",
        "        \"\"\" Loads the last checkpoint for the given model \"\"\"\n",
        "        try:\n",
        "            if(run_id is None):\n",
        "                run_id = mlflow.search_runs(experiment_names=['BraTS_'+type(self.model).__name__],\n",
        "                                        order_by=[\"start_time DESC\"]).iloc[0].run_id\n",
        "\n",
        "            checkpoint = mlflow.pytorch.load_state_dict('runs:/'+run_id+'/checkpoint',\n",
        "                                                        map_location=torch.device(self.device))\n",
        "\n",
        "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            self.elapsed_epochs = len(checkpoint['training_loss'])\n",
        "            self.training_loss = checkpoint['training_loss']\n",
        "            self.validation_loss = checkpoint['validation_loss']\n",
        "            self.dict_metrics = checkpoint['dict_metrics']\n",
        "            self.elapsed_seconds = checkpoint['elapsed_seconds']\n",
        "            #print(self.elapsed_epochs)\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Exception thrown in class {self.model.__class__.__name__ }, method load_checkpoint\")\n",
        "            print(e)\n",
        "            print('\\n')\n",
        "            if(mlflow.active_run()):\n",
        "                mlflow.end_run()\n",
        "\n",
        "\n",
        "    #Calculates a slew of different metrics that might be interesting such as the number of nodes of each label and voxel and node Dice scores\n",
        "    def calculate_all_metrics_for_brain(self,mri_id,dataset,node_preds,node_labels):\n",
        "        label_counts = np.concatenate([evaluation.count_node_labels(node_preds),evaluation.count_node_labels(node_labels)])\n",
        "        node_dices = evaluation.calculate_node_dices(node_preds,node_labels)\n",
        "        #read in voxel_labels and supervoxel mapping to compute the image metrics\n",
        "        sv_partitioning = dataset.get_supervoxel_partitioning(mri_id)\n",
        "        true_voxels = dataset.get_voxel_labels(mri_id)\n",
        "        pred_voxels = project_nodes_to_img(sv_partitioning,node_preds)\n",
        "        voxel_metrics = evaluation.calculate_brats_metrics(pred_voxels,true_voxels)\n",
        "        return label_counts,np.concatenate([node_dices,voxel_metrics])\n",
        "\n",
        "\n",
        "    def train(self, train_loader, val_loader = None,  experiment_prefix = ''):\n",
        "\n",
        "        try:\n",
        "            # Set MLFlow experiment\n",
        "            if(experiment_prefix):\n",
        "                mlflow.set_experiment(experiment_prefix + self.model.__class__.__name__)\n",
        "            else:\n",
        "                mlflow.set_experiment('BraTS_'+self.model.__class__.__name__)\n",
        "\n",
        "            # Start a new run if the model wasn't loaded\n",
        "            if(not mlflow.active_run()):\n",
        "                # Track metrics in the current run\n",
        "                mlflow.start_run()\n",
        "            elif(self.LOAD_MODEL == False and mlflow.active_run()):\n",
        "                mlflow.end_run()\n",
        "                mlflow.start_run()\n",
        "\n",
        "            for i in range(len(self.training_loss)):\n",
        "                mlflow.log_metric('train_loss', self.training_loss[i], step=i)\n",
        "\n",
        "            for i in range(len(self.validation_loss)):\n",
        "                mlflow.log_metric('val_loss', self.validation_loss[i], step=i)\n",
        "\n",
        "            self.update_params({'batch_size':train_loader.batch_size})\n",
        "            mlflow.log_params(self.dict_params)\n",
        "\n",
        "            training_loss = self.training_loss\n",
        "            validation_loss = self.validation_loss\n",
        "\n",
        "            self.tot_epochs = self.elapsed_epochs + self.num_epochs+1\n",
        "            self.tot_time = time.time()\n",
        "\n",
        "            # Train\n",
        "            for epoch in range(self.elapsed_epochs+1, self.tot_epochs):\n",
        "                start = time.time() # track time\n",
        "\n",
        "              # Evaluate first if loaded model missed the evaluation during an epoch\n",
        "                if(len(training_loss) > len(validation_loss)):\n",
        "\n",
        "                    # COMPLETE EVALUATION OF PREVIOUS EPOCH\n",
        "                    # NB: epoch = epoch - 1\n",
        "                    if(val_loader is not None):\n",
        "\n",
        "                        val_batch_loss = self.__eval(val_loader, (epoch-1) )\n",
        "                        validation_loss.append(np.array(val_batch_loss).mean())\n",
        "\n",
        "                        # Log additional metrics\n",
        "                        self.dict_metrics = self.__eval_metrics(val_loader)\n",
        "                        for k in self.dict_metrics.keys():\n",
        "                            mlflow.log_metric(str(k), self.dict_metrics[k], step=epoch-1)\n",
        "\n",
        "                        mlflow.log_metric('val_loss',validation_loss[-1], step=epoch-1)\n",
        "\n",
        "                        print(f\"Epoch: {epoch-1}/{self.tot_epochs-1}, Validation Loss: {validation_loss[-1]:.4f}, Elapsed time: {time.time() - start:.0f} sec\")\n",
        "\n",
        "                      # Update training time\n",
        "                        epoch_time = int(time.time() - self.tot_time) + self.elapsed_seconds\n",
        "\n",
        "                      #Create checkpoint\n",
        "                        val_dict = {\n",
        "                                  'model_state_dict': self.model.state_dict(),\n",
        "                                  'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                                  'training_loss': training_loss,\n",
        "                                  'validation_loss': validation_loss,\n",
        "                                  'dict_metrics': self.dict_metrics,\n",
        "                                  'elapsed_seconds': epoch_time\n",
        "                                  }\n",
        "                        self.log_checkpoint(val_dict)\n",
        "                    else:\n",
        "                        # Kind of exception, needed to keep the vectors of the same size\n",
        "                        validation_loss.append(np.mean(validation_loss))\n",
        "\n",
        "                        #Log metric\n",
        "                        mlflow.log_metric('val_loss',validation_loss[-1], step=epoch-1)\n",
        "\n",
        "                #### TRAIN ######\n",
        "                train_batch_loss = self.__train(train_loader, epoch)\n",
        "                training_loss.append(np.array(train_batch_loss).mean())\n",
        "\n",
        "                # Log metrics\n",
        "                mlflow.log_metric('train_loss',training_loss[-1], step=epoch) # MLFLOW tracking\n",
        "                print(f\"Epoch: {epoch}/{self.tot_epochs-1}, Loss: {training_loss[-1]:.4f}, Epoch elapsed time: {time.time() - start:.0f} sec \\n\")\n",
        "\n",
        "                #Save model every elapsed epoch\n",
        "                self.elapsed_epochs = epoch\n",
        "                epoch_time = int(time.time() - self.tot_time) + self.elapsed_seconds\n",
        "\n",
        "                train_dict = {\n",
        "                          'model_state_dict': self.model.state_dict(),\n",
        "                          'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                          'training_loss': training_loss,\n",
        "                          'validation_loss': validation_loss,\n",
        "                          'dict_metrics':self.dict_metrics,\n",
        "                          'elapsed_seconds': epoch_time\n",
        "                          }\n",
        "                self.log_checkpoint(train_dict)\n",
        "\n",
        "                #### EVALUATE ######\n",
        "                if(val_loader is not None):\n",
        "\n",
        "                    val_batch_loss = self.__eval(val_loader, epoch)\n",
        "                    validation_loss.append(np.array(val_batch_loss).mean())\n",
        "\n",
        "                    # Log additional metrics\n",
        "                    self.dict_metrics = self.__eval_metrics(val_loader)\n",
        "                    for k in self.dict_metrics.keys():\n",
        "                        mlflow.log_metric(str(k), self.dict_metrics[k], step=epoch)\n",
        "\n",
        "                    # Log metric\n",
        "                    mlflow.log_metric('val_loss',validation_loss[-1], step=epoch)\n",
        "                    print(f\"Epoch: {epoch}/{self.tot_epochs-1}, Validation Loss: {validation_loss[-1]:.4f}, Elapsed time: {time.time() - start:.0f} sec\\n\")\n",
        "\n",
        "                    #Checkpoint\n",
        "                    epoch_time = int(time.time() - self.tot_time) + self.elapsed_seconds\n",
        "                    val_dict = {\n",
        "                              'model_state_dict': self.model.state_dict(),\n",
        "                              'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                              'training_loss': training_loss,\n",
        "                              'validation_loss': validation_loss,\n",
        "                              'dict_metrics':self.dict_metrics,\n",
        "                              'elapsed_seconds': epoch_time\n",
        "                              }\n",
        "                    self.log_checkpoint(val_dict)\n",
        "\n",
        "            print(f\"Total training time: {time.time()-self.tot_time:.0f} sec\")\n",
        "\n",
        "            # Log model --> end run\n",
        "            mlflow.pytorch.log_model(self.model, artifact_path='model')\n",
        "            mlflow.end_run()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Exception thrown in class Wrapper, method train:\")\n",
        "            print(e)\n",
        "            print('\\n')\n",
        "            mlflow.end_run()\n",
        "\n",
        "        return training_loss, validation_loss\n",
        "\n",
        "\n",
        "\n",
        "    def __train(self, train_loader: DataLoader, epoch:int):\n",
        "\n",
        "        \"\"\" Train for an epoch \"\"\"\n",
        "\n",
        "        self.model.train()\n",
        "        train_batch_loss = []\n",
        "        train_steps = len(train_loader)\n",
        "\n",
        "        if(self.isgnn):\n",
        "\n",
        "            metrics = np.zeros((len(train_loader),3))\n",
        "            i = 0\n",
        "\n",
        "            for batch_mris, batch_graphs, batch_features, batch_labels in train_loader:\n",
        "\n",
        "                batch_graphs = batch_graphs.to(self.device)\n",
        "                batch_features = batch_features.to(self.device)\n",
        "                batch_labels = batch_labels.to(self.device)\n",
        "\n",
        "                logits = self.model(batch_graphs,batch_features)\n",
        "                logits = logits.to(self.device)\n",
        "                #_, predicted_classes = torch.max(logits, dim=1)\n",
        "                predicted_classes = logits.argmax(1)\n",
        "\n",
        "                loss = self.loss_fn(logits, batch_labels)\n",
        "                train_batch_loss.append(loss.detach().item())\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                metrics[i][:] = evaluation.calculate_node_dices(predicted_classes.detach().cpu().numpy(),\n",
        "                                                          batch_labels.detach().cpu().numpy())\n",
        "\n",
        "                i = i+1\n",
        "                out = f\"Epoch: {epoch}/{self.tot_epochs-1}, Step: {i+1}/{train_steps}, Training Loss: {loss.item():.4f}, Elapsed time: {time.time() - self.tot_time:.0f} sec \"\n",
        "                sys.stdout.write(\"\\r\" + out)\n",
        "                sys.stdout.flush()\n",
        "\n",
        "\n",
        "            print(metrics)\n",
        "            self.scheduler.step()\n",
        "            avg_metrics = np.mean(metrics,axis=0)\n",
        "\n",
        "            print(f\"train_wt_dice: {np.round(avg_metrics[0],4)}\")\n",
        "            print(f\"train_ct_dice: {np.round(avg_metrics[1],4)}\")\n",
        "            print(f\"train_at_dice: {np.round(avg_metrics[2],4)}\")\n",
        "\n",
        "            mlflow.log_metric('train_wt_dice', np.round(avg_metrics[0],4), step = epoch)\n",
        "            mlflow.log_metric('train_ct_dice', np.round(avg_metrics[1],4), step = epoch)\n",
        "            mlflow.log_metric('train_at_dice', np.round(avg_metrics[2],4), step = epoch)\n",
        "\n",
        "        else:\n",
        "\n",
        "            for i, (data,labels) in enumerate(train_loader):\n",
        "\n",
        "                #torch.cuda.empty_cache()\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                if self.device == 'cuda':\n",
        "                  data = data.type(torch.cuda.FloatTensor)\n",
        "                else:\n",
        "                  data = data.type(torch.FloatTensor)\n",
        "\n",
        "                data = data.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                outputs = self.model(data)\n",
        "\n",
        "                if(self.supervised):\n",
        "                  loss = self.loss_fn(outputs,labels)\n",
        "                else:\n",
        "                  loss = self.loss_fn(outputs, data)\n",
        "\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                train_batch_loss.append(loss.detach().item())\n",
        "\n",
        "                out = f\"Epoch: {epoch}/{self.tot_epochs-1}, Step: {i+1}/{train_steps}, Training Loss: {loss.item():.4f}, Elapsed time: {time.time() - self.tot_time:.0f} sec \"\n",
        "                sys.stdout.write(\"\\r\" + out)\n",
        "                sys.stdout.flush()\n",
        "            torch.cuda.empty_cache()\n",
        "            time.sleep(0.5)\n",
        "\n",
        "        return train_batch_loss\n",
        "\n",
        "\n",
        "    def __eval(self, val_loader: DataLoader, epoch:int):\n",
        "\n",
        "        \"\"\" Evaluate for an epoch \"\"\"\n",
        "\n",
        "        val_steps =  len(val_loader)\n",
        "        self.model.eval()\n",
        "        val_batch_loss = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            if(self.isgnn):\n",
        "\n",
        "                #metrics stores loss and node dices\n",
        "                metrics = np.zeros((len(val_loader),3))\n",
        "                i=0\n",
        "\n",
        "                for curr_id,batch_graphs,batch_feats,batch_labels in val_loader:\n",
        "\n",
        "                    batch_graphs = batch_graphs.to(self.device)\n",
        "                    batch_feats = torch.FloatTensor(batch_feats).to(self.device)\n",
        "                    batch_labels = torch.LongTensor(batch_labels).to(self.device)\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        logits = self.model(batch_graphs,batch_feats)\n",
        "                        val_loss = self.loss_fn(logits, batch_labels)\n",
        "\n",
        "                    val_batch_loss.append(val_loss.detach().item())\n",
        "                    #_, predicted_classes = torch.max(logits, dim=1)\n",
        "                    predicted_classes = logits.argmax(1)\n",
        "                    res = evaluation.calculate_node_dices(predicted_classes.detach().cpu().numpy(),\n",
        "                                                          batch_labels.detach().cpu().numpy())\n",
        "                    metrics[i][:] = res\n",
        "                    i+=1\n",
        "                    \n",
        "                    out = f\"Epoch: {epoch}/{self.tot_epochs-1}, Validation Step: {i+1}/{val_steps}, Validation Loss: {val_loss.item():.4f}, Elapsed time: {time.time() - self.tot_time:.0f} sec \"\n",
        "                    sys.stdout.write(\"\\r\" + out)\n",
        "                    sys.stdout.flush()\n",
        "                print(metrics)\n",
        "                avg_metrics = np.mean(metrics,axis=0)\n",
        "\n",
        "                print(f\"val_wt_dice: {np.round(avg_metrics[0],4)}\")\n",
        "                print(f\"val_ct_dice: {np.round(avg_metrics[1],4)}\")\n",
        "                print(f\"val_at_dice: {np.round(avg_metrics[2],4)}\")\n",
        "\n",
        "                mlflow.log_metric('val_wt_dice', np.round(avg_metrics[0],4), step = epoch)\n",
        "                mlflow.log_metric('val_ct_dice', np.round(avg_metrics[1],4), step = epoch)\n",
        "                mlflow.log_metric('val_at_dice', np.round(avg_metrics[2],4), step = epoch)\n",
        "\n",
        "                return val_batch_loss\n",
        "\n",
        "            else:\n",
        "                for i, (data,labels) in enumerate(val_loader):\n",
        "\n",
        "                  #torch.cuda.empty_cache()\n",
        "                  self.optimizer.zero_grad()\n",
        "\n",
        "                  if self.device == 'cuda':\n",
        "                    data = data.type(torch.cuda.FloatTensor)\n",
        "                  else:\n",
        "                    data = data.type(torch.FloatTensor)\n",
        "\n",
        "                  data = data.to(self.device)\n",
        "                  outputs = self.model(data)\n",
        "\n",
        "                  if(self.supervised):\n",
        "                      val_loss = self.loss_fn(outputs, labels)\n",
        "                  else:\n",
        "                      val_loss = self.loss_fn(outputs, data)\n",
        "\n",
        "                  val_batch_loss.append(val_loss.detach().item())\n",
        "\n",
        "                  out = f\"Epoch: {epoch}/{self.tot_epochs-1}, Validation Step: {i+1}/{val_steps}, Validation Loss: {val_loss.item():.4f}, Elapsed time: {time.time() - self.tot_time:.0f} sec \"\n",
        "                  sys.stdout.write(\"\\r\" + out)\n",
        "                  sys.stdout.flush()\n",
        "\n",
        "                torch.cuda.empty_cache()\n",
        "                time.sleep(.5)\n",
        "\n",
        "        return val_batch_loss\n",
        "\n",
        "\n",
        "    def __eval_metrics(self, data_loader:DataLoader):\n",
        "        \"\"\" Evaluates additional metrics aside the loss function \"\"\"\n",
        "        metrics_dict = {}\n",
        "        try:\n",
        "            self.model.eval()\n",
        "            if(self.eval_metrics is not None):\n",
        "\n",
        "                metrics_dict = {k.__class__.__name__:[] for k in self.eval_metrics}\n",
        "\n",
        "                with torch.no_grad():\n",
        "\n",
        "                    for i, (data,labels) in enumerate(data_loader):\n",
        "                        torch.cuda.empty_cache()\n",
        "                        self.optimizer.zero_grad()\n",
        "\n",
        "                        for metric in self.eval_metrics:\n",
        "\n",
        "                            if self.device == 'cuda':\n",
        "                                data = data.type(torch.cuda.FloatTensor)\n",
        "                            else:\n",
        "                                data = data.type(torch.FloatTensor)\n",
        "\n",
        "                            data = data.to(self.device)\n",
        "                            outputs = self.model(data)\n",
        "\n",
        "                            if(self.supervised):\n",
        "                                metric_value = metric(outputs, labels)\n",
        "                            else:\n",
        "                                metric_value = metric(outputs, data)\n",
        "\n",
        "                            metrics_dict[metric.__class__.__name__].append(metric_value.detach().item())\n",
        "\n",
        "                    for k in metrics_dict.keys():\n",
        "                        metrics_dict[k] = np.array(metrics_dict[k]).mean()\n",
        "\n",
        "        except Exception as e:\n",
        "            print('Exception thrown in wrapper.__eval_metrics')\n",
        "            print(e)\n",
        "        finally:\n",
        "            return metrics_dict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def predict_graph(self, val_loader:DataLoader):\n",
        "\n",
        "        \"\"\" Evaluate for an epoch \"\"\"\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "\n",
        "            #metrics stores loss,label counts, node dices,voxel dices,voxel hausdorff\n",
        "            metrics = np.zeros((len(dataset),3))\n",
        "\n",
        "            i=0\n",
        "            for curr_id,curr_graph,curr_feats,curr_labels in val_loader:\n",
        "\n",
        "                curr_graph = curr_graph.to(self.device)\n",
        "                curr_feats = torch.FloatTensor(curr_feats).to(self.device)\n",
        "                curr_labels = torch.LongTensor(curr_labels).to(self.device)\n",
        "\n",
        "                logits = self.model(curr_graph,curr_feats)\n",
        "                val_loss = self.loss_fn(logits, curr_labels)\n",
        "\n",
        "                _, predicted_classes = torch.max(logits, dim=1)\n",
        "                metrics[i] = evaluation.calculate_node_dices(predicted_classes.detach().cpu().numpy(),\n",
        "                                                      curr_labels.detach().cpu().numpy())\n",
        "                i+=1\n",
        "\n",
        "            avg_metrics = np.mean(metrics,axis=0)\n",
        "\n",
        "            return avg_metrics\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def predict_batch(self, data_loader:DataLoader):\n",
        "\n",
        "        output = []\n",
        "        self.model = self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            try:\n",
        "              for i, batch in enumerate(data_loader):\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "                if(len(batch) == 1):\n",
        "                  data = batch\n",
        "                else:\n",
        "                  data,label = batch\n",
        "\n",
        "                if self.device == 'cuda':\n",
        "                  data = data.type(torch.cuda.FloatTensor)\n",
        "                else:\n",
        "                  data = data.type(torch.FloatTensor)\n",
        "\n",
        "                data.to(self.device)\n",
        "\n",
        "                out = self.model(data)\n",
        "                out = out.cpu().detach().numpy()\n",
        "                output.append(out)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Exception thrown in class {self.model.__class__.__name__ }, method predict_batch:\")\n",
        "                print(e)\n",
        "                print('\\n')\n",
        "\n",
        "        return np.array(output)\n",
        "\n",
        "\n",
        "    def predict(self, data):\n",
        "\n",
        "        if device == 'cuda':\n",
        "          data = data.type(torch.cuda.FloatTensor)\n",
        "        else:\n",
        "          data = data.type(torch.FloatTensor)\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            data.to(device)\n",
        "            output = self.model(data)\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he-C8aZXQkry"
      },
      "source": [
        "## Loss ðŸ•³"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pUxP6_HiQiP8"
      },
      "outputs": [],
      "source": [
        "class Loss(nn.Module):\n",
        "    def __init__(self, focal):\n",
        "        super(Loss, self).__init__()\n",
        "        if focal:\n",
        "            self.loss_fn = DiceFocalLoss(\n",
        "                include_background=False, softmax=True, to_onehot_y=True, batch=True, gamma=2.0\n",
        "            )\n",
        "        else:\n",
        "            self.loss_fn = DiceCELoss(include_background=False, softmax=True, to_onehot_y=True, batch=True)\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        return self.loss_fn(y_pred, y_true)\n",
        "\n",
        "\n",
        "class LossBraTS(nn.Module):\n",
        "    def __init__(self, focal):\n",
        "        super(LossBraTS, self).__init__()\n",
        "        self.dice = DiceLoss(sigmoid=True, batch=True)\n",
        "        self.ce = FocalLoss(gamma=2.0, to_onehot_y=False) if focal else nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def _loss(self, p, y):\n",
        "\n",
        "        return self.dice(p, y) + self.ce(p, y.float())\n",
        "\n",
        "    def forward(self, p, y):\n",
        "        print('p '+str(p.size()))\n",
        "        print('y '+str(y.size()))\n",
        "        y_wt, y_tc, y_et = y > 0, ((y == 1) + (y == 3)) > 0, y == 3\n",
        "        p_wt, p_tc, p_et = p[:, 0].unsqueeze(1), p[:, 1].unsqueeze(1), p[:, 2].unsqueeze(1)\n",
        "        l_wt, l_tc, l_et = self._loss(p_wt, y_wt), self._loss(p_tc, y_tc), self._loss(p_et, y_et)\n",
        "        return l_wt + l_tc + l_et"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsRN0nOwDif5"
      },
      "source": [
        "## Build dataset ðŸ—"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9m9XrfCJDqWy"
      },
      "outputs": [],
      "source": [
        "dotenv_path = \"/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/.env\"\n",
        "load_dotenv(dotenv_path)\n",
        "\n",
        "\n",
        "INPUT_PATH = os.getenv(\"INPUT_DATA_DIR\")\n",
        "PROCESSED_PATH = os.getenv('PROCESSED_DATA_DIR')\n",
        "INPUT_PATH_PARENT = '/'.join(INPUT_PATH.split('/')[:-1])\n",
        "\n",
        "TRAIN_PATH = os.path.join(INPUT_PATH_PARENT,'train')\n",
        "VAL_PATH = os.path.join(INPUT_PATH_PARENT,'val')\n",
        "TEST_PATH = os.path.join(INPUT_PATH_PARENT,'test')\n",
        "\n",
        "TAR_PATH = os.path.join(INPUT_PATH_PARENT,'BraTS2021_Training_Data.tar')\n",
        "BUILD_DATASET = False\n",
        "\n",
        "if(BUILD_DATASET):\n",
        "  untar_brats(tar_path = '/content/drive/MyDrive/Lorusso/BraTS/data/raw/BraTS2021_Training_Data.tar', extract_path = INPUT_PATH )\n",
        "  #dataset = DataPreprocessor()\n",
        "  #dataset.split_dataset()\n",
        "\n",
        "#dataset = DataPreprocessor()\n",
        "#train_loader = DataLoader(dataset, sampler = SeqSampler(dataset), batch_size = 1, num_workers = 0)\n",
        "#images, labels= next(iter(train_loader))\n",
        "#plot_brain_sections([images[0], labels[0]])\n",
        "#del images, labels, train_loader, dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59tr9TkL0zF3"
      },
      "source": [
        "# Generate Graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkZZCxM101ZL",
        "outputId": "1fd0fcfb-38f9-4e2e-bc1b-47332991a47e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MRIs to convert:14\n",
            "Pending conversions: 0\n",
            "Converting BraTS2021_00030\n",
            "Converting BraTS2021_00016\n",
            "Converting BraTS2021_00026\n",
            "Converting BraTS2021_00025\n",
            "Converting BraTS2021_00024\n",
            "Set up Threads, starting execution\n",
            "Converting BraTS2021_00031\n",
            "Converting BraTS2021_00018\n",
            "Converting BraTS2021_00019\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages/pydantic/_internal/_config.py:321: UserWarning: Valid config keys have changed in V2:\n",
            "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
            "  warnings.warn(message, UserWarning)\n",
            "[2024-01-11 14:24:02 +0100] [81600] [INFO] Starting gunicorn 21.2.0\n",
            "[2024-01-11 14:24:02 +0100] [81600] [ERROR] Connection in use: ('127.0.0.1', 5000)\n",
            "[2024-01-11 14:24:02 +0100] [81600] [ERROR] Retrying in 1 second.\n",
            "[2024-01-11 14:24:03 +0100] [81600] [ERROR] Connection in use: ('127.0.0.1', 5000)\n",
            "[2024-01-11 14:24:03 +0100] [81600] [ERROR] Retrying in 1 second.\n",
            "[2024-01-11 14:24:04 +0100] [81600] [ERROR] Connection in use: ('127.0.0.1', 5000)\n",
            "[2024-01-11 14:24:04 +0100] [81600] [ERROR] Retrying in 1 second.\n",
            "[2024-01-11 14:24:05 +0100] [81600] [ERROR] Connection in use: ('127.0.0.1', 5000)\n",
            "[2024-01-11 14:24:05 +0100] [81600] [ERROR] Retrying in 1 second.\n",
            "[2024-01-11 14:24:06 +0100] [81600] [ERROR] Connection in use: ('127.0.0.1', 5000)\n",
            "[2024-01-11 14:24:06 +0100] [81600] [ERROR] Retrying in 1 second.\n",
            "[2024-01-11 14:24:07 +0100] [81600] [ERROR] Can't connect to ('127.0.0.1', 5000)\n",
            "Running the mlflow server failed. Please see the logs above for details.\n",
            "/Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages/scipy/ndimage/_measurements.py:1535: RuntimeWarning: invalid value encountered in divide\n",
            "  results = [sum(input * grids[dir].astype(float), labels, index) / normalizer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished BraTS2021_00016Converting BraTS2021_00020\n",
            "\n",
            "Finished BraTS2021_00018\n",
            "Converting BraTS2021_00022\n",
            "Finished BraTS2021_00031\n",
            "Converting BraTS2021_00032\n",
            "Finished BraTS2021_00024\n",
            "Converting BraTS2021_00028\n",
            "Finished BraTS2021_00025\n",
            "Converting BraTS2021_00021\n",
            "Finished BraTS2021_00019\n",
            "Converting BraTS2021_00017\n",
            "Finished BraTS2021_00030\n",
            "Finished BraTS2021_00026\n",
            "Finished BraTS2021_00020\n",
            "Finished BraTS2021_00022\n",
            "Finished BraTS2021_00021\n",
            "Finished BraTS2021_00028\n",
            "Finished BraTS2021_00032\n",
            "Finished BraTS2021_00017\n"
          ]
        }
      ],
      "source": [
        "#dataset = DataPreprocessor(INPUT_PATH = '/content/drive/MyDrive/Lorusso/BraTS/data/raw/BraTS2023-Test', label_extension = None,  mri_prefix = 'BraTS-GLI-', modality_extensions = ['-t1c.nii.gz', '-t1n.nii.gz', '-t2f.nii.gz', '-t2w.nii.gz'], force_conversion = False)\n",
        "IMG2GRAPH = False\n",
        "if(IMG2GRAPH):\n",
        "    dataset = DataPreprocessor(INPUT_PATH = '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/raw/sampled', force_conversion = True)\n",
        "    if(not set(dataset.get_status_ids()['Finished']).issuperset(set(dataset.all_ids))):\n",
        "        ids_to_convert = list(set(dataset.all_ids).difference(set(dataset.get_status_ids()['Finished'])))\n",
        "        print('MRIs to convert:'+ str(len(ids_to_convert)))\n",
        "        dataset.all_ids = ids_to_convert\n",
        "        print(f\"Pending conversions: {len(set(dataset.get_status_ids()['Pending']))}\")\n",
        "        dataset.run()\n",
        "        dataset = DataPreprocessor(INPUT_PATH = '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_15000_0.5_0/sampled', force_conversion = True)\n",
        "        dataset.split_dataset(fixed=(10,4,0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz-6k-tLLDbh"
      },
      "source": [
        "# Train and predict âŒ›"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dle5EmF9LXms"
      },
      "source": [
        "## Autoencoder v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UZ5ItOcISTzW"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'LOAD_MODEL' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m      5\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(TRAIN_MODEL \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mLOAD_MODEL\u001b[49m):\n\u001b[1;32m      7\u001b[0m   num_workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      8\u001b[0m   batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'LOAD_MODEL' is not defined"
          ]
        }
      ],
      "source": [
        "TRAIN_MODEL = False\n",
        "LOAD_MODEL = False\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "time.sleep(5)\n",
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "  num_workers = 0\n",
        "  batch_size = 1\n",
        "  num_epochs = 1\n",
        "  lr = 0.005\n",
        "  supervised = False\n",
        "\n",
        "  # MONAI AUTOENCODER\n",
        "  model = AutoEncoder(\n",
        "         spatial_dims=3,\n",
        "         kernel_size = 3,\n",
        "         up_kernel_size = 3,\n",
        "         in_channels=4,\n",
        "         out_channels=4,\n",
        "         channels=(5,),\n",
        "         strides=(2,),\n",
        "         inter_channels=(8, 16, 32),\n",
        "         inter_dilations=(1, 2, 4),\n",
        "         num_inter_units=2\n",
        "     )\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=1e-10)\n",
        "  loss_fn = nn.MSELoss() #SSIMLoss(spatial_dims=3)\n",
        "\n",
        "  wrapper = ModelWrapper(model = model,\n",
        "                            loss_fn = loss_fn,\n",
        "                            optimizer = optimizer,\n",
        "                            supervised = supervised,\n",
        "                            num_epochs = num_epochs,\n",
        "                            LOAD_MODEL = LOAD_MODEL\n",
        "                        )\n",
        "\n",
        "  dataset = DataPreprocessor(INPUT_PATH = INPUT_PATH)\n",
        "\n",
        "  # Split dataset if it's not\n",
        "  if(not os.path.exists(TRAIN_PATH)):\n",
        "    dataset.split_dataset()\n",
        "\n",
        "\n",
        "  train_dataset = DataPreprocessor(INPUT_PATH = TRAIN_PATH)\n",
        "  val_dataset = DataPreprocessor(INPUT_PATH = VAL_PATH)\n",
        "  test_dataset = DataPreprocessor(INPUT_PATH = TEST_PATH)\n",
        "\n",
        "  train_loader = DataLoader(dataset = train_dataset,\n",
        "                           sampler = SeqSampler(train_dataset),\n",
        "                           batch_size = batch_size,\n",
        "                           num_workers = num_workers)\n",
        "\n",
        "  val_loader = DataLoader(dataset = val_dataset,\n",
        "                           sampler = SeqSampler(val_dataset),\n",
        "                           batch_size = batch_size,\n",
        "                           num_workers = num_workers)\n",
        "\n",
        "  test_loader = DataLoader(dataset = test_dataset,\n",
        "                           sampler = SeqSampler(test_dataset),\n",
        "                           batch_size = batch_size,\n",
        "                           num_workers = num_workers)\n",
        "\n",
        "\n",
        "  print('Elapsed epochs: ' + str(wrapper.elapsed_epochs))\n",
        "\n",
        "if(TRAIN_MODEL):\n",
        "      training_loss, validation_loss = wrapper.train(train_loader = train_loader, val_loader = val_loader )\n",
        "      torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bo0aQf08rHvn"
      },
      "outputs": [],
      "source": [
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "  xx = range(1,wrapper.elapsed_epochs+1)\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.plot(xx, wrapper.training_loss, '-o', label = 'Train')\n",
        "  plt.plot(xx, wrapper.validation_loss,'-o', label = 'Val')\n",
        "  plt.legend(loc='lower left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvvSdXEvIw5w"
      },
      "outputs": [],
      "source": [
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "\n",
        "  slice_index = 100\n",
        "  ax = 0\n",
        "\n",
        "  im_test, lab = next(iter(val_loader))\n",
        "  output = wrapper.predict(data = im_test)\n",
        "  out = output[0]\n",
        "  out_numpy = out.cpu().detach().numpy()\n",
        "  im_test_numpy = im_test.cpu().detach().numpy()\n",
        "  print(np.shape(im_test_numpy))\n",
        "\n",
        "  plot_reconstruction(im_orig = np.sum(im_test_numpy[0], axis=0), im_rec = np.sum(out_numpy, axis = 0), ax = ax, slice_index = slice_index)\n",
        "  plot_brain_sections([im_test[0], lab[0]], ax = ax, slice_index = slice_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETwFBvf1Zjyp"
      },
      "outputs": [],
      "source": [
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "  ker = wrapper.model.decode[0][0][0].weight.detach().clone()\n",
        "  print(ker.size())\n",
        "  #\n",
        "  visTensor(ker[0], allkernels=True)\n",
        "\n",
        "  ker = wrapper.model.decode[0][0][0].weight.detach().clone()\n",
        "  print(ker.size())\n",
        "  #\n",
        "  visTensor(torch.sum(ker, dim=(0)), allkernels=True)\n",
        "\n",
        "  kk = torch.sum(ker, dim= 0)\n",
        "  kk = torch.sum(kk, dim = 0)\n",
        "  plt.imshow(kk[0,:,:].cpu().detach().numpy())\n",
        "\n",
        "  # Sum over the channels\n",
        "  #ker =ker.sum(axis=(0,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CScy9Z1UXCD2"
      },
      "outputs": [],
      "source": [
        "#import torch.nn.functional as F\n",
        "#im_test, lab = next(iter(test_loader))\n",
        "#ker = wrapper.model.decode[0][0][0].weight.detach().clone()\n",
        "#print(ker.size(), im_test.size())\n",
        "##ker =ker.sum(axis=0)\n",
        "##im_test = im_test.sum(axis=0)\n",
        "#result = F.conv3d(im_test,ker)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNn9uFyniXlr"
      },
      "source": [
        "## GNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtS7HG4ciZi5",
        "outputId": "68b0ae4c-eb97-44c9-b107-4191e4189ff8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 10 MRIs\n",
            "Found 4 MRIs\n",
            "Found 0 MRIs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed epochs: 0\n",
            "Epoch: 1/5, Step: 5/4, Training Loss: 6.4229, Elapsed time: 82 sec  [[0.08235486 0.         0.        ]\n",
            " [0.         0.         0.        ]\n",
            " [0.45662461 0.09549338 0.07322034]\n",
            " [0.10242942 0.02976612 0.02976612]]\n",
            "train_wt_dice: 0.1604\n",
            "train_ct_dice: 0.0313\n",
            "train_at_dice: 0.0257\n",
            "Epoch: 1/5, Loss: 16.0409, Epoch elapsed time: 82 sec \n",
            "\n",
            "Epoch: 1/5, Validation Step: 3/2, Validation Loss: 10.8366, Elapsed time: 103 sec [[0.03357817 0.22413793 0.21428571]\n",
            " [0.         0.         0.        ]]\n",
            "val_wt_dice: 0.0168\n",
            "val_ct_dice: 0.1121\n",
            "val_at_dice: 0.1071\n",
            "Epoch: 1/5, Validation Loss: 9.6440, Elapsed time: 103 sec\n",
            "\n",
            "Epoch: 2/5, Step: 5/4, Training Loss: 3.2028, Elapsed time: 166 sec [[0.33634126 0.4776699  0.33890215]\n",
            " [0.59847573 0.33893557 0.        ]\n",
            " [0.48200758 0.11581861 0.54811715]\n",
            " [0.04759423 0.00665419 0.00665419]]\n",
            "train_wt_dice: 0.3661\n",
            "train_ct_dice: 0.2348\n",
            "train_at_dice: 0.2234\n",
            "Epoch: 2/5, Loss: 5.0081, Epoch elapsed time: 63 sec \n",
            "\n",
            "Epoch: 2/5, Validation Step: 3/2, Validation Loss: 5.1906, Elapsed time: 183 sec [[0.34569067 0.         0.        ]\n",
            " [0.71543408 0.         0.        ]]\n",
            "val_wt_dice: 0.5306\n",
            "val_ct_dice: 0.0\n",
            "val_at_dice: 0.0\n",
            "Epoch: 2/5, Validation Loss: 3.1824, Elapsed time: 80 sec\n",
            "\n",
            "Epoch: 3/5, Step: 5/4, Training Loss: 1.1992, Elapsed time: 247 sec [[0.54820187 0.         0.        ]\n",
            " [0.72406915 0.         0.        ]\n",
            " [0.02261048 0.         0.        ]\n",
            " [0.09722222 0.         0.        ]]\n",
            "train_wt_dice: 0.348\n",
            "train_ct_dice: 0.0\n",
            "train_at_dice: 0.0\n",
            "Epoch: 3/5, Loss: 2.7349, Epoch elapsed time: 63 sec \n",
            "\n",
            "Epoch: 3/5, Validation Step: 3/2, Validation Loss: 5.1193, Elapsed time: 265 sec [[0.50237417 0.         0.        ]\n",
            " [0.47234679 0.01333333 0.01762115]]\n",
            "val_wt_dice: 0.4874\n",
            "val_ct_dice: 0.0067\n",
            "val_at_dice: 0.0088\n",
            "Epoch: 3/5, Validation Loss: 2.9875, Elapsed time: 81 sec\n",
            "\n",
            "Epoch: 4/5, Step: 5/4, Training Loss: 1.3112, Elapsed time: 326 sec [[0.72125813 0.51669596 0.4397463 ]\n",
            " [0.49291101 0.56785714 0.54378819]\n",
            " [0.57064304 0.375      0.30178069]\n",
            " [0.07038274 0.04096834 0.04096834]]\n",
            "train_wt_dice: 0.4638\n",
            "train_ct_dice: 0.3751\n",
            "train_at_dice: 0.3316\n",
            "Epoch: 4/5, Loss: 1.3361, Epoch elapsed time: 60 sec \n",
            "\n",
            "Epoch: 4/5, Validation Step: 3/2, Validation Loss: 2.7991, Elapsed time: 337 sec [[0.41770137 0.07103321 0.06746765]\n",
            " [0.74306839 0.5584563  0.44059406]]\n",
            "val_wt_dice: 0.5804\n",
            "val_ct_dice: 0.3147\n",
            "val_at_dice: 0.254\n",
            "Epoch: 4/5, Validation Loss: 1.8835, Elapsed time: 72 sec\n",
            "\n",
            "Epoch: 5/5, Step: 5/4, Training Loss: 0.5567, Elapsed time: 398 sec [[0.65341995 0.31501832 0.22589532]\n",
            " [0.71458011 0.40172786 0.32272727]\n",
            " [0.62822252 0.3567753  0.28623519]\n",
            " [0.19230769 0.21052632 0.21052632]]\n",
            "train_wt_dice: 0.5471\n",
            "train_ct_dice: 0.321\n",
            "train_at_dice: 0.2613\n",
            "Epoch: 5/5, Loss: 1.4633, Epoch elapsed time: 60 sec \n",
            "\n",
            "Epoch: 5/5, Validation Step: 3/2, Validation Loss: 3.3312, Elapsed time: 416 sec [[0.54788657 0.         0.        ]\n",
            " [0.45288754 0.         0.        ]]\n",
            "val_wt_dice: 0.5004\n",
            "val_ct_dice: 0.0\n",
            "val_at_dice: 0.0\n",
            "Epoch: 5/5, Validation Loss: 2.1143, Elapsed time: 79 sec\n",
            "\n",
            "Total training time: 417 sec\n"
          ]
        }
      ],
      "source": [
        "## SE IMPOSTO BATCH SIZE A 1 OTTENGO I GIUSTI RISULTATI!!\n",
        "## IL PROBLEMA Ãˆ METRICS SU CUI CALCOLO IN MANIERA SBAGLIATA LA MEDIA!!\n",
        "## INIZIALIZZARE LA LUNGHEZZA DELLA VARIABILE METRICS CON LEN(TRAIN/VAL_LOADER) AL POSTO DI LEN(TRAIN/VAL_LOADER.DATASET)\n",
        "\n",
        "\n",
        "import torch.nn.functional as F\n",
        "INPUT_PATH = '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_15000_0.5_0'\n",
        "\n",
        "TRAIN_PATH = os.path.join(INPUT_PATH,'train')\n",
        "VAL_PATH = os.path.join(INPUT_PATH,'val')\n",
        "TEST_PATH = os.path.join(INPUT_PATH,'test') # set to 'test' in production\n",
        "\n",
        "\n",
        "train_dataset = ImageGraphDataset(TRAIN_PATH,'BraTS2021',read_image=False,read_graph=True,read_label=True)\n",
        "val_dataset = ImageGraphDataset(VAL_PATH,'BraTS2021',read_image=False,read_graph=True,read_label=True)\n",
        "test_dataset = ImageGraphDataset(TEST_PATH,'BraTS2021',read_image=False,read_graph=True,read_label=True)\n",
        "\n",
        "\n",
        "TRAIN_MODEL = True\n",
        "LOAD_MODEL = False # resume training\n",
        "\n",
        "supervised = True\n",
        "eval_metrics = None\n",
        "num_workers = 0\n",
        "\n",
        "batch_size = 3\n",
        "num_epochs = 5\n",
        "lr = 5e-4\n",
        "dropout = 0\n",
        "input_feats = 20\n",
        "class_weights = torch.Tensor([0.2,1,2,3]).to(device) #compute_average_weights(val_dataset) #\n",
        "layer_sizes=[640]*4\n",
        "n_classes=4\n",
        "aggregator_type='pool'\n",
        "\n",
        "#heads = [128]*3\n",
        "#residuals = [128]*3\n",
        "heads = [8, 8, 8, 8, 8, 8]\n",
        "residuals = [False, True, True, False, True, True]\n",
        "activation = F.relu\n",
        "val_dropout = 0.02\n",
        "val_feat_drop = 0.2\n",
        "val_attn_drop = 0.2\n",
        "\n",
        "\n",
        "dict_params = {k:eval(k) for k in ['dropout','input_feats', 'class_weights', 'layer_sizes', 'n_classes', 'aggregator_type', 'n_classes', 'heads', 'residuals']}\n",
        "model = GraphSage(in_feats=input_feats,\n",
        "                  layer_sizes=layer_sizes,\n",
        "                  n_classes=n_classes,\n",
        "                  aggregator_type=aggregator_type,\n",
        "                  dropout=dropout)\n",
        "\n",
        "#model = GAT(in_feats = input_feats, layer_sizes = layer_sizes, n_classes=n_classes,heads = heads, residuals = residuals, activation = activation,  feat_drop = val_feat_drop, attn_drop = val_attn_drop)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(),lr=lr,weight_decay=1e-4)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "#loss_fn = LossBraTS(focal=False)\n",
        "\n",
        "wrapper = ModelWrapper(model = model,\n",
        "                            loss_fn = loss_fn,\n",
        "                            optimizer = optimizer,\n",
        "                            supervised = supervised,\n",
        "                            dict_params = dict_params,\n",
        "                            isgnn = True,\n",
        "                            num_epochs = num_epochs,\n",
        "                            LOAD_MODEL = LOAD_MODEL,\n",
        "                            eval_metrics = eval_metrics\n",
        "                          )\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dataset = train_dataset,\n",
        "                             batch_size = batch_size,\n",
        "                             num_workers = num_workers,\n",
        "                              collate_fn=minibatch_graphs)\n",
        "\n",
        "val_loader = DataLoader(dataset = val_dataset,\n",
        "                             batch_size = batch_size,\n",
        "                             num_workers = num_workers,\n",
        "                              collate_fn=minibatch_graphs)\n",
        "\n",
        "\n",
        "\n",
        "print('Elapsed epochs: ' + str(wrapper.elapsed_epochs))\n",
        "\n",
        "if(TRAIN_MODEL):\n",
        "    training_loss, validation_loss = wrapper.train(train_loader = train_loader, val_loader = val_loader )\n",
        "    #torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_J8e-G2cJQxr"
      },
      "outputs": [],
      "source": [
        "def rm_run(run_id, experiment = '134912204135972352',):\n",
        "    rm_path = '/content/drive/MyDrive/Lorusso/BraTS/mlruns/'+experiment+'/'+run_id\n",
        "    shutil.rmtree(rm_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1_TRMmsm6jY"
      },
      "source": [
        "# TESTING SECTION ðŸš§"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bC-ortIQ3vXX"
      },
      "outputs": [],
      "source": [
        "#! rm -r /content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled\n",
        "#! rm -r /content/drive/MyDrive/Lorusso/BraTS/data/interim/train\n",
        "#! rm -r /content/drive/MyDrive/Lorusso/BraTS/data/interim/test\n",
        "#! rm -r /content/drive/MyDrive/Lorusso/BraTS/data/interim/val\n",
        "\n",
        "\n",
        "\n",
        "#trainset = set()\n",
        "#valset = set()\n",
        "#testset = set()\n",
        "#for el in dp.get_status_ids()['Pending']:\n",
        "#    if(el in train_dataset.all_ids):\n",
        "#        trainset.add(el)\n",
        "#    if(el in val_dataset.all_ids):\n",
        "#        valset.add(el)\n",
        "#    if(el in test_dataset.all_ids):\n",
        "#        testset.add(el)\n",
        "#\n",
        "#\n",
        "#for el in valset:\n",
        "#    src = VAL_PATH+'/'+str(el)\n",
        "#    dst = '/content/drive/MyDrive/Lorusso/BraTS/data/processed_5000_0.5_10/brats/'+el\n",
        "#    shutil.copytree(src, dst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJUctzmLazd9"
      },
      "source": [
        "## Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHHzhDDF_3G9"
      },
      "outputs": [],
      "source": [
        "\n",
        "TEST_MODE = False\n",
        "\n",
        "\n",
        "if(TEST_MODE):\n",
        "\n",
        "    INPUT_PATH = '/content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled'\n",
        "    INPUT_PATH_PARENT = '/'.join(INPUT_PATH.split('/')[:-1])\n",
        "    TRAIN_PATH = os.path.join(INPUT_PATH_PARENT,'train')\n",
        "    VAL_PATH = os.path.join(INPUT_PATH_PARENT,'val')\n",
        "    TEST_PATH = os.path.join(INPUT_PATH_PARENT,'test')\n",
        "\n",
        "    TRAIN_MODEL = False\n",
        "    LOAD_MODEL = True # resume training\n",
        "\n",
        "    num_workers = 0\n",
        "    batch_size = 1\n",
        "    num_epochs = 2\n",
        "    lr = 0.01\n",
        "    supervised = False\n",
        "    eval_metrics = [nn.MSELoss()]\n",
        "\n",
        "  # MONAI AUTOENCODER\n",
        "    model = AutoEncoder(\n",
        "           spatial_dims=3,\n",
        "           kernel_size = 3,\n",
        "           up_kernel_size = 3,\n",
        "           in_channels=4,\n",
        "           out_channels=4,\n",
        "           channels=(5,),\n",
        "           strides=(2,),\n",
        "           inter_channels=(8, 16, 32),\n",
        "           inter_dilations=(1, 2, 4),\n",
        "           num_inter_units=2\n",
        "       )\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=1e-10)\n",
        "    loss_fn = nn.MSELoss() #SSIMLoss(spatial_dims=3)\n",
        "\n",
        "    wrapper = ModelWrapper(model = model,\n",
        "                              loss_fn = loss_fn,\n",
        "                              optimizer = optimizer,\n",
        "                              supervised = supervised,\n",
        "                              num_epochs = num_epochs,\n",
        "                              LOAD_MODEL = LOAD_MODEL,\n",
        "                              eval_metrics = eval_metrics\n",
        "                          )\n",
        "\n",
        "    dataset = DataPreprocessor(INPUT_PATH = INPUT_PATH)\n",
        "\n",
        "    # Split dataset if it's not\n",
        "    if(not os.path.exists(TRAIN_PATH)):\n",
        "      dataset.split_dataset()\n",
        "\n",
        "\n",
        "    train_dataset = DataPreprocessor(INPUT_PATH = TRAIN_PATH)\n",
        "    val_dataset = DataPreprocessor(INPUT_PATH = VAL_PATH)\n",
        "    test_dataset = DataPreprocessor(INPUT_PATH = TEST_PATH)\n",
        "\n",
        "    train_loader = DataLoader(dataset = train_dataset,\n",
        "                             sampler = SeqSampler(train_dataset),\n",
        "                             batch_size = batch_size,\n",
        "                             num_workers = num_workers)\n",
        "\n",
        "    val_loader = DataLoader(dataset = val_dataset,\n",
        "                             sampler = SeqSampler(val_dataset),\n",
        "                             batch_size = batch_size,\n",
        "                             num_workers = num_workers)\n",
        "\n",
        "    test_loader = DataLoader(dataset = test_dataset,\n",
        "                             sampler = SeqSampler(test_dataset),\n",
        "                             batch_size = batch_size,\n",
        "                             num_workers = num_workers)\n",
        "\n",
        "\n",
        "    print('Elapsed epochs: ' + str(wrapper.elapsed_epochs))\n",
        "\n",
        "    if(TRAIN_MODEL):\n",
        "        training_loss, validation_loss = wrapper.train(train_loader = train_loader, val_loader = val_loader, experiment_prefix = 'Test' )\n",
        "        torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcuxwsmW9OYS"
      },
      "outputs": [],
      "source": [
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "  xx = range(1,wrapper.elapsed_epochs+1)\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.plot(xx, wrapper.training_loss, '-o', label = 'Train')\n",
        "  plt.plot(xx, wrapper.validation_loss,'-o', label = 'Val')\n",
        "  plt.legend(loc='lower left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3TKi4A9O4NA"
      },
      "outputs": [],
      "source": [
        "if(False):\n",
        "\n",
        "  slice_index = 90\n",
        "  ax = 0\n",
        "\n",
        "  im_test, lab = next(iter(test_loader))\n",
        "  output = wrapper.predict(data = im_test)\n",
        "  out = output[0]\n",
        "  out_numpy = out.cpu().detach().numpy()\n",
        "  im_test_numpy = im_test.cpu().detach().numpy()\n",
        "\n",
        "  plot_reconstruction(im_orig = np.sum(im_test_numpy[0], axis=0), im_rec = np.sum(out_numpy, axis = 0), ax = ax, slice_index = slice_index)\n",
        "  plot_brain_sections([im_test[0], lab[0]], ax = ax, slice_index = slice_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5fwjWaWOhXN"
      },
      "outputs": [],
      "source": [
        "if(False):\n",
        "  ker = wrapper.model.decode[0][0][0].weight.detach().clone()\n",
        "  print(ker.size())\n",
        "  #\n",
        "  visTensor(ker[1], allkernels=True)\n",
        "\n",
        "  ker = wrapper.model.decode[0][0][0].weight.detach().clone()\n",
        "  print(ker.size())\n",
        "  #\n",
        "  visTensor(torch.sum(ker, dim=(0)), allkernels=True)\n",
        "\n",
        "  kk = torch.sum(ker, dim= 0)\n",
        "  kk = torch.sum(kk, dim = 0)\n",
        "  plt.imshow(kk[0,:,:].cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGPCqWQcrPqb"
      },
      "source": [
        "## Feature extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-lpiQp3XNxn"
      },
      "source": [
        "## GNN training â›½"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVWsu1gEXV9j"
      },
      "outputs": [],
      "source": [
        "\n",
        "TEST_MODE = False\n",
        "\n",
        "\n",
        "if(TEST_MODE):\n",
        "\n",
        "    INPUT_PATH = '/content/drive/MyDrive/Lorusso/BraTS/data/processed_5000_0.5_10'\n",
        "    TRAIN_PATH = os.path.join(INPUT_PATH,'train')\n",
        "    VAL_PATH = os.path.join(INPUT_PATH,'val')\n",
        "    TEST_PATH = os.path.join(INPUT_PATH,'val') # set again to 'test' in production\n",
        "\n",
        "    TRAIN_MODEL = True\n",
        "    LOAD_MODEL = False # resume training\n",
        "\n",
        "    num_workers = 0\n",
        "    batch_size = 1\n",
        "    num_epochs = 2\n",
        "    lr = 0.005\n",
        "    supervised = True\n",
        "    eval_metrics = []\n",
        "\n",
        "    dropout = 0\n",
        "    input_feats = 20\n",
        "    class_weights = torch.Tensor([0.1,1,2,2])\n",
        "    layer_sizes=[256]*4\n",
        "    n_classes=4\n",
        "    aggregator_type='pool'\n",
        "\n",
        "    dict_params = {k:eval(k) for k in ['input_feats', 'class_weights', 'layer_sizes', 'n_classes', 'aggregator_type', 'n_classes']}\n",
        "\n",
        "    model = GraphSage(in_feats=input_feats,layer_sizes=layer_sizes,n_classes=n_classes,aggregator_type=aggregator_type,dropout=dropout)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(),lr=lr,weight_decay=1e-10)\n",
        "    loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "    wrapper = ModelWrapper(model = model,\n",
        "                            loss_fn = loss_fn,\n",
        "                            optimizer = optimizer,\n",
        "                            supervised = supervised,\n",
        "                            dict_params = dict_params,\n",
        "                            isgnn = True,\n",
        "                            num_epochs = num_epochs,\n",
        "                            LOAD_MODEL = LOAD_MODEL,\n",
        "                            eval_metrics = eval_metrics\n",
        "                          )\n",
        "\n",
        "\n",
        "    train_dataset = ImageGraphDataset(VAL_PATH,'BraTS2021',read_image=False,read_graph=True,read_label=True)\n",
        "    #val_dataset = ImageGraphDataset(VAL_PATH,'BraTS2021',read_image=False,read_graph=True,read_label=True)\n",
        "    #test_dataset = ImageGraphDataset(TEST_PATH,'BraTS2021',read_image=False,read_graph=True,read_label=True)\n",
        "\n",
        "    train_loader = DataLoader(dataset = train_dataset,\n",
        "                             batch_size = batch_size,\n",
        "                             num_workers = num_workers,\n",
        "                              collate_fn=minibatch_graphs)\n",
        "\n",
        "\n",
        "    print('Elapsed epochs: ' + str(wrapper.elapsed_epochs))\n",
        "\n",
        "    if(TRAIN_MODEL):\n",
        "        training_loss, validation_loss = wrapper.train(train_loader = train_loader, val_loader = train_loader, experiment_prefix = 'Test_GNN' )\n",
        "        torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVH1teeglI4t"
      },
      "source": [
        "# MLFlow transitioner\n",
        "\n",
        "Helps to export to MLFlow a model saved with pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xjPxt_lhQ7z"
      },
      "outputs": [],
      "source": [
        "if(False):\n",
        "    checkpoint = torch.load(wrapper.save_path, map_location=torch.device(wrapper.device))\n",
        "    wrapper.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    wrapper.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    wrapper.elapsed_epochs = checkpoint['epochs']\n",
        "    wrapper.training_loss = checkpoint['training_loss']\n",
        "    wrapper.validation_loss = checkpoint['validation_loss']\n",
        "    wrapper.elapsed_seconds = checkpoint['elapsed_seconds']\n",
        "    try:\n",
        "        mlflow.set_experiment('BraTS_'+wrapper.model.__class__.__name__)\n",
        "        mlflow.start_run()\n",
        "        param_dict = {\n",
        "            'batch_size':train_loader.batch_size,\n",
        "            'optimizer':wrapper.optimizer.__class__.__name__,\n",
        "            'learning_rate':wrapper.optimizer.state_dict()['param_groups'][0]['lr'],\n",
        "            'loss_fn':wrapper.loss_fn.__class__.__name__\n",
        "        }\n",
        "        mlflow.log_params(param_dict)\n",
        "\n",
        "        #sample_input,_ = next(iter(train_loader))\n",
        "        #sample_output = wrapper.predict(sample_input)\n",
        "        #signature = infer_signature(sample_input.numpy(), sample_output.numpy())\n",
        "    #\n",
        "        #print(\"Model signature:\", signature)\n",
        "\n",
        "        for i in range(len(wrapper.training_loss)):\n",
        "            mlflow.log_metric('train_loss',wrapper.training_loss[i], step =i+1)\n",
        "        for i in range(len(wrapper.validation_loss)):\n",
        "            mlflow.log_metric('val_loss',wrapper.validation_loss[i], step =i+1)\n",
        "\n",
        "        val_dict = {\n",
        "              'model_state_dict': wrapper.model.state_dict(),\n",
        "              'optimizer_state_dict': wrapper.optimizer.state_dict(),\n",
        "              'elapsed_seconds': wrapper.elapsed_seconds,\n",
        "              'training_loss':wrapper.training_loss,\n",
        "              'validation_loss':wrapper.validation_loss\n",
        "              }\n",
        "\n",
        "        mlflow.pytorch.log_state_dict(val_dict,artifact_path=\"checkpoint\")\n",
        "        mlflow.pytorch.log_model(wrapper.model, artifact_path='model')\n",
        "\n",
        "        mlflow.end_run()\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        mlflow.end_run()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "mwFJcAuef07T",
        "wE7OwGBES7sa",
        "q7ygOSsiEAWs",
        "aKEY_j_lCzCa",
        "cgINpL8BK3hL",
        "0u3q4OhjYyGq",
        "he-C8aZXQkry",
        "vsRN0nOwDif5",
        "pwDBKoXvkno1",
        "dle5EmF9LXms",
        "n1_TRMmsm6jY",
        "T-lpiQp3XNxn",
        "kVH1teeglI4t"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
