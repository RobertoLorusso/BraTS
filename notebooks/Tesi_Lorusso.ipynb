{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## README â—\n",
        "\n",
        "Set a manual_seed for reproducibility.\n",
        "\n",
        "References:\n",
        "\n",
        "- See [Reproducibility](https://pytorch.org/docs/stable/notes/randomness.html)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ub1h-Y7DIpYf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### TO-DO âœ…\n",
        "\n",
        "\n",
        "#### FIX ðŸ§¯\n",
        "\n",
        "\n",
        "Quando viene sollevata un'eccezione in DataPreprocessor.__getitem __ viene restituito uno stack di immagini vuote. Aggiungere il relativo ID ad una lista e in fase di training evitare che queste immagini nere vengano incluse nel batch. Magari sostituendo a queste una delle immagini valide presenti nello stesso batch.\n"
      ],
      "metadata": {
        "id": "Yj5kNWe7UKif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment setup ðŸ›\n"
      ],
      "metadata": {
        "id": "mwFJcAuef07T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install python-dotenv\n",
        "! pip install monai\n",
        "! pip install shutil\n",
        "! pip install mlflow --quiet\n",
        "! pip install pyngrok --quiet\n",
        "! pip install torchmetrics\n",
        "! pip install dgl\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "sys.path.append('/content/drive/MyDrive/Lorusso/BraTS/')\n",
        "\n",
        "\n",
        "from src.preprocess.image_processing import *\n",
        "from src.preprocess.nifti_io import *\n",
        "from src.preprocess.graphgen import *\n",
        "from src.preprocess.graph_io import *\n",
        "\n",
        "from mlflow.models.signature import infer_signature\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "from pyngrok import ngrok\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dotenv import load_dotenv\n",
        "import concurrent.futures\n",
        "import tarfile\n",
        "import nibabel as nib\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "from distutils.dir_util import copy_tree\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import SequentialSampler\n",
        "from torchvision import utils\n",
        "\n",
        "from monai.networks.nets import AutoEncoder\n",
        "from monai.losses import DiceCELoss, DiceFocalLoss, DiceLoss, FocalLoss\n",
        "\n",
        "from dgl import from_networkx as to_dgl_graph\n",
        "\n",
        "\n",
        "#torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "id": "45BU03HjgAgT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "791ac75e-a6e7-41a4-bdf9-ddf3a2d2e13e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n",
            "Collecting monai\n",
            "  Downloading monai-1.3.0-202310121228-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from monai) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from monai) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->monai) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->monai) (1.3.0)\n",
            "Installing collected packages: monai\n",
            "Successfully installed monai-1.3.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement shutil (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for shutil\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m230.6/230.6 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchmetrics\n",
            "  Downloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu118)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.10.0 torchmetrics-1.2.1\n",
            "Collecting dgl\n",
            "  Downloading dgl-1.1.3-cp310-cp310-manylinux1_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.11.17)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.1.3\n",
            "Mounted at /content/drive/\n",
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "if [ ! -f '/content/drive/MyDrive/Lorusso/BraTS/.env' ]; then\n",
        "    echo \"Creating .env file...\"\n",
        "    echo \"INPUT_DATA_DIR='/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats'\" > '/content/drive/MyDrive/Lorusso/BraTS/.env'\n",
        "    echo \"PROCESSED_DATA_DIR='/content/drive/MyDrive/Lorusso/BraTS/data/processed'\" >> '/content/drive/MyDrive/Lorusso/BraTS/.env'\n",
        "fi"
      ],
      "metadata": {
        "id": "MkZwkHg4Wn_e"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "if [ ! -f '/content/drive/MyDrive/Lorusso/BraTS/data/raw/BraTS2021_Training_Data.tar'  ]; then\n",
        "    echo \"Downloading BraTS dataset at /content/drive/MyDrive/Lorusso/BraTS/data/raw ...\"\n",
        "    mkdir /root/.kaggle/\n",
        "    cp '/content/drive/MyDrive/Lorusso/kaggle.json' /root/.kaggle\n",
        "    chmod 600 '/root/.kaggle/kaggle.json'\n",
        "    cd '/content/drive/MyDrive/Lorusso/BraTS/data/raw' && kaggle datasets download -d dschettler8845/brats-2021-task1\n",
        "    ls '/content/drive/MyDrive/Lorusso/BraTS/data/raw'\n",
        "    unzip '/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats-2021-task1.zip' -d '/content/drive/MyDrive/Lorusso/BraTS/data/raw/'\n",
        "    rm -r '/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats-2021-task1.zip'\n",
        "fi"
      ],
      "metadata": {
        "id": "0u_tX1q-hh-L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "path='/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats'\n",
        "dst='/content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled/'\n",
        "\n",
        "rm -r '/content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled'\n",
        "if [ ! -d '/content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled' ]; then\n",
        "\n",
        "    mkdir '/content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled'\n",
        "\n",
        "    rm -r /content/drive/MyDrive/Lorusso/BraTS/data/interim/train\n",
        "    rm -r /content/drive/MyDrive/Lorusso/BraTS/data/interim/test\n",
        "    rm -r /content/drive/MyDrive/Lorusso/BraTS/data/interim/val\n",
        "\n",
        "    for el in $(ls $path | head -n 3);\n",
        "        do\n",
        "            echo \"$path/$el -> $dst\"\n",
        "            cp -R \"$path/$el\" $dst\n",
        "        done\n",
        "fi\n"
      ],
      "metadata": {
        "id": "2dm-FkQK1izU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15cbbea1-65e1-4a30-d9a0-c0162f85688b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00000 -> /content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled/\n",
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00002 -> /content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled/\n",
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00003 -> /content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLFlow server"
      ],
      "metadata": {
        "id": "wE7OwGBES7sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_tracking_uri('file:///content/drive/MyDrive/Lorusso/BraTS/mlruns')\n",
        "\n",
        "# Terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "# Get your authtoken from https://dashboard.ngrok.com/auth\n",
        "NGROK_AUTH_TOKEN = \"2Yliuv8VnNyKNcljxgEv6NpZgz8_6ZDBYmEcebUeoX93eGJAE\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# Open an HTTPs tunnel on port 5000 for http://localhost:5000\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)\n",
        "\n",
        "# run tracking UI in the background\n",
        "get_ipython().system_raw(\"mlflow ui --backend-store-uri file:///content/drive/MyDrive/Lorusso/BraTS/mlruns --port 5000 & \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4-kysoZS-i4",
        "outputId": "a411a499-8523-4f88-cfd1-09e36a69cc61"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLflow Tracking UI: https://2dff-34-125-53-119.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils ðŸ› "
      ],
      "metadata": {
        "id": "q7ygOSsiEAWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def untar_brats(tar_path, extract_path):\n",
        "    tar = tarfile.open(tar_path)\n",
        "    tar.extractall(extract_path)\n",
        "    tar.close()\n",
        "\n",
        "\n",
        "\n",
        "def plot_reconstruction(im_orig, im_rec, ax:int = 0, slice_index:int = 100):\n",
        "\n",
        "    f, ax_array = plt.subplots(1,2, figsize=(10,10))\n",
        "    ax_array[0].imshow(np.take(im_orig, indices = slice_index, axis = ax), cmap='gray')\n",
        "    ax_array[1].imshow(np.take( im_rec , indices=slice_index, axis = ax), cmap='gray')\n",
        "\n",
        "def plot_brain_sections(images,ax = 1,slice_index = 90):\n",
        "\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "\n",
        "    d1,d2,d3 = np.shape(images[1])\n",
        "    dims = [d1,d2,d3]\n",
        "    dims.pop(ax)\n",
        "    color_segmentation = np.zeros((dims[0],dims[1],3))\n",
        "\n",
        "    gray_segmentation = np.take(images[1],slice_index,axis = ax)\n",
        "    color_segmentation[gray_segmentation == 1] = [255,0,0] # Red (necrotic tumor core)\n",
        "    color_segmentation[gray_segmentation == 2] = [0,255,0] # Green (peritumoral edematous/invaded tissue)\n",
        "    color_segmentation[gray_segmentation == 4] = [0,0,255] # Blue (enhancing tumor)\n",
        "\n",
        "    t1 = images[0][0]\n",
        "    flair = images[0][1]\n",
        "    t2 = images[0][2]\n",
        "    t1ce = images[0][3]\n",
        "\n",
        "    image = t1+t2+flair+t1ce\n",
        "\n",
        "    plt.figure(figsize=(15,15))\n",
        "    plt.subplot(1,4,1)\n",
        "    plt.imshow(np.take(image,slice_index,axis = 0),cmap='gray')\n",
        "\n",
        "    plt.subplot(1,4,2)\n",
        "    plt.imshow(np.take(image,slice_index,axis = 1),cmap='gray')\n",
        "\n",
        "    plt.subplot(1,4,3)\n",
        "    plt.imshow(np.take(image,slice_index,axis = 2),cmap='gray')\n",
        "\n",
        "    plt.subplot(1,4,4)\n",
        "    plt.imshow(color_segmentation,cmap='gray')\n",
        "    plt.xlabel('Segmentation')\n",
        "\n",
        "\n",
        "def visTensor(tensor, ch=0, allkernels=False, nrow=8, padding=1):\n",
        "    n,c,w,h = tensor.shape\n",
        "    if allkernels: tensor = tensor.view(n*c, -1, w, h)\n",
        "    elif c != 3: tensor = tensor[:,ch,:,:].unsqueeze(dim=1)\n",
        "    rows = np.min((tensor.shape[0] // nrow + 1, 64))\n",
        "    grid = utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n",
        "    plt.figure( figsize=(nrow,rows) )\n",
        "    plt.imshow(grid.cpu().permute((1, 2, 0)))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Lrs_wCJEAJpS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset class  ðŸ’¾\n"
      ],
      "metadata": {
        "id": "aKEY_j_lCzCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Preprocessing script to convert from data provided by BraTS to data used by our model. Should be the first thing you run.\n",
        "Fulfills the following four functions:\n",
        "1. Normalize and standardize each image of each MRI modality\n",
        "2. Combine multiple MRI modalitities into one image array\n",
        "3. Swap labels from BraTS order (0,2,1,4) to more intuitive order (0,1,2,3)\n",
        "4. Convert image into a graph\n",
        "    Using Simple Linear Iterative Clustering algorithm\n",
        "    Parameters passed on command line\n",
        "\n",
        "If no labels are present (e.g. at test time, in deployment) can also build graph without labels.\n",
        "\n",
        "Saves the following in the specified output directory for each sample\n",
        "MRI_ID/\n",
        "    _input.nii.gz (processed and combined modalities for a sample as nifti file)\n",
        "    _label.nii.gz\n",
        "    _nxgraph.json (networkx graph containing both graph topography and features and labels for each node)\n",
        "    _supervoxels.nii.gz (supervoxel partitioning produced by SLIC)\n",
        "    _crop.npy (optionally the crop of the processed data relative to the original data) (crops out empty image planes)\n",
        "'''\n",
        "\n",
        "\n",
        "class DataPreprocessor(Dataset):\n",
        "    def __init__(self, dotenv_path = \"/content/drive/MyDrive/Lorusso/BraTS/.env\", transform = True, INPUT_PATH = None,\n",
        "                 num_nodes = 5000, boxiness_coef = 0.5, num_neighbors = 10):\n",
        "\n",
        "        load_dotenv(dotenv_path)\n",
        "        # Data mean and variance\n",
        "        data_stats = ([0.4645, 0.6625, 0.4064, 0.3648],\n",
        "                      [0.1593, 0.1703, 0.1216, 0.1627])\n",
        "        self.N_THREADS = 6\n",
        "\n",
        "        self.num_nodes = num_nodes\n",
        "        self.boxiness_coef = boxiness_coef\n",
        "        self.num_neighbors = num_neighbors\n",
        "\n",
        "        if(INPUT_PATH is not None and os.path.exists(INPUT_PATH)):\n",
        "            self.data_dir = INPUT_PATH\n",
        "        else:\n",
        "            self.data_dir = os.getenv('INPUT_DATA_DIR')\n",
        "        self.output_dir = os.getenv('PROCESSED_DATA_DIR')\n",
        "        self.mri_prefix = 'BraTS2021'\n",
        "        self.modality_extensions = [\"_flair.nii.gz\", \"_t1.nii.gz\", \"_t1ce.nii.gz\", \"_t2.nii.gz\"]\n",
        "        self.label_extension = \"_seg.nii.gz\"\n",
        "        self.include_labels = self.label_extension is not None\n",
        "        self.all_ids, self.id_to_fp = self.get_all_mris_in_dataset()\n",
        "        self.LABEL_MAP = {4: 3, 2: 1, 1: 2}\n",
        "        self.dataset_mean = np.array(data_stats[0], dtype=np.float32)\n",
        "        self.dataset_std = np.array(data_stats[1], dtype=np.float32)\n",
        "        self.transform = transform if isinstance(transform, bool) else True\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.all_ids)\n",
        "\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        images = []\n",
        "        # Load the image corresponding to idx\n",
        "        try:\n",
        "            fp = [self.id_to_fp[k] for k in self.all_ids if k.split('_')[-1] == idx][0]\n",
        "            bn = os.path.basename(os.path.split(fp)[0])\n",
        "            images.append([nib.load(os.path.join(fp, bn + level)).get_fdata(dtype=np.float32).T\n",
        "                           for level in self.modality_extensions])\n",
        "            labels = nib.load(os.path.join(fp, bn + self.label_extension)).get_fdata(dtype=np.float32).T\n",
        "\n",
        "            # Convert to numpy array otherwise you'll experience RAM leak\n",
        "            images = np.asarray(images[0])\n",
        "            imstack = np.stack(np.array(images, dtype=np.float32), axis = 0)\n",
        "            imstack, labels = self.padding(imstack, labels)\n",
        "\n",
        "            if (self.transform):\n",
        "                imstack,labels = self.get_standardized_image(imstack, labels)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Exception thrown in class {self.__class__.__name__ }, method __getitem__\")\n",
        "            print(e)\n",
        "            imstack = np.zeros([4,240,240,240],dtype=np.float32)\n",
        "            labels = np.zeros([240, 240, 240])\n",
        "\n",
        "        return np.array(imstack), labels\n",
        "\n",
        "    def image_to_graph(self, mri_id):\n",
        "        # NB: be careful to pass only the number to __getitem__ and not all the string.\n",
        "        # Example: Given the MRI Brats_00000 we need to pass to image_to_graph only '00000'\n",
        "        imstack, labels = self.__getitem__(mri_id.split('_')[-1])\n",
        "        save_path = f\"{self.output_dir}_{self.num_nodes}_{self.boxiness_coef}_{self.num_neighbors}{os.sep}{os.path.basename(self.data_dir)}{os.sep}{mri_id}\"\n",
        "\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "            # TRANSPOSE variable imstack because img2graph expects channel-first images\n",
        "            nx_graph,node_feats,region_img = img2graph(imstack.T,labels,self.num_nodes,self.boxiness_coef,self.num_neighbors)\n",
        "            #save in correct folder\n",
        "\n",
        "            save_networkx_graph(nx_graph, f\"{save_path}{os.sep}{mri_id}_nxgraph.json\")\n",
        "            save_as_nifti(imstack,f\"{save_path}{os.sep}{mri_id}_input.nii.gz\")\n",
        "            save_as_nifti(labels,f\"{save_path}{os.sep}{mri_id}_label.nii.gz\")\n",
        "            save_as_nifti(region_img,f\"{save_path}{os.sep}{mri_id}_supervoxels.nii.gz\")\n",
        "\n",
        "        return mri_id\n",
        "\n",
        "    def run(self):\n",
        "        with concurrent.futures.ThreadPoolExecutor(max_workers=self.N_THREADS) as executor:\n",
        "            futures = [executor.submit(self.image_to_graph, mri_id) for mri_id in self.all_ids]\n",
        "            print(\"Set up Threads, starting execution\")\n",
        "            for future in concurrent.futures.as_completed(futures):\n",
        "                try:\n",
        "                    mri_id = future.result()\n",
        "                except Exception as exc:\n",
        "                    print(\"Execption caught in DataPreprocessor.run\")\n",
        "                    print(f\"{exc}\")\n",
        "                else:\n",
        "                    print(\"Finished \"+ mri_id)\n",
        "\n",
        "\n",
        "\n",
        "    def get_all_mris_in_dataset(self):\n",
        "        mri_folders = glob.glob(f\"{self.data_dir}**/{self.mri_prefix}*/\",\n",
        "                                recursive=True)\n",
        "        mri_folders = self.remove_incomplete_mris(mri_folders)\n",
        "        scan_dic = {os.path.split(fp)[0].split(\"/\")[-1]: fp for fp in mri_folders}\n",
        "        if(len(mri_folders) == 0):\n",
        "            print(\"No MRI found at \" + self.data_dir)\n",
        "        return list(scan_dic.keys()), scan_dic\n",
        "\n",
        "\n",
        "    def remove_incomplete_mris(self, mri_folders):\n",
        "        # if there are any you want to ignore just add them to this list\n",
        "        removed_mris = []\n",
        "        return [fp for fp in mri_folders if fp.split(\"/\")[-2] not in removed_mris]\n",
        "\n",
        "\n",
        "    def split_dataset(self, ratio = (.6,.2,.2),seed = 42):\n",
        "\n",
        "        random.seed(seed)\n",
        "        if(np.sum(ratio) != 1 or ratio is None):\n",
        "          print(\"Error: ratio does not sum up to one.\\nSwitching to default (.6,.2,.2))\")\n",
        "          ratio = (.6,.2,.2)\n",
        "\n",
        "        train_length = int(len(self.all_ids)*ratio[0])\n",
        "        val_length = int(len(self.all_ids)*ratio[1])\n",
        "        test_length = int(len(self.all_ids)*ratio[2])\n",
        "        pos = random.sample(range(0,len(self.all_ids)), len(self.all_ids))\n",
        "\n",
        "        split_dict = {\n",
        "            'train': [self.all_ids[i] for i in pos[:train_length]],\n",
        "            'val': [self.all_ids[i] for i in pos[train_length :train_length + val_length]],\n",
        "            'test': [self.all_ids[i] for i in pos[train_length + val_length:]]\n",
        "        }\n",
        "\n",
        "        for k in split_dict.keys():\n",
        "          parent = '/'.join(self.data_dir.split('/')[:-1])\n",
        "          dst = os.path.join(parent,k)\n",
        "\n",
        "          try:\n",
        "            # create train,val,test dirs\n",
        "            if(not os.path.exists(dst)):\n",
        "              os.mkdir(dst)\n",
        "\n",
        "            # copy splitted data inside folders\n",
        "            for id in split_dict[k]:\n",
        "              if(not os.path.exists(os.path.join(dst,id))):\n",
        "                 os.mkdir(os.path.join(dst,id))\n",
        "              copy_tree(self.id_to_fp[id],os.path.join(dst,id))\n",
        "\n",
        "          except Exception as e:\n",
        "            print(f\"Exception thrown in class {self.__class__.__name__ }, method split_dataset\")\n",
        "            print(e)\n",
        "\n",
        "\n",
        "    def padding(self,image, labels):\n",
        "        n_channels = np.shape(image)[0]\n",
        "        max_val = max(np.shape(image))\n",
        "        pad_list = np.zeros([n_channels,max_val,max_val,max_val],dtype=np.float32)\n",
        "\n",
        "        for channel in range(0, n_channels): # pad every channel\n",
        "            pad_list[channel] = np.pad(image[channel],[(42,43),(0,0),(0,0)],'constant')\n",
        "        labels = np.pad(labels, [(42,43),(0,0),(0,0)],'constant')\n",
        "\n",
        "        return pad_list, labels\n",
        "\n",
        "\n",
        "    def get_standardized_image(self, image_data, label_data):\n",
        "\n",
        "        standardized_labels = self.swap_labels_from_brats(label_data)\n",
        "        #standardized_data = self.standardize_img(\n",
        "        #    image_data, self.dataset_mean, self.dataset_std)\n",
        "        #normalized_data = self.standardize_img(image_data)\n",
        "        normalized_data = self.normalize_img(image_data)\n",
        "        return normalized_data, standardized_labels\n",
        "\n",
        "\n",
        "    def normalize_img(self, img_array):\n",
        "        new_image = np.zeros(img_array.shape, dtype=np.float32)\n",
        "        n_channel = img_array.shape[0] # channel-first images\n",
        "\n",
        "        for channel in range(0, n_channel): # normalize every channel\n",
        "\n",
        "            maxval, minval= np.max(img_array[channel]), np.min(img_array[channel])\n",
        "            new_image[channel] = (img_array[channel] - minval)/(maxval-minval)\n",
        "\n",
        "        return new_image\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def normalize_img_quantile(self, img_array):\n",
        "        quantile = np.quantile(img_array, 0.995, axis = (0,1,2,3) )\n",
        "        return img_array/quantile\n",
        "\n",
        "\n",
        "\n",
        "    def standardize_img(self,img_array):\n",
        "        img_array = img_array.T # Align shapes\n",
        "        centered = img_array-self.dataset_mean\n",
        "        standardized = centered/self.dataset_std\n",
        "        return standardized.T\n",
        "\n",
        "\n",
        "    def swap_labels_from_brats(self,label_data):\n",
        "        uniques = np.unique(label_data)\n",
        "        for u in uniques:\n",
        "            if u not in [0, 1, 2, 4]:\n",
        "                raise RuntimeError('unexpected label')\n",
        "        new_label_data = np.zeros_like(label_data, dtype=np.int16)\n",
        "        new_label_data[label_data == 4] = self.LABEL_MAP[4]\n",
        "        new_label_data[label_data == 2] = self.LABEL_MAP[2]\n",
        "        new_label_data[label_data == 1] = self.LABEL_MAP[1]\n",
        "        return new_label_data\n",
        "\n",
        "    def swap_labels_to_brats(self,label_data):\n",
        "        uniques = np.unique(label_data)\n",
        "        for u in uniques:\n",
        "            if u not in [0, 1, 2, 3]:\n",
        "                raise RuntimeError('unexpected label')\n",
        "        new_label_data = np.zeros_like(label_data, dtype=np.int16)\n",
        "        new_label_data[label_data == self.LABEL_MAP[4]] = 4\n",
        "        new_label_data[label_data == self.LABEL_MAP[2]] = 2\n",
        "        new_label_data[label_data == self.LABEL_MAP[1]] = 1\n",
        "        return new_label_data\n",
        "\n",
        "\n",
        "'''\n",
        "A Dataset similar to a torch dataset which iterates over all samples in a directory and returns the contents as numpy arrays.\n",
        "Expects to receive a filepath to the output of the preprocess script which should have the following:\n",
        "1.processed image (nifti)\n",
        "2.label image (nifti)\n",
        "3.networkx graph (json)\n",
        "4.supervoxel partitioning (nifti)\n",
        "5. (optionally) a .npy file containing the crop of the processed image relative to the original image\n",
        "\n",
        "\n",
        "#Input#\n",
        "dataset_root_dir: filepath to preprocessed dataset (generated by running preprocess script)\n",
        "mri_start_string: a prefix that every image folder starts with (can be empty string)\n",
        "read_image: whether to read in and return preprocessed images for each sample (only necessary for CNN model)\n",
        "read_graph: whether to return graphs for each sample (for training GNN)\n",
        "read_label: whether to read in labels. Will be returned in vector form (one label per node if )\n",
        "\n",
        "#Output#\n",
        "\n",
        "If graph:\n",
        "Returns a DGL Graph, features for each node, and (optionally) labels for each node\n",
        "If image:\n",
        "Returns a numpy image array and (optionally) a numpy label array\n",
        "\n",
        "'''\n",
        "\n",
        "class ImageGraphDataset(Dataset):\n",
        "    def __init__(self, dataset_root_dir,mri_start_string,read_image=True,read_graph=True,read_label=True):\n",
        "        self.dataset_root_dir=dataset_root_dir\n",
        "        self.all_ids = self.get_all_mris_in_dataset(dataset_root_dir,mri_start_string)\n",
        "        self.read_image=read_image\n",
        "        self.read_graph=read_graph\n",
        "        self.read_label = read_label\n",
        "        assert(self.read_graph or self.read_image)\n",
        "\n",
        "    def get_all_mris_in_dataset(self,dataset_root_dir,mri_start_string):\n",
        "        mri_folders = glob.glob(f\"{dataset_root_dir}**/{mri_start_string}*/\",recursive=True)\n",
        "        mri_ids = [fp.split(os.sep)[-2] for fp in mri_folders]\n",
        "        print(f\"Found {len(mri_folders)} MRIs\")\n",
        "        return mri_ids\n",
        "\n",
        "    def get_one(self,mri_id):\n",
        "        if(self.read_graph and not self.read_image):\n",
        "            return (mri_id, *self.get_graph(mri_id))\n",
        "        elif(self.read_image  and not self.read_graph):\n",
        "            return (mri_id, *self.get_image(mri_id))\n",
        "        elif(self.read_image and self.read_graph):\n",
        "            return (mri_id, *self.get_graph(mri_id), *self.get_image(mri_id))\n",
        "        else:\n",
        "            print(\"Invalid combination of flags\")\n",
        "\n",
        "    '''\n",
        "    Reads in the saved networkx graph, converts it to a DGLGraph, normalizes the graph (not actually sure how useful this is),\n",
        "    and returns the DGLGraph as well as a vector of node features and optionally labels.\n",
        "    '''\n",
        "    def get_graph(self,mri_id):\n",
        "        nx_graph = load_networkx_graph(f\"{self.dataset_root_dir}{os.sep}{mri_id}{os.sep}{mri_id}_nxgraph.json\")\n",
        "        features = np.array([nx_graph.nodes[n]['features'] for n in nx_graph.nodes])\n",
        "        if(self.read_label):\n",
        "            labels = np.array([nx_graph.nodes[n]['label'] for n in nx_graph.nodes])\n",
        "        G = to_dgl_graph(nx_graph)\n",
        "        n_edges = G.number_of_edges()\n",
        "        # normalization\n",
        "        degs = G.in_degrees().float()\n",
        "        norm = torch.pow(degs, -0.5)\n",
        "        norm[torch.isinf(norm)] = 0\n",
        "        G.ndata['norm'] = norm.unsqueeze(1)\n",
        "        #G.ndata['feat'] = features\n",
        "        if(self.read_label):\n",
        "            #G.ndata['label'] = labels\n",
        "            return G, features, labels\n",
        "        return G, features\n",
        "\n",
        "    def get_voxel_labels(self,mri_id):\n",
        "        fp=f\"{self.dataset_root_dir}{os.sep}{mri_id}{os.sep}{mri_id}_label.nii.gz\"\n",
        "        return read_nifti(fp,np.int16)\n",
        "\n",
        "    def get_image(self,mri_id):\n",
        "        fp = f\"{self.dataset_root_dir}{os.sep}{mri_id}{os.sep}{mri_id}_input.nii.gz\"\n",
        "        img = read_nifti(fp,np.float32)\n",
        "        if(self.read_label):\n",
        "            return img,self.get_voxel_labels(mri_id)\n",
        "        else:\n",
        "            return (img,)\n",
        "\n",
        "    def get_supervoxel_partitioning(self,mri_id):\n",
        "        fp=f\"{self.dataset_root_dir}{os.sep}{mri_id}{os.sep}{mri_id}_supervoxels.nii.gz\"\n",
        "        return read_nifti(fp,np.int16)\n",
        "\n",
        "    def get_crop(self,mri_id):\n",
        "        fp=f\"{self.dataset_root_dir}{os.sep}{mri_id}{os.sep}{mri_id}_crop.npy\"\n",
        "        return tuple(np.load(fp,allow_pickle=True))\n",
        "\n",
        "    def __iter__(self):\n",
        "        for mri_id in self.all_ids:\n",
        "            yield self.get_one(mri_id)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        mri_id = self.all_ids[index]\n",
        "        return self.get_one(mri_id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.all_ids)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class SeqSampler(SequentialSampler):\n",
        "    \"\"\"Samples elements sequentially, always in the same order.\n",
        "\n",
        "    Args:\n",
        "        data_source (Dataset): dataset to sample from\n",
        "    \"\"\"\n",
        "    def __init__(self, data_source:Dataset):\n",
        "        self.data_source = data_source\n",
        "        self.indexDict = [id.split('_')[1] for id in data_source.all_ids]\n",
        "    def __iter__(self):\n",
        "        return iter(self.indexDict)\n",
        "    def __len__(self):\n",
        "        return len(self.indexDict)\n"
      ],
      "metadata": {
        "id": "-Pa_KNzpRi0d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models ðŸ“ª\n"
      ],
      "metadata": {
        "id": "cgINpL8BK3hL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from dgl.nn.pytorch import GATConv, GraphConv\n",
        "from dgl.nn.pytorch.conv import SAGEConv\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "'''\n",
        "Contains the actual neural network architectures.\n",
        "Supports GraphSAGE with either the pool,mean,gcn, or lstm aggregator as well as GAT.\n",
        "The input, output, and intermediate layer sizes can all be specified.\n",
        "Typically will call init_graph_net and pass along the desired model and hyperparameters.\n",
        "\n",
        "Also contains the CNN Refinement net which is a very simple 2 layer 3D convolutional neural network.\n",
        "As input, it expects 8 channels, which are the concatenated 4 input modalities and 4 output logits of the GNN predictions.\n",
        "'''\n",
        "\n",
        "\n",
        "class GraphSage(nn.Module):\n",
        "    def __init__(self,in_feats,layer_sizes,n_classes,aggregator_type,dropout):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        # input layer\n",
        "        self.layers.append(SAGEConv(in_feats, layer_sizes[0], aggregator_type, feat_drop=dropout, activation=F.relu))\n",
        "        # hidden layers\n",
        "        for i in range(1,len(layer_sizes)):\n",
        "            self.layers.append(SAGEConv(layer_sizes[i-1], layer_sizes[i], aggregator_type, feat_drop=dropout, activation=F.relu))\n",
        "        # output layer\n",
        "        self.layers.append(SAGEConv(layer_sizes[-1], n_classes, aggregator_type, feat_drop=0, activation=None))\n",
        "\n",
        "    def forward(self,graph,features):\n",
        "        h = features\n",
        "        for layer in self.layers:\n",
        "            h = layer(graph, h)\n",
        "        return h\n",
        "\n",
        "\n",
        "class GAT(nn.Module):\n",
        "    def __init__(self,in_feats,layer_sizes,n_classes,heads,residuals,\n",
        "                activation=F.elu,feat_drop=0,attn_drop=0,negative_slope=0.2):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.activation = activation\n",
        "        # input projection (no residual)\n",
        "        self.layers.append(GATConv(\n",
        "            in_feats, layer_sizes[0], heads[0],\n",
        "            feat_drop, attn_drop, negative_slope, False, self.activation))\n",
        "        # hidden layers\n",
        "        for i in range(1, len(layer_sizes)):\n",
        "            # due to multi-head, the in_dim = num_hidden * num_heads\n",
        "            self.layers.append(GATConv(\n",
        "                layer_sizes[i-1] * heads[i-1], layer_sizes[i], heads[i],\n",
        "                feat_drop, attn_drop, negative_slope, residuals[i], self.activation))\n",
        "        # output projection\n",
        "        self.layers.append(GATConv(\n",
        "            layer_sizes[-1] * heads[-1], n_classes, 1,\n",
        "            feat_drop, attn_drop, negative_slope, False, None))\n",
        "\n",
        "    def forward(self,g, inputs):\n",
        "        h = inputs\n",
        "        for l in range(len(self.layers)-1):\n",
        "            h = self.layers[l](g, h).flatten(1)\n",
        "        # output projection\n",
        "        logits = self.layers[-1](g, h).mean(1)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "78WIjwSZRkGN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Wrapper ðŸ“¨\n"
      ],
      "metadata": {
        "id": "0u3q4OhjYyGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelWrapper():\n",
        "    \"\"\"\n",
        "    Allows train, evaluation, prediction and I/O operations on generic PyTorch models\n",
        "    The model is saved at every epoch.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model: nn.Module, optimizer: nn.Module, loss_fn: nn.Module,\n",
        "                 num_epochs: int, supervised: bool = True, dict_params:dict = {}, LOAD_MODEL: bool = False,\n",
        "                 model_path: str  = '/content/drive/MyDrive/Lorusso/models', eval_metrics = None):\n",
        "\n",
        "        self.device = (\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "        self.model = model\n",
        "        self.model = self.model.to(self.device)\n",
        "        self.model = self.model.to(torch.float)\n",
        "        self.num_epochs = num_epochs\n",
        "        self.loss_fn = loss_fn\n",
        "        self.eval_metrics = eval_metrics\n",
        "        self.optimizer = optimizer\n",
        "        self.model_path = model_path\n",
        "        self.save_path = self.model_path + '/' + self.model.__class__.__name__ + '/model.pt'\n",
        "\n",
        "        self.supervised = supervised\n",
        "        self.training_loss = []\n",
        "        self.validation_loss = []\n",
        "        self.dict_metrics = {}\n",
        "        self.elapsed_epochs = 0\n",
        "        self.elapsed_seconds = 0\n",
        "\n",
        "        self.dict_params = dict_params\n",
        "        self.update_params({'loss_fn':self.loss_fn.__class__.__name__})\n",
        "        self.update_params({'optimizer':self.optimizer.__class__.__name__})\n",
        "        self.update_params({'learning_rate':self.optimizer.state_dict()['param_groups'][0]['lr']})\n",
        "        self.update_params({'weight_decay':self.optimizer.state_dict()['param_groups'][0]['weight_decay']})\n",
        "\n",
        "        if(LOAD_MODEL):\n",
        "          self.load_checkpoint()\n",
        "\n",
        "        # Create directory for model loading\n",
        "        try:\n",
        "          if(not os.path.exists(self.model_path + '/' + self.model.__class__.__name__)):\n",
        "            os.mkdir(self.model_path + '/' + self.model.__class__.__name__)\n",
        "        except Exception as e:\n",
        "          print(f\"Exception thrown in class {self.model.__class__.__name__ }, method __init__\")\n",
        "          print(e)\n",
        "          print('\\n')\n",
        "\n",
        "\n",
        "    def update_params(self, new_params):\n",
        "        try:\n",
        "            self.dict_params.update(new_params)\n",
        "        except Exception as e:\n",
        "            print('Exception raised in WrapperModel.update_params')\n",
        "            print(e)\n",
        "\n",
        "    def log_checkpoint(self, info: dict):\n",
        "        mlflow.pytorch.log_state_dict(info, artifact_path='checkpoint')\n",
        "        #torch.save(info, self.save_path)\n",
        "\n",
        "    def load_checkpoint(self):\n",
        "        \"\"\" Loads the last checkpoint for the given model \"\"\"\n",
        "        try:\n",
        "            run_id = mlflow.search_runs(experiment_names=['BraTS_'+type(self.model).__name__],\n",
        "                                        order_by=[\"start_time DESC\"]).iloc[0].run_id\n",
        "\n",
        "            checkpoint = mlflow.pytorch.load_state_dict('runs:/'+run_id+'/checkpoint',\n",
        "                                                        map_location=torch.device(self.device))\n",
        "\n",
        "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            self.elapsed_epochs = len(checkpoint['training_loss'])\n",
        "            self.training_loss = checkpoint['training_loss']\n",
        "            self.validation_loss = checkpoint['validation_loss']\n",
        "            self.dict_metrics = checkpoint['dict_metrics']\n",
        "            self.elapsed_seconds = checkpoint['elapsed_seconds']\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Exception thrown in class {self.model.__class__.__name__ }, method load_checkpoint\")\n",
        "            print(e)\n",
        "            print('\\n')\n",
        "            if(mlflow.active_run()):\n",
        "                mlflow.end_run()\n",
        "\n",
        "\n",
        "    def train(self, train_loader, val_loader = None,  experiment_prefix = ''):\n",
        "\n",
        "        try:\n",
        "            # Set MLFlow experiment\n",
        "            if(experiment_prefix):\n",
        "                mlflow.set_experiment(experiment_prefix + self.model.__class__.__name__)\n",
        "            else:\n",
        "                mlflow.set_experiment('BraTS_'+self.model.__class__.__name__)\n",
        "\n",
        "            # Start a new run if the model wasn't loaded\n",
        "            if(not mlflow.active_run()):\n",
        "                # Track metrics in the current run\n",
        "                mlflow.start_run()\n",
        "\n",
        "            for i in range(len(self.training_loss)):\n",
        "                mlflow.log_metric('train_loss', self.training_loss[i], step=i)\n",
        "\n",
        "            for i in range(len(self.validation_loss)):\n",
        "                mlflow.log_metric('val_loss', self.validation_loss[i], step=i)\n",
        "\n",
        "            self.update_params({'batch_size':train_loader.batch_size})\n",
        "            mlflow.log_params(self.dict_params)\n",
        "\n",
        "            training_loss = self.training_loss\n",
        "            validation_loss = self.validation_loss\n",
        "\n",
        "            self.tot_epochs = self.elapsed_epochs + self.num_epochs+1\n",
        "            self.tot_time = time.time()\n",
        "\n",
        "            # Train\n",
        "            for epoch in range(self.elapsed_epochs+1, self.tot_epochs):\n",
        "                start = time.time() # track time\n",
        "\n",
        "              # Evaluate first if loaded model missed the evaluation during an epoch\n",
        "                if(len(training_loss) > len(validation_loss)):\n",
        "                    if(val_loader is not None):\n",
        "\n",
        "                      ## COMPLETE EVALUATION OF PREVIOUS EPOCH ##\n",
        "                      # NB: epoch = epoch - 1\n",
        "                        val_batch_loss = self.__eval(val_loader, (epoch-1) )\n",
        "                        validation_loss.append(np.array(val_batch_loss).mean())\n",
        "                        self.dict_metrics = self.__eval_metrics(val_loader)\n",
        "\n",
        "                        for k in self.dict_metrics.keys():\n",
        "                            mlflow.log_metric(str(k), self.dict_metrics[k], step=epoch-1)\n",
        "                        # Log metric\n",
        "                        mlflow.log_metric('val_loss',validation_loss[-1], step=epoch-1)\n",
        "\n",
        "                        print(f\"Epoch: {epoch-1}/{self.tot_epochs-1}, Validation Loss: {validation_loss[-1]:.4f}, Elapsed time: {time.time() - start:.0f} sec \")\n",
        "\n",
        "                      # Update training time\n",
        "                        epoch_time = int(time.time() - self.tot_time) + self.elapsed_seconds\n",
        "\n",
        "                      #Create checkpoint\n",
        "                        val_dict = {\n",
        "                                  'model_state_dict': self.model.state_dict(),\n",
        "                                  'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                                  'training_loss': training_loss,\n",
        "                                  'validation_loss': validation_loss,\n",
        "                                  'dict_metrics': self.dict_metrics,\n",
        "                                  'elapsed_seconds': epoch_time\n",
        "                                  }\n",
        "                        self.log_checkpoint(val_dict)\n",
        "                    else:\n",
        "                        # Kind of exception, needed to keep the vectors of the same size\n",
        "                        validation_loss.append(np.mean(validation_loss))\n",
        "\n",
        "                        #Log metric\n",
        "                        mlflow.log_metric('val_loss',validation_loss[-1], step=epoch-1)\n",
        "\n",
        "                #### TRAIN ######\n",
        "                train_batch_loss = self.__train(train_loader, epoch)\n",
        "                training_loss.append(np.array(train_batch_loss).mean())\n",
        "\n",
        "                # Log metric\n",
        "                mlflow.log_metric('train_loss',training_loss[-1], step=epoch) # MLFLOW tracking\n",
        "                print(f\"\\nEpoch: {epoch}/{self.tot_epochs-1}, Loss: {training_loss[-1]:.4f}, Epoch elapsed time: {time.time() - start:.0f} sec \\n\")\n",
        "\n",
        "                #Save model every elapsed epoch\n",
        "                self.elapsed_epochs = epoch\n",
        "                epoch_time = int(time.time() - self.tot_time) + self.elapsed_seconds\n",
        "\n",
        "                train_dict = {\n",
        "                          'model_state_dict': self.model.state_dict(),\n",
        "                          'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                          'training_loss': training_loss,\n",
        "                          'validation_loss': validation_loss,\n",
        "                          'dict_metrics':self.dict_metrics,\n",
        "                          'elapsed_seconds': epoch_time\n",
        "                          }\n",
        "                self.log_checkpoint(train_dict)\n",
        "\n",
        "                #### EVALUATE ######\n",
        "                torch.cuda.empty_cache()\n",
        "                time.sleep(5)\n",
        "                if(val_loader is not None):\n",
        "\n",
        "                    val_batch_loss = self.__eval(val_loader, epoch)\n",
        "                    validation_loss.append(np.array(val_batch_loss).mean())\n",
        "\n",
        "                    self.dict_metrics = self.__eval_metrics(val_loader)\n",
        "\n",
        "                    for k in self.dict_metrics.keys():\n",
        "                        mlflow.log_metric(str(k), self.dict_metrics[k], step=epoch)\n",
        "\n",
        "                    # Log metric\n",
        "                    mlflow.log_metric('val_loss',validation_loss[-1], step=epoch)\n",
        "                    print(f\"Epoch: {epoch}/{self.tot_epochs-1}, Validation Loss: {validation_loss[-1]:.4f}, Elapsed time: {time.time() - start:.0f} sec \")\n",
        "\n",
        "                    #Checkpoint\n",
        "                    epoch_time = int(time.time() - self.tot_time) + self.elapsed_seconds\n",
        "                    val_dict = {\n",
        "                              'model_state_dict': self.model.state_dict(),\n",
        "                              'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                              'training_loss': training_loss,\n",
        "                              'validation_loss': validation_loss,\n",
        "                              'dict_metrics':self.dict_metrics,\n",
        "                              'elapsed_seconds': epoch_time\n",
        "                              }\n",
        "                    self.log_checkpoint(val_dict)\n",
        "\n",
        "                print(f\"Total training time: {time.time()-self.tot_time:.0f} sec\")\n",
        "\n",
        "            # Log model --> end run\n",
        "            mlflow.pytorch.log_model(self.model, artifact_path='model')\n",
        "            mlflow.end_run()\n",
        "        except Exception as e:\n",
        "            print(f\"Exception thrown in class {self.model.__class__.__name__ }, method train:\")\n",
        "            print(e)\n",
        "            print('\\n')\n",
        "            mlflow.end_run()\n",
        "\n",
        "\n",
        "        return training_loss, validation_loss\n",
        "\n",
        "    def __train(self, train_loader: DataLoader, epoch:int):\n",
        "\n",
        "        \"\"\" Train for an epoch \"\"\"\n",
        "\n",
        "        self.model.train()\n",
        "        train_batch_loss = []\n",
        "        train_steps = int(len(train_loader.dataset.all_ids)/train_loader.batch_size)\n",
        "\n",
        "        for i, (data,labels) in enumerate(train_loader):\n",
        "\n",
        "          torch.cuda.empty_cache()\n",
        "          self.optimizer.zero_grad()\n",
        "\n",
        "          if self.device == 'cuda':\n",
        "            data = data.type(torch.cuda.FloatTensor)\n",
        "          else:\n",
        "            data = data.type(torch.FloatTensor)\n",
        "\n",
        "          data = data.to(self.device)\n",
        "\n",
        "          outputs = self.model(data)\n",
        "\n",
        "          if(self.supervised):\n",
        "            loss = self.loss_fn(outputs,labels)\n",
        "          else:\n",
        "            loss = self.loss_fn(outputs, data)\n",
        "\n",
        "          loss.backward()\n",
        "          self.optimizer.step()\n",
        "          train_batch_loss.append(loss.detach().item())\n",
        "\n",
        "          out = f\"Epoch: {epoch}/{self.tot_epochs-1}, Step: {i+1}/{train_steps}, Loss: {loss.item():.4f}, Elapsed time: {time.time() - self.tot_time:.0f} sec \"\n",
        "          sys.stdout.write(\"\\r\" + out)\n",
        "          sys.stdout.flush()\n",
        "\n",
        "        return train_batch_loss\n",
        "\n",
        "\n",
        "    def __eval(self, val_loader: DataLoader, epoch:int):\n",
        "\n",
        "        \"\"\" Evaluate for an epoch \"\"\"\n",
        "\n",
        "        val_steps = int(len(val_loader.dataset.all_ids)/val_loader.batch_size)\n",
        "        self.model.eval()\n",
        "        val_batch_loss = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "          for i, (data,labels) in enumerate(val_loader):\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            if self.device == 'cuda':\n",
        "              data = data.type(torch.cuda.FloatTensor)\n",
        "            else:\n",
        "              data = data.type(torch.FloatTensor)\n",
        "\n",
        "            data = data.to(self.device)\n",
        "            outputs = self.model(data)\n",
        "\n",
        "            if(self.supervised):\n",
        "                val_loss = self.loss_fn(outputs, labels)\n",
        "            else:\n",
        "                val_loss = self.loss_fn(outputs, data)\n",
        "\n",
        "            val_batch_loss.append(val_loss.detach().item())\n",
        "\n",
        "            out = f\"Epoch: {epoch}/{self.tot_epochs-1}, Validation Step: {i+1}/{val_steps}, Validation Loss: {val_loss.item():.4f}, Elapsed time: {time.time() - self.tot_time:.0f} sec \"\n",
        "            sys.stdout.write(\"\\r\" + out)\n",
        "            sys.stdout.flush()\n",
        "\n",
        "        return val_batch_loss\n",
        "\n",
        "\n",
        "    def __eval_metrics(self, data_loader:DataLoader):\n",
        "        \"\"\" Evaluates additional metrics aside the loss function \"\"\"\n",
        "        metrics_dict = {}\n",
        "        try:\n",
        "            self.model.eval()\n",
        "            if(self.eval_metrics is not None):\n",
        "\n",
        "                metrics_dict = {k.__class__.__name__:[] for k in self.eval_metrics}\n",
        "\n",
        "                with torch.no_grad():\n",
        "\n",
        "                    for i, (data,labels) in enumerate(data_loader):\n",
        "                        torch.cuda.empty_cache()\n",
        "                        self.optimizer.zero_grad()\n",
        "\n",
        "                        for metric in self.eval_metrics:\n",
        "\n",
        "                            if self.device == 'cuda':\n",
        "                                data = data.type(torch.cuda.FloatTensor)\n",
        "                            else:\n",
        "                                data = data.type(torch.FloatTensor)\n",
        "\n",
        "                            data = data.to(self.device)\n",
        "                            outputs = self.model(data)\n",
        "\n",
        "                            if(self.supervised):\n",
        "                                metric_value = metric(outputs, labels)\n",
        "                            else:\n",
        "                                metric_value = metric(outputs, data)\n",
        "\n",
        "                            metrics_dict[metric.__class__.__name__].append(metric_value.detach().item())\n",
        "\n",
        "                    for k in metrics_dict.keys():\n",
        "                        metrics_dict[k] = np.array(metrics_dict[k]).mean()\n",
        "\n",
        "        except Exception as e:\n",
        "            print('Exception thrown in wrapper.__eval_metrics')\n",
        "            print(e)\n",
        "        finally:\n",
        "            return metrics_dict\n",
        "\n",
        "\n",
        "\n",
        "    def predict_batch(self, data_loader:DataLoader):\n",
        "\n",
        "        output = []\n",
        "        self.model = self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            try:\n",
        "              for i, batch in enumerate(data_loader):\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "                if(len(batch) == 1):\n",
        "                  data = batch\n",
        "                else:\n",
        "                  data,label = batch\n",
        "\n",
        "                if self.device == 'cuda':\n",
        "                  data = data.type(torch.cuda.FloatTensor)\n",
        "                else:\n",
        "                  data = data.type(torch.FloatTensor)\n",
        "\n",
        "                data.to(self.device)\n",
        "\n",
        "                out = self.model(data)\n",
        "                out = out.cpu().detach().numpy()\n",
        "                output.append(out)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Exception thrown in class {self.model.__class__.__name__ }, method predict_batch:\")\n",
        "                print(e)\n",
        "                print('\\n')\n",
        "\n",
        "        return np.array(output)\n",
        "\n",
        "\n",
        "    def predict(self, data):\n",
        "\n",
        "        if device == 'cuda':\n",
        "          data = data.type(torch.cuda.FloatTensor)\n",
        "        else:\n",
        "          data = data.type(torch.FloatTensor)\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            data.to(device)\n",
        "            output = self.model(data)\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "biiQzha9JP8G"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss ðŸ•³"
      ],
      "metadata": {
        "id": "he-C8aZXQkry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Loss(nn.Module):\n",
        "    def __init__(self, focal):\n",
        "        super(Loss, self).__init__()\n",
        "        if focal:\n",
        "            self.loss_fn = DiceFocalLoss(\n",
        "                include_background=False, softmax=True, to_onehot_y=True, batch=True, gamma=2.0\n",
        "            )\n",
        "        else:\n",
        "            self.loss_fn = DiceCELoss(include_background=False, softmax=True, to_onehot_y=True, batch=True)\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        return self.loss_fn(y_pred, y_true)\n",
        "\n",
        "\n",
        "class LossBraTS(nn.Module):\n",
        "    def __init__(self, focal):\n",
        "        super(LossBraTS, self).__init__()\n",
        "        self.dice = DiceLoss(sigmoid=True, batch=True)\n",
        "        self.ce = FocalLoss(gamma=2.0, to_onehot_y=False) if focal else nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def _loss(self, p, y):\n",
        "        print('p '+str(p.size()))\n",
        "        print('y '+str(y.size()))\n",
        "        return self.dice(p, y) + self.ce(p, y.float())\n",
        "\n",
        "    def forward(self, p, y):\n",
        "        y_wt, y_tc, y_et = y > 0, ((y == 1) + (y == 3)) > 0, y == 3\n",
        "        p_wt, p_tc, p_et = p[:, 0].unsqueeze(1), p[:, 1].unsqueeze(1), p[:, 2].unsqueeze(1)\n",
        "        l_wt, l_tc, l_et = self._loss(p_wt, y_wt), self._loss(p_tc, y_tc), self._loss(p_et, y_et)\n",
        "        return l_wt + l_tc + l_et"
      ],
      "metadata": {
        "id": "pUxP6_HiQiP8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build dataset ðŸ—"
      ],
      "metadata": {
        "id": "vsRN0nOwDif5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dotenv_path = \"/content/drive/MyDrive/Lorusso/BraTS/.env\"\n",
        "load_dotenv(dotenv_path)\n",
        "\n",
        "\n",
        "INPUT_PATH = os.getenv(\"INPUT_DATA_DIR\")\n",
        "PROCESSED_PATH = os.getenv('PROCESSED_DATA_DIR')\n",
        "INPUT_PATH_PARENT = '/'.join(INPUT_PATH.split('/')[:-1])\n",
        "\n",
        "TRAIN_PATH = os.path.join(INPUT_PATH_PARENT,'train')\n",
        "VAL_PATH = os.path.join(INPUT_PATH_PARENT,'val')\n",
        "TEST_PATH = os.path.join(INPUT_PATH_PARENT,'test')\n",
        "\n",
        "TAR_PATH = os.path.join(INPUT_PATH_PARENT,'BraTS2021_Training_Data.tar')\n",
        "BUILD_DATASET = False\n",
        "\n",
        "if(BUILD_DATASET):\n",
        "  untar_brats(tar_path = '/content/drive/MyDrive/Lorusso/BraTS/data/raw/BraTS2021_Training_Data.tar', extract_path = INPUT_PATH )\n",
        "  dataset = DataPreprocessor()\n",
        "  dataset.split_dataset()\n",
        "\n",
        "#dataset = DataPreprocessor()\n",
        "#train_loader = DataLoader(dataset, sampler = SeqSampler(dataset), batch_size = 1, num_workers = 0)\n",
        "#images, labels= next(iter(train_loader))\n",
        "#plot_brain_sections([images[0], labels[0]])\n",
        "#del images, labels, train_loader, dataset"
      ],
      "metadata": {
        "id": "9m9XrfCJDqWy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and predict âŒ›"
      ],
      "metadata": {
        "id": "mz-6k-tLLDbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_MODEL = False\n",
        "LOAD_MODEL = False\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "time.sleep(10)\n",
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "  num_workers = 0\n",
        "  batch_size = 1\n",
        "  num_epochs = 1\n",
        "  lr = 0.005\n",
        "  supervised = False\n",
        "\n",
        "  # MONAI AUTOENCODER\n",
        "  model = AutoEncoder(\n",
        "         spatial_dims=3,\n",
        "         kernel_size = 3,\n",
        "         up_kernel_size = 3,\n",
        "         in_channels=4,\n",
        "         out_channels=4,\n",
        "         channels=(5,),\n",
        "         strides=(2,),\n",
        "         inter_channels=(8, 16, 32),\n",
        "         inter_dilations=(1, 2, 4),\n",
        "         num_inter_units=2\n",
        "     )\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=1e-10)\n",
        "  loss_fn = nn.MSELoss() #SSIMLoss(spatial_dims=3)\n",
        "\n",
        "  wrapper = ModelWrapper(model = model,\n",
        "                            loss_fn = loss_fn,\n",
        "                            optimizer = optimizer,\n",
        "                            supervised = supervised,\n",
        "                            num_epochs = num_epochs,\n",
        "                            LOAD_MODEL = LOAD_MODEL\n",
        "                        )\n",
        "\n",
        "  dataset = DataPreprocessor(INPUT_PATH = INPUT_PATH)\n",
        "\n",
        "  # Split dataset if it's not\n",
        "  if(not os.path.exists(TRAIN_PATH)):\n",
        "    dataset.split_dataset()\n",
        "\n",
        "\n",
        "  train_dataset = DataPreprocessor(INPUT_PATH = TRAIN_PATH)\n",
        "  val_dataset = DataPreprocessor(INPUT_PATH = VAL_PATH)\n",
        "  test_dataset = DataPreprocessor(INPUT_PATH = TEST_PATH)\n",
        "\n",
        "  train_loader = DataLoader(dataset = train_dataset,\n",
        "                           sampler = SeqSampler(train_dataset),\n",
        "                           batch_size = batch_size,\n",
        "                           num_workers = num_workers)\n",
        "\n",
        "  val_loader = DataLoader(dataset = val_dataset,\n",
        "                           sampler = SeqSampler(val_dataset),\n",
        "                           batch_size = batch_size,\n",
        "                           num_workers = num_workers)\n",
        "\n",
        "  test_loader = DataLoader(dataset = test_dataset,\n",
        "                           sampler = SeqSampler(test_dataset),\n",
        "                           batch_size = batch_size,\n",
        "                           num_workers = num_workers)\n",
        "\n",
        "\n",
        "  print('Elapsed epochs: ' + str(wrapper.elapsed_epochs))\n",
        "\n",
        "if(TRAIN_MODEL):\n",
        "      training_loss, validation_loss = wrapper.train(train_loader = train_loader, val_loader = val_loader )\n",
        "      torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "UZ5ItOcISTzW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "  xx = range(1,wrapper.elapsed_epochs+1)\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.plot(xx, wrapper.training_loss, '-o', label = 'Train')\n",
        "  plt.plot(xx, wrapper.validation_loss,'-o', label = 'Val')\n",
        "  plt.legend(loc='lower left')"
      ],
      "metadata": {
        "id": "Bo0aQf08rHvn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "\n",
        "  slice_index = 150\n",
        "  ax = 0\n",
        "\n",
        "  im_test, lab = next(iter(test_loader))\n",
        "  output = wrapper.predict(data = im_test)\n",
        "  out = output[0]\n",
        "  out_numpy = out.cpu().detach().numpy()\n",
        "  im_test_numpy = im_test.cpu().detach().numpy()\n",
        "\n",
        "  plot_reconstruction(im_orig = np.sum(im_test_numpy[0], axis=0), im_rec = np.sum(out_numpy, axis = 0), ax = ax, slice_index = slice_index)\n",
        "  plot_brain_sections([im_test[0], lab[0]], ax = ax, slice_index = slice_index)"
      ],
      "metadata": {
        "id": "DvvSdXEvIw5w"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "  ker = wrapper.model.decode[0][0][0].weight.detach().clone()\n",
        "  print(ker.size())\n",
        "  #\n",
        "  visTensor(ker[0], allkernels=True)\n",
        "\n",
        "  ker = wrapper.model.decode[0][0][0].weight.detach().clone()\n",
        "  print(ker.size())\n",
        "  #\n",
        "  visTensor(torch.sum(ker, dim=(0)), allkernels=True)\n",
        "\n",
        "  kk = torch.sum(ker, dim= 0)\n",
        "  kk = torch.sum(kk, dim = 0)\n",
        "  plt.imshow(kk[0,:,:].cpu().detach().numpy())"
      ],
      "metadata": {
        "id": "ETwFBvf1Zjyp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING SECTION ðŸš§"
      ],
      "metadata": {
        "id": "n1_TRMmsm6jY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#! rm -r /content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled\n",
        "#! rm -r /content/drive/MyDrive/Lorusso/BraTS/data/interim/train\n",
        "#! rm -r /content/drive/MyDrive/Lorusso/BraTS/data/interim/test\n",
        "#! rm -r /content/drive/MyDrive/Lorusso/BraTS/data/interim/val"
      ],
      "metadata": {
        "id": "bC-ortIQ3vXX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autoencoder"
      ],
      "metadata": {
        "id": "kJUctzmLazd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "TEST_MODE = False\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if(TEST_MODE):\n",
        "\n",
        "    INPUT_PATH = '/content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled'\n",
        "    INPUT_PATH_PARENT = '/'.join(INPUT_PATH.split('/')[:-1])\n",
        "    TRAIN_PATH = os.path.join(INPUT_PATH_PARENT,'train')\n",
        "    VAL_PATH = os.path.join(INPUT_PATH_PARENT,'val')\n",
        "    TEST_PATH = os.path.join(INPUT_PATH_PARENT,'test')\n",
        "\n",
        "    TRAIN_MODEL = False\n",
        "    LOAD_MODEL = False # resume training\n",
        "\n",
        "    num_workers = 0\n",
        "    batch_size = 1\n",
        "    num_epochs = 2\n",
        "    lr = 0.01\n",
        "    supervised = False\n",
        "    eval_metrics = [nn.MSELoss()]\n",
        "\n",
        "  # MONAI AUTOENCODER\n",
        "    model = AutoEncoder(\n",
        "           spatial_dims=3,\n",
        "           kernel_size = 3,\n",
        "           up_kernel_size = 3,\n",
        "           in_channels=4,\n",
        "           out_channels=4,\n",
        "           channels=(5,),\n",
        "           strides=(2,),\n",
        "           inter_channels=(8, 16, 32),\n",
        "           inter_dilations=(1, 2, 4),\n",
        "           num_inter_units=2\n",
        "       )\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=1e-10)\n",
        "    loss_fn = nn.MSELoss() #SSIMLoss(spatial_dims=3)\n",
        "\n",
        "    wrapper = ModelWrapper(model = model,\n",
        "                              loss_fn = loss_fn,\n",
        "                              optimizer = optimizer,\n",
        "                              supervised = supervised,\n",
        "                              num_epochs = num_epochs,\n",
        "                              LOAD_MODEL = LOAD_MODEL,\n",
        "                              eval_metrics = eval_metrics\n",
        "                          )\n",
        "\n",
        "    dataset = DataPreprocessor(INPUT_PATH = INPUT_PATH)\n",
        "\n",
        "    # Split dataset if it's not\n",
        "    if(not os.path.exists(TRAIN_PATH)):\n",
        "      dataset.split_dataset()\n",
        "\n",
        "\n",
        "    train_dataset = DataPreprocessor(INPUT_PATH = TRAIN_PATH)\n",
        "    val_dataset = DataPreprocessor(INPUT_PATH = VAL_PATH)\n",
        "    test_dataset = DataPreprocessor(INPUT_PATH = TEST_PATH)\n",
        "\n",
        "    train_loader = DataLoader(dataset = train_dataset,\n",
        "                             sampler = SeqSampler(train_dataset),\n",
        "                             batch_size = batch_size,\n",
        "                             num_workers = num_workers)\n",
        "\n",
        "    val_loader = DataLoader(dataset = val_dataset,\n",
        "                             sampler = SeqSampler(val_dataset),\n",
        "                             batch_size = batch_size,\n",
        "                             num_workers = num_workers)\n",
        "\n",
        "    test_loader = DataLoader(dataset = test_dataset,\n",
        "                             sampler = SeqSampler(test_dataset),\n",
        "                             batch_size = batch_size,\n",
        "                             num_workers = num_workers)\n",
        "\n",
        "\n",
        "    print('Elapsed epochs: ' + str(wrapper.elapsed_epochs))\n",
        "\n",
        "    if(TRAIN_MODEL):\n",
        "        training_loss, validation_loss = wrapper.train(train_loader = train_loader, val_loader = val_loader, experiment_prefix = 'Test' )\n",
        "        torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "eHHzhDDF_3G9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "  xx = range(1,wrapper.elapsed_epochs+1)\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.plot(xx, wrapper.training_loss, '-o', label = 'Train')\n",
        "  plt.plot(xx, wrapper.validation_loss,'-o', label = 'Val')\n",
        "  plt.legend(loc='lower left')"
      ],
      "metadata": {
        "id": "CcuxwsmW9OYS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "\n",
        "  slice_index = 90\n",
        "  ax = 0\n",
        "\n",
        "  im_test, lab = next(iter(test_loader))\n",
        "  output = wrapper.predict(data = im_test)\n",
        "  out = output[0]\n",
        "  out_numpy = out.cpu().detach().numpy()\n",
        "  im_test_numpy = im_test.cpu().detach().numpy()\n",
        "\n",
        "  plot_reconstruction(im_orig = np.sum(im_test_numpy[0], axis=0), im_rec = np.sum(out_numpy, axis = 0), ax = ax, slice_index = slice_index)\n",
        "  plot_brain_sections([im_test[0], lab[0]], ax = ax, slice_index = slice_index)"
      ],
      "metadata": {
        "id": "V3TKi4A9O4NA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "  ker = wrapper.model.decode[0][0][0].weight.detach().clone()\n",
        "  print(ker.size())\n",
        "  #\n",
        "  visTensor(ker[1], allkernels=True)\n",
        "\n",
        "  ker = wrapper.model.decode[0][0][0].weight.detach().clone()\n",
        "  print(ker.size())\n",
        "  #\n",
        "  visTensor(torch.sum(ker, dim=(0)), allkernels=True)\n",
        "\n",
        "  kk = torch.sum(ker, dim= 0)\n",
        "  kk = torch.sum(kk, dim = 0)\n",
        "  plt.imshow(kk[0,:,:].cpu().detach().numpy())"
      ],
      "metadata": {
        "id": "s5fwjWaWOhXN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GNN training â›½"
      ],
      "metadata": {
        "id": "T-lpiQp3XNxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#start = time.time()\n",
        "## Create graphs\n",
        "#train_dataset.run()\n",
        "#end = time.time() - start\n",
        "#end"
      ],
      "metadata": {
        "id": "Em_z0SdDa5vx"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "TEST_MODE = True\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if(TEST_MODE):\n",
        "\n",
        "    INPUT_PATH = '/content/drive/MyDrive/Lorusso/BraTS/data/processed_5000_0.5_10'\n",
        "    INPUT_PATH_PARENT = '/'.join(INPUT_PATH.split('/')[:-1])\n",
        "    TRAIN_PATH = os.path.join(INPUT_PATH_PARENT,'train')\n",
        "    VAL_PATH = os.path.join(INPUT_PATH_PARENT,'val')\n",
        "    TEST_PATH = os.path.join(INPUT_PATH_PARENT,'test')\n",
        "\n",
        "    TRAIN_MODEL = True\n",
        "    LOAD_MODEL = False # resume training\n",
        "\n",
        "    num_workers = 0\n",
        "    batch_size = 1\n",
        "    num_epochs = 2\n",
        "    lr = 0.01\n",
        "    supervised = True\n",
        "    eval_metrics = []\n",
        "\n",
        "    dropout = 0\n",
        "    input_feats = 20\n",
        "    class_weights = torch.Tensor([0.1,1,2,2])\n",
        "    layer_sizes=[256]*4\n",
        "    n_classes=4\n",
        "    aggregator_type='pool'\n",
        "\n",
        "    dict_params = {k:eval(k) for k in ['input_feats', 'class_weights', 'layer_sizes', 'n_classes', 'aggregator_type', 'n_classes']}\n",
        "\n",
        "    model = GraphSage(in_feats=input_feats,layer_sizes=layer_sizes,n_classes=n_classes,aggregator_type=aggregator_type,dropout=dropout)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(),lr=lr,weight_decay=1e-10)\n",
        "    loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "    wrapper = ModelWrapper(model = model,\n",
        "                              loss_fn = loss_fn,\n",
        "                              optimizer = optimizer,\n",
        "                              supervised = supervised,\n",
        "                              dict_params = dict_params,\n",
        "                              num_epochs = num_epochs,\n",
        "                              LOAD_MODEL = LOAD_MODEL,\n",
        "                              eval_metrics = eval_metrics\n",
        "                          )\n",
        "\n",
        "\n",
        "    train_dataset = ImageGraphDataset(TRAIN_PATH,'BraTS2021',read_image=False,read_graph=True,read_label=True)\n",
        "    val_dataset = ImageGraphDataset(VAL_PATH,'BraTS2021',read_image=False,read_graph=True,read_label=True)\n",
        "    test_dataset = ImageGraphDataset(TEST_PATH,'BraTS2021',read_image=False,read_graph=True,read_label=True)\n",
        "\n",
        "    train_loader = DataLoader(dataset = train_dataset,\n",
        "                             sampler = SeqSampler(train_dataset),\n",
        "                             batch_size = batch_size,\n",
        "                             num_workers = num_workers)\n",
        "\n",
        "    val_loader = DataLoader(dataset = val_dataset,\n",
        "                             sampler = SeqSampler(val_dataset),\n",
        "                             batch_size = batch_size,\n",
        "                             num_workers = num_workers)\n",
        "\n",
        "    test_loader = DataLoader(dataset = test_dataset,\n",
        "                             sampler = SeqSampler(test_dataset),\n",
        "                             batch_size = batch_size,\n",
        "                             num_workers = num_workers)\n",
        "\n",
        "\n",
        "    print('Elapsed epochs: ' + str(wrapper.elapsed_epochs))\n",
        "\n",
        "    if(TRAIN_MODEL):\n",
        "        training_loss, validation_loss = wrapper.train(train_loader = train_loader, val_loader = None, experiment_prefix = 'Test_GNN' )\n",
        "        torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVWsu1gEXV9j",
        "outputId": "a4c58112-297a-4ec2-a8b7-8fad08145676"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 MRIs\n",
            "Found 0 MRIs\n",
            "Found 0 MRIs\n",
            "Elapsed epochs: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023/12/13 18:32:20 INFO mlflow.tracking.fluent: Experiment with name 'Test_GNNGraphSage' does not exist. Creating a new experiment.\n",
            "<ipython-input-9-0e7b9eac4fcb>:157: RuntimeWarning: Mean of empty slice.\n",
            "  training_loss.append(np.array(train_batch_loss).mean())\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1/2, Loss: nan, Epoch elapsed time: 0 sec \n",
            "\n",
            "Total training time: 5 sec\n",
            "\n",
            "Epoch: 2/2, Loss: nan, Epoch elapsed time: 0 sec \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "2023/12/13 18:32:30 WARNING mlflow.utils.requirements_utils: Found torch version (2.1.0+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torch==2.1.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training time: 10 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023/12/13 18:32:36 WARNING mlflow.utils.requirements_utils: Found torch version (2.1.0+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torch==2.1.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
            "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLFlow transitioner\n",
        "\n",
        "Helps to bring a model saved with pickle to MLFlow"
      ],
      "metadata": {
        "id": "kVH1teeglI4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if(False):\n",
        "    checkpoint = torch.load(wrapper.save_path, map_location=torch.device(wrapper.device))\n",
        "    wrapper.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    wrapper.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    wrapper.elapsed_epochs = checkpoint['epochs']\n",
        "    wrapper.training_loss = checkpoint['training_loss']\n",
        "    wrapper.validation_loss = checkpoint['validation_loss']\n",
        "    wrapper.elapsed_seconds = checkpoint['elapsed_seconds']\n",
        "    try:\n",
        "        mlflow.set_experiment('BraTS_'+wrapper.model.__class__.__name__)\n",
        "        mlflow.start_run()\n",
        "        param_dict = {\n",
        "            'batch_size':train_loader.batch_size,\n",
        "            'optimizer':wrapper.optimizer.__class__.__name__,\n",
        "            'learning_rate':wrapper.optimizer.state_dict()['param_groups'][0]['lr'],\n",
        "            'loss_fn':wrapper.loss_fn.__class__.__name__\n",
        "        }\n",
        "        mlflow.log_params(param_dict)\n",
        "\n",
        "        #sample_input,_ = next(iter(train_loader))\n",
        "        #sample_output = wrapper.predict(sample_input)\n",
        "        #signature = infer_signature(sample_input.numpy(), sample_output.numpy())\n",
        "    #\n",
        "        #print(\"Model signature:\", signature)\n",
        "\n",
        "        for i in range(len(wrapper.training_loss)):\n",
        "            mlflow.log_metric('train_loss',wrapper.training_loss[i], step =i+1)\n",
        "        for i in range(len(wrapper.validation_loss)):\n",
        "            mlflow.log_metric('val_loss',wrapper.validation_loss[i], step =i+1)\n",
        "\n",
        "        val_dict = {\n",
        "              'model_state_dict': wrapper.model.state_dict(),\n",
        "              'optimizer_state_dict': wrapper.optimizer.state_dict(),\n",
        "              'elapsed_seconds': wrapper.elapsed_seconds,\n",
        "              'training_loss':wrapper.training_loss,\n",
        "              'validation_loss':wrapper.validation_loss\n",
        "              }\n",
        "\n",
        "        mlflow.pytorch.log_state_dict(val_dict,artifact_path=\"checkpoint\")\n",
        "        mlflow.pytorch.log_model(wrapper.model, artifact_path='model')\n",
        "\n",
        "        mlflow.end_run()\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        mlflow.end_run()"
      ],
      "metadata": {
        "id": "_xjPxt_lhQ7z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Ub1h-Y7DIpYf",
        "q7ygOSsiEAWs",
        "he-C8aZXQkry",
        "vsRN0nOwDif5",
        "mz-6k-tLLDbh",
        "kJUctzmLazd9",
        "kVH1teeglI4t"
      ],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}