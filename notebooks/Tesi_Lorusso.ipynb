{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## README â—\n",
        "\n",
        "Set a manual_seed for reproducibility.\n",
        "\n",
        "References:\n",
        "\n",
        "- See [Reproducibility](https://pytorch.org/docs/stable/notes/randomness.html)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ub1h-Y7DIpYf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### TO-DO âœ…\n",
        "\n",
        "\n",
        "#### FIX ðŸ§¯\n",
        "\n",
        "\n",
        "Quando viene sollevata un'eccezione in DataPreprocessor.__getitem __ viene restituito uno stack di immagini vuote. Aggiungere il relativo ID ad una lista e in fase di training evitare che queste immagini nere vengano incluse nel batch. Magari sostituendo a queste una delle immagini valide presenti nello stesso batch.\n"
      ],
      "metadata": {
        "id": "Yj5kNWe7UKif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment setup ðŸ›\n"
      ],
      "metadata": {
        "id": "mwFJcAuef07T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install python-dotenv\n",
        "! pip install monai\n",
        "! pip install shutil\n",
        "! pip install mlflow --quiet\n",
        "! pip install pyngrok --quiet\n",
        "! pip install torchmetrics\n",
        "! pip install dgl\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "sys.path.append('/content/drive/MyDrive/Lorusso/BraTS/')\n",
        "\n",
        "\n",
        "from src.preprocess.image_processing import *\n",
        "from src.preprocess.nifti_io import *\n",
        "from src.preprocess.graphgen import *\n",
        "from src.preprocess.graph_io import *\n",
        "\n",
        "from mlflow.models.signature import infer_signature\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "from pyngrok import ngrok\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dotenv import load_dotenv\n",
        "import concurrent.futures\n",
        "import tarfile\n",
        "import nibabel as nib\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "from distutils.dir_util import copy_tree\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import SequentialSampler\n",
        "from torchvision import utils\n",
        "\n",
        "from monai.networks.nets import AutoEncoder\n",
        "from monai.losses import DiceCELoss, DiceFocalLoss, DiceLoss, FocalLoss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "id": "45BU03HjgAgT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d728649-01a3-4f8f-f092-40c63be15370"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n",
            "Collecting monai\n",
            "  Downloading monai-1.3.0-202310121228-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from monai) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from monai) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->monai) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->monai) (1.3.0)\n",
            "Installing collected packages: monai\n",
            "Successfully installed monai-1.3.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement shutil (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for shutil\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m230.6/230.6 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchmetrics\n",
            "  Downloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu118)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.10.0 torchmetrics-1.2.1\n",
            "Collecting dgl\n",
            "  Downloading dgl-1.1.3-cp310-cp310-manylinux1_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.11.17)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.1.3\n",
            "Mounted at /content/drive/\n",
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "if [ ! -f '/content/drive/MyDrive/Lorusso/BraTS/.env' ]; then\n",
        "    echo \"Creating .env file...\"\n",
        "    echo \"INPUT_DATA_DIR='/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats'\" > '/content/drive/MyDrive/Lorusso/BraTS/.env'\n",
        "    echo \"PROCESSED_DATA_DIR='/content/drive/MyDrive/Lorusso/BraTS/data/processed'\" >> '/content/drive/MyDrive/Lorusso/BraTS/.env'\n",
        "fi"
      ],
      "metadata": {
        "id": "MkZwkHg4Wn_e"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "if [ ! -f '/content/drive/MyDrive/Lorusso/BraTS/data/raw/BraTS2021_Training_Data.tar'  ]; then\n",
        "    echo \"Downloading BraTS dataset at /content/drive/MyDrive/Lorusso/BraTS/data/raw ...\"\n",
        "    mkdir /root/.kaggle/\n",
        "    cp '/content/drive/MyDrive/Lorusso/kaggle.json' /root/.kaggle\n",
        "    chmod 600 '/root/.kaggle/kaggle.json'\n",
        "    cd '/content/drive/MyDrive/Lorusso/BraTS/data/raw' && kaggle datasets download -d dschettler8845/brats-2021-task1\n",
        "    ls '/content/drive/MyDrive/Lorusso/BraTS/data/raw'\n",
        "    unzip '/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats-2021-task1.zip' -d '/content/drive/MyDrive/Lorusso/BraTS/data/raw/'\n",
        "    rm -r '/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats-2021-task1.zip'\n",
        "fi"
      ],
      "metadata": {
        "id": "0u_tX1q-hh-L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "path='/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats'\n",
        "dst='/content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled/'\n",
        "\n",
        "rm -r '/content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled'\n",
        "if [ ! -d '/content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled' ]; then\n",
        "\n",
        "    mkdir '/content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled'\n",
        "\n",
        "    rm -r /content/drive/MyDrive/Lorusso/BraTS/data/interim/train\n",
        "    rm -r /content/drive/MyDrive/Lorusso/BraTS/data/interim/test\n",
        "    rm -r /content/drive/MyDrive/Lorusso/BraTS/data/interim/val\n",
        "\n",
        "    for el in $(ls $path | head -n 3);\n",
        "        do\n",
        "            echo \"$path/$el -> $dst\"\n",
        "            cp -R \"$path/$el\" $dst\n",
        "        done\n",
        "fi\n"
      ],
      "metadata": {
        "id": "2dm-FkQK1izU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f966dcb5-1c87-4e76-d34d-54e7c6d3af37"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00000 -> /content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled/\n",
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00002 -> /content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled/\n",
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00003 -> /content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLFlow server"
      ],
      "metadata": {
        "id": "wE7OwGBES7sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_tracking_uri('file:///content/drive/MyDrive/Lorusso/BraTS/mlruns')\n",
        "\n",
        "# Terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "# Get your authtoken from https://dashboard.ngrok.com/auth\n",
        "NGROK_AUTH_TOKEN = \"2Yliuv8VnNyKNcljxgEv6NpZgz8_6ZDBYmEcebUeoX93eGJAE\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# Open an HTTPs tunnel on port 5000 for http://localhost:5000\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)\n",
        "\n",
        "# run tracking UI in the background\n",
        "get_ipython().system_raw(\"mlflow ui --backend-store-uri file:///content/drive/MyDrive/Lorusso/BraTS/mlruns --port 5000 & \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4-kysoZS-i4",
        "outputId": "7c416270-0721-4c14-c7c9-dd3646d1e2c2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLflow Tracking UI: https://45a4-34-126-132-163.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils ðŸ› "
      ],
      "metadata": {
        "id": "q7ygOSsiEAWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def untar_brats(tar_path, extract_path):\n",
        "    tar = tarfile.open(tar_path)\n",
        "    tar.extractall(extract_path)\n",
        "    tar.close()\n",
        "\n",
        "\n",
        "\n",
        "def plot_reconstruction(im_orig, im_rec, ax:int = 0, slice_index:int = 100):\n",
        "\n",
        "    f, ax_array = plt.subplots(1,2, figsize=(10,10))\n",
        "    ax_array[0].imshow(np.take(im_orig, indices = slice_index, axis = ax), cmap='gray')\n",
        "    ax_array[1].imshow(np.take( im_rec , indices=slice_index, axis = ax), cmap='gray')\n",
        "\n",
        "def plot_brain_sections(images,ax = 1,slice_index = 90):\n",
        "\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "\n",
        "    d1,d2,d3 = np.shape(images[1])\n",
        "    dims = [d1,d2,d3]\n",
        "    dims.pop(ax)\n",
        "    color_segmentation = np.zeros((dims[0],dims[1],3))\n",
        "\n",
        "    gray_segmentation = np.take(images[1],slice_index,axis = ax)\n",
        "    color_segmentation[gray_segmentation == 1] = [255,0,0] # Red (necrotic tumor core)\n",
        "    color_segmentation[gray_segmentation == 2] = [0,255,0] # Green (peritumoral edematous/invaded tissue)\n",
        "    color_segmentation[gray_segmentation == 4] = [0,0,255] # Blue (enhancing tumor)\n",
        "\n",
        "    t1 = images[0][0]\n",
        "    flair = images[0][1]\n",
        "    t2 = images[0][2]\n",
        "    t1ce = images[0][3]\n",
        "\n",
        "    image = t1+t2+flair+t1ce\n",
        "\n",
        "    plt.figure(figsize=(15,15))\n",
        "    plt.subplot(1,4,1)\n",
        "    plt.imshow(np.take(image,slice_index,axis = 0),cmap='gray')\n",
        "\n",
        "    plt.subplot(1,4,2)\n",
        "    plt.imshow(np.take(image,slice_index,axis = 1),cmap='gray')\n",
        "\n",
        "    plt.subplot(1,4,3)\n",
        "    plt.imshow(np.take(image,slice_index,axis = 2),cmap='gray')\n",
        "\n",
        "    plt.subplot(1,4,4)\n",
        "    plt.imshow(color_segmentation,cmap='gray')\n",
        "    plt.xlabel('Segmentation')\n",
        "\n",
        "\n",
        "def visTensor(tensor, ch=0, allkernels=False, nrow=8, padding=1):\n",
        "    n,c,w,h = tensor.shape\n",
        "    if allkernels: tensor = tensor.view(n*c, -1, w, h)\n",
        "    elif c != 3: tensor = tensor[:,ch,:,:].unsqueeze(dim=1)\n",
        "    rows = np.min((tensor.shape[0] // nrow + 1, 64))\n",
        "    grid = utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n",
        "    plt.figure( figsize=(nrow,rows) )\n",
        "    plt.imshow(grid.cpu().permute((1, 2, 0)))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Lrs_wCJEAJpS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset class  ðŸ’¾\n"
      ],
      "metadata": {
        "id": "aKEY_j_lCzCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Preprocessing script to convert from data provided by BraTS to data used by our model. Should be the first thing you run.\n",
        "Fulfills the following four functions:\n",
        "1. Normalize and standardize each image of each MRI modality\n",
        "2. Combine multiple MRI modalitities into one image array\n",
        "3. Swap labels from BraTS order (0,2,1,4) to more intuitive order (0,1,2,3)\n",
        "4. Convert image into a graph\n",
        "    Using Simple Linear Iterative Clustering algorithm\n",
        "    Parameters passed on command line\n",
        "\n",
        "If no labels are present (e.g. at test time, in deployment) can also build graph without labels.\n",
        "\n",
        "Saves the following in the specified output directory for each sample\n",
        "MRI_ID/\n",
        "    _input.nii.gz (processed and combined modalities for a sample as nifti file)\n",
        "    _label.nii.gz\n",
        "    _nxgraph.json (networkx graph containing both graph topography and features and labels for each node)\n",
        "    _supervoxels.nii.gz (supervoxel partitioning produced by SLIC)\n",
        "    _crop.npy (optionally the crop of the processed data relative to the original data) (crops out empty image planes)\n",
        "'''\n",
        "\n",
        "\n",
        "class DataPreprocessor(Dataset):\n",
        "    def __init__(self, dotenv_path = \"/content/drive/MyDrive/Lorusso/BraTS/.env\", transform = True, INPUT_PATH = None,\n",
        "                 num_nodes = 5000, boxiness_coef = 0.5, num_neighbors = 10):\n",
        "\n",
        "        load_dotenv(dotenv_path)\n",
        "        # Data mean and variance\n",
        "        data_stats = ([0.4645, 0.6625, 0.4064, 0.3648],\n",
        "                      [0.1593, 0.1703, 0.1216, 0.1627])\n",
        "        self.N_THREADS = 6\n",
        "\n",
        "        self.num_nodes = num_nodes\n",
        "        self.boxiness_coef = boxiness_coef\n",
        "        self.num_neighbors = num_neighbors\n",
        "\n",
        "        if(INPUT_PATH is not None and os.path.exists(INPUT_PATH)):\n",
        "            self.data_dir = INPUT_PATH\n",
        "        else:\n",
        "            self.data_dir = os.getenv('INPUT_DATA_DIR')\n",
        "        self.output_dir = os.getenv('PROCESSED_DATA_DIR')\n",
        "        self.mri_prefix = 'BraTS2021'\n",
        "        self.modality_extensions = [\"_flair.nii.gz\", \"_t1.nii.gz\", \"_t1ce.nii.gz\", \"_t2.nii.gz\"]\n",
        "        self.label_extension = \"_seg.nii.gz\"\n",
        "        self.include_labels = self.label_extension is not None\n",
        "        self.all_ids, self.id_to_fp = self.get_all_mris_in_dataset()\n",
        "        self.LABEL_MAP = {4: 3, 2: 1, 1: 2}\n",
        "        self.dataset_mean = np.array(data_stats[0], dtype=np.float32)\n",
        "        self.dataset_std = np.array(data_stats[1], dtype=np.float32)\n",
        "        self.transform = transform if isinstance(transform, bool) else True\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.all_ids)\n",
        "\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        images = []\n",
        "        # Load the image corresponding to idx\n",
        "        try:\n",
        "            fp = [self.id_to_fp[k] for k in self.all_ids if k.split('_')[-1] == idx][0]\n",
        "            bn = os.path.basename(os.path.split(fp)[0])\n",
        "            images.append([nib.load(os.path.join(fp, bn + level)).get_fdata(dtype=np.float32).T\n",
        "                           for level in self.modality_extensions])\n",
        "            labels = nib.load(os.path.join(fp, bn + self.label_extension)).get_fdata(dtype=np.float32).T\n",
        "\n",
        "            # Convert to numpy array otherwise you'll experience RAM leak\n",
        "            images = np.asarray(images[0])\n",
        "            imstack = np.stack(np.array(images, dtype=np.float32), axis = 0)\n",
        "            imstack, labels = self.padding(imstack, labels)\n",
        "\n",
        "            if (self.transform):\n",
        "                imstack,labels = self.get_standardized_image(imstack, labels)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Exception thrown in class {self.__class__.__name__ }, method __getitem__\")\n",
        "            print(e)\n",
        "            imstack = np.zeros([4,240,240,240],dtype=np.float32)\n",
        "            labels = np.zeros([240, 240, 240])\n",
        "\n",
        "        return np.array(imstack), labels\n",
        "\n",
        "    def image_to_graph(self, mri_id):\n",
        "        # NB: be careful to pass only the number to __getitem__ and not all the string.\n",
        "        # Example: Given the MRI Brats_00000 we need to pass to image_to_graph only '00000'\n",
        "        imstack, labels = self.__getitem__(mri_id.split('_')[-1])\n",
        "        save_path = f\"{self.output_dir}_{self.num_nodes}_{self.boxiness_coef}_{self.num_neighbors}{os.sep}{os.path.basename(self.data_dir)}{os.sep}{mri_id}\"\n",
        "\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "            # TRANSPOSE variable imstack because img2graph expects channel-first images\n",
        "            nx_graph,node_feats,region_img = img2graph(imstack.T,labels,self.num_nodes,self.boxiness_coef,self.num_neighbors)\n",
        "            #save in correct folder\n",
        "\n",
        "            save_networkx_graph(nx_graph, f\"{save_path}{os.sep}{mri_id}_nxgraph.json\")\n",
        "            save_as_nifti(imstack,f\"{save_path}{os.sep}{mri_id}_input.nii.gz\")\n",
        "            save_as_nifti(labels,f\"{save_path}{os.sep}{mri_id}_label.nii.gz\")\n",
        "            save_as_nifti(region_img,f\"{save_path}{os.sep}{mri_id}_supervoxels.nii.gz\")\n",
        "\n",
        "        return mri_id\n",
        "\n",
        "    def run(self):\n",
        "        with concurrent.futures.ThreadPoolExecutor(max_workers=self.N_THREADS) as executor:\n",
        "            futures = [executor.submit(self.image_to_graph, mri_id) for mri_id in self.all_ids]\n",
        "            print(\"Set up Threads, starting execution\")\n",
        "            for future in concurrent.futures.as_completed(futures):\n",
        "                try:\n",
        "                    mri_id = future.result()\n",
        "                except Exception as exc:\n",
        "                    print(\"Execption caught in DataPreprocessor.run\")\n",
        "                    print(f\"{exc}\")\n",
        "                else:\n",
        "                    print(\"Finished \"+ mri_id)\n",
        "\n",
        "\n",
        "\n",
        "    def get_all_mris_in_dataset(self):\n",
        "        mri_folders = glob.glob(f\"{self.data_dir}**/{self.mri_prefix}*/\",\n",
        "                                recursive=True)\n",
        "        mri_folders = self.remove_incomplete_mris(mri_folders)\n",
        "        scan_dic = {os.path.split(fp)[0].split(\"/\")[-1]: fp for fp in mri_folders}\n",
        "        if(len(mri_folders) == 0):\n",
        "            print(\"No MRI found at \" + self.data_dir)\n",
        "        return list(scan_dic.keys()), scan_dic\n",
        "\n",
        "\n",
        "    def remove_incomplete_mris(self, mri_folders):\n",
        "        # if there are any you want to ignore just add them to this list\n",
        "        removed_mris = []\n",
        "        return [fp for fp in mri_folders if fp.split(\"/\")[-2] not in removed_mris]\n",
        "\n",
        "\n",
        "    def split_dataset(self, ratio = (.6,.2,.2),seed = 42):\n",
        "\n",
        "        random.seed(seed)\n",
        "        if(np.sum(ratio) != 1 or ratio is None):\n",
        "          print(\"Error: ratio does not sum up to one.\\nSwitching to default (.6,.2,.2))\")\n",
        "          ratio = (.6,.2,.2)\n",
        "\n",
        "        train_length = int(len(self.all_ids)*ratio[0])\n",
        "        val_length = int(len(self.all_ids)*ratio[1])\n",
        "        test_length = int(len(self.all_ids)*ratio[2])\n",
        "        pos = random.sample(range(0,len(self.all_ids)), len(self.all_ids))\n",
        "\n",
        "        split_dict = {\n",
        "            'train': [self.all_ids[i] for i in pos[:train_length]],\n",
        "            'val': [self.all_ids[i] for i in pos[train_length :train_length + val_length]],\n",
        "            'test': [self.all_ids[i] for i in pos[train_length + val_length:]]\n",
        "        }\n",
        "\n",
        "        for k in split_dict.keys():\n",
        "          parent = '/'.join(self.data_dir.split('/')[:-1])\n",
        "          dst = os.path.join(parent,k)\n",
        "\n",
        "          try:\n",
        "            # create train,val,test dirs\n",
        "            if(not os.path.exists(dst)):\n",
        "              os.mkdir(dst)\n",
        "\n",
        "            # copy splitted data inside folders\n",
        "            for id in split_dict[k]:\n",
        "              if(not os.path.exists(os.path.join(dst,id))):\n",
        "                 os.mkdir(os.path.join(dst,id))\n",
        "              copy_tree(self.id_to_fp[id],os.path.join(dst,id))\n",
        "\n",
        "          except Exception as e:\n",
        "            print(f\"Exception thrown in class {self.__class__.__name__ }, method split_dataset\")\n",
        "            print(e)\n",
        "\n",
        "\n",
        "    def padding(self,image, labels):\n",
        "        n_channels = np.shape(image)[0]\n",
        "        max_val = max(np.shape(image))\n",
        "        pad_list = np.zeros([n_channels,max_val,max_val,max_val],dtype=np.float32)\n",
        "\n",
        "        for channel in range(0, n_channels): # pad every channel\n",
        "            pad_list[channel] = np.pad(image[channel],[(42,43),(0,0),(0,0)],'constant')\n",
        "        labels = np.pad(labels, [(42,43),(0,0),(0,0)],'constant')\n",
        "\n",
        "        return pad_list, labels\n",
        "\n",
        "\n",
        "    def get_standardized_image(self, image_data, label_data):\n",
        "\n",
        "        standardized_labels = self.swap_labels_from_brats(label_data)\n",
        "        #standardized_data = self.standardize_img(\n",
        "        #    image_data, self.dataset_mean, self.dataset_std)\n",
        "        #normalized_data = self.standardize_img(image_data)\n",
        "        normalized_data = self.normalize_img(image_data)\n",
        "        return normalized_data, standardized_labels\n",
        "\n",
        "\n",
        "    def normalize_img(self, img_array):\n",
        "        new_image = np.zeros(img_array.shape, dtype=np.float32)\n",
        "        n_channel = img_array.shape[0] # channel-first images\n",
        "\n",
        "        for channel in range(0, n_channel): # normalize every channel\n",
        "\n",
        "            maxval, minval= np.max(img_array[channel]), np.min(img_array[channel])\n",
        "            new_image[channel] = (img_array[channel] - minval)/(maxval-minval)\n",
        "\n",
        "        return new_image\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def normalize_img_quantile(self, img_array):\n",
        "        quantile = np.quantile(img_array, 0.995, axis = (0,1,2,3) )\n",
        "        return img_array/quantile\n",
        "\n",
        "\n",
        "\n",
        "    def standardize_img(self,img_array):\n",
        "        img_array = img_array.T # Align shapes\n",
        "        centered = img_array-self.dataset_mean\n",
        "        standardized = centered/self.dataset_std\n",
        "        return standardized.T\n",
        "\n",
        "\n",
        "    def swap_labels_from_brats(self,label_data):\n",
        "        uniques = np.unique(label_data)\n",
        "        for u in uniques:\n",
        "            if u not in [0, 1, 2, 4]:\n",
        "                raise RuntimeError('unexpected label')\n",
        "        new_label_data = np.zeros_like(label_data, dtype=np.int16)\n",
        "        new_label_data[label_data == 4] = self.LABEL_MAP[4]\n",
        "        new_label_data[label_data == 2] = self.LABEL_MAP[2]\n",
        "        new_label_data[label_data == 1] = self.LABEL_MAP[1]\n",
        "        return new_label_data\n",
        "\n",
        "    def swap_labels_to_brats(self,label_data):\n",
        "        uniques = np.unique(label_data)\n",
        "        for u in uniques:\n",
        "            if u not in [0, 1, 2, 3]:\n",
        "                raise RuntimeError('unexpected label')\n",
        "        new_label_data = np.zeros_like(label_data, dtype=np.int16)\n",
        "        new_label_data[label_data == self.LABEL_MAP[4]] = 4\n",
        "        new_label_data[label_data == self.LABEL_MAP[2]] = 2\n",
        "        new_label_data[label_data == self.LABEL_MAP[1]] = 1\n",
        "        return new_label_data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class SeqSampler(SequentialSampler):\n",
        "    \"\"\"Samples elements sequentially, always in the same order.\n",
        "\n",
        "    Args:\n",
        "        data_source (Dataset): dataset to sample from\n",
        "    \"\"\"\n",
        "    def __init__(self, data_source:Dataset):\n",
        "        self.data_source = data_source\n",
        "        self.indexDict = [id.split('_')[1] for id in data_source.all_ids]\n",
        "    def __iter__(self):\n",
        "        return iter(self.indexDict)\n",
        "    def __len__(self):\n",
        "        return len(self.indexDict)\n"
      ],
      "metadata": {
        "id": "-Pa_KNzpRi0d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models ðŸ“ª\n"
      ],
      "metadata": {
        "id": "cgINpL8BK3hL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder3D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder3D, self).__init__()\n",
        "        # Encoder\n",
        "        self.activation = nn.ReLU()\n",
        "        #self.activation = nn.LogSigmoid()# nn.Tanh()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.conv1 = nn.Conv3d(4, 8, 3)\n",
        "        self.conv2 = nn.Conv3d(8, 32, 3)\n",
        "        self.conv3 = nn.Conv3d(64, 256, 2)\n",
        "        self.pool1 = nn.MaxPool3d(kernel_size=2, stride=2, return_indices=True)\n",
        "        self.pool2 = nn.MaxPool3d(kernel_size=2, stride=2, return_indices=True)\n",
        "        self.pool3 = nn.MaxPool3d(kernel_size=2, stride=2, return_indices=True)\n",
        "        self.enc_linear = nn.Linear(381216, 512)\n",
        "\n",
        "        # Decoder\n",
        "        self.deconv1 = nn.ConvTranspose3d(256, 64, 2)\n",
        "        self.deconv2 = nn.ConvTranspose3d(32, 8, 3)\n",
        "        self.deconv3 = nn.ConvTranspose3d(8, 4, 3)\n",
        "        self.unpool1 = nn.MaxUnpool3d(kernel_size=2, stride=2)\n",
        "        self.unpool2 = nn.MaxUnpool3d(kernel_size=2, stride=2)\n",
        "        self.unpool3 = nn.MaxUnpool3d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.dec_linear = nn.Linear(512, 381216)\n",
        "\n",
        "    def encode(self, x, return_partials=True):\n",
        "        # Encoder\n",
        "        x = self.conv1(x)\n",
        "        x = self.activation(x)\n",
        "        up3out_shape = x.shape\n",
        "        x, indices1 = self.pool1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.activation(x)\n",
        "        up2out_shape = x.shape\n",
        "        x, indices2 = self.pool2(x)\n",
        "\n",
        "        #x = self.conv3(x)\n",
        "        #x = self.activation(x)\n",
        "        #up1out_shape = x.shape\n",
        "        #x, indices3 = self.pool3(x)\n",
        "\n",
        "\n",
        "\n",
        "        #print(x.shape)\n",
        "        #x = x.view((x.size(0), -1))\n",
        "        #print(x.shape)\n",
        "        #x = self.enc_linear(x)\n",
        "\n",
        "        # required for unpool\n",
        "        pool_par = {\n",
        "            \"P1\": [indices1, up3out_shape],\n",
        "            \"P2\": [indices2, up2out_shape],\n",
        "            #\"P3\": [indices3, up1out_shape]\n",
        "                   }\n",
        "\n",
        "        if return_partials:\n",
        "            return x, pool_par\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "    def decode(self, x, pool_par):\n",
        "        #x = self.dec_linear(x)\n",
        "        #x = x.view((x.size(0), 96, 11, 19, 19))\n",
        "\n",
        "        #x = self.unpool1(x, output_size=pool_par[\"P3\"][1], indices=pool_par[\"P3\"][0])\n",
        "        ##print(x.shape)\n",
        "        #x = self.deconv1(x)\n",
        "        #x = self.activation(x)\n",
        "\n",
        "        x = self.unpool2(x, output_size=pool_par[\"P2\"][1], indices=pool_par[\"P2\"][0])\n",
        "        x = self.deconv2(x)\n",
        "        x = self.activation(x)\n",
        "#\n",
        "        x = self.unpool3(x, output_size=pool_par[\"P1\"][1], indices=pool_par[\"P1\"][0])\n",
        "        x = self.deconv3(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.feature, pool_par = self.encode(x)\n",
        "        out = self.decode(self.feature, pool_par)\n",
        "        return out"
      ],
      "metadata": {
        "id": "O4dkf94oMgZz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, slope = 0.2):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv3d(4, 16, kernel_size=(3,3,3), stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm3d(16),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv3d(16, 64 , kernel_size=(3,3,3), stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm3d(64),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose3d(64, 16, kernel_size=(3,3,3), stride=2, padding=1,output_padding=1, bias=False),\n",
        "\n",
        "            nn.ConvTranspose3d(16, 4, kernel_size=(3,3,3), stride=2, padding=1, output_padding=1, bias=False),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n"
      ],
      "metadata": {
        "id": "dj9rmyw_LXS6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Wrapper ðŸ“¨\n"
      ],
      "metadata": {
        "id": "0u3q4OhjYyGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelWrapper():\n",
        "    \"\"\"\n",
        "    Allows train, evaluation, prediction and I/O operations on generic PyTorch models\n",
        "    The model is saved at every epoch.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model: nn.Module, optimizer: nn.Module, loss_fn: nn.Module,\n",
        "                 num_epochs: int, supervised: bool = True, LOAD_MODEL: bool = False,\n",
        "                 model_path: str  = '/content/drive/MyDrive/Lorusso/models', eval_metrics = None):\n",
        "\n",
        "        self.device = (\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "        self.model = model\n",
        "        self.model = self.model.to(self.device)\n",
        "        self.model = self.model.to(torch.float)\n",
        "        self.num_epochs = num_epochs\n",
        "        self.loss_fn = loss_fn\n",
        "        self.eval_metrics = eval_metrics\n",
        "        self.optimizer = optimizer\n",
        "        self.model_path = model_path\n",
        "        self.save_path = self.model_path + '/' + self.model.__class__.__name__ + '/model.pt'\n",
        "\n",
        "        self.supervised = supervised\n",
        "        self.training_loss = []\n",
        "        self.validation_loss = []\n",
        "        self.dict_metrics = {}\n",
        "        self.elapsed_epochs = 0\n",
        "        self.elapsed_seconds = 0\n",
        "\n",
        "        if(LOAD_MODEL):\n",
        "          self.load_checkpoint()\n",
        "\n",
        "        # Create directory for model loading\n",
        "        try:\n",
        "          if(not os.path.exists(self.model_path + '/' + self.model.__class__.__name__)):\n",
        "            os.mkdir(self.model_path + '/' + self.model.__class__.__name__)\n",
        "        except Exception as e:\n",
        "          print(f\"Exception thrown in class {self.model.__class__.__name__ }, method __init__\")\n",
        "          print(e)\n",
        "          print('\\n')\n",
        "\n",
        "\n",
        "    def log_checkpoint(self, info: dict):\n",
        "        mlflow.pytorch.log_state_dict(info, artifact_path='checkpoint')\n",
        "        #torch.save(info, self.save_path)\n",
        "\n",
        "    def load_checkpoint(self):\n",
        "        \"\"\" Loads the last checkpoint for the given model \"\"\"\n",
        "        try:\n",
        "            run_id = mlflow.search_runs(experiment_names=['BraTS_'+type(self.model).__name__],\n",
        "                                        order_by=[\"start_time DESC\"]).iloc[0].run_id\n",
        "\n",
        "            checkpoint = mlflow.pytorch.load_state_dict('runs:/'+run_id+'/checkpoint',\n",
        "                                                        map_location=torch.device(self.device))\n",
        "\n",
        "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            self.elapsed_epochs = len(checkpoint['training_loss'])\n",
        "            self.training_loss = checkpoint['training_loss']\n",
        "            self.validation_loss = checkpoint['validation_loss']\n",
        "            self.dict_metrics = checkpoint['dict_metrics']\n",
        "            self.elapsed_seconds = checkpoint['elapsed_seconds']\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Exception thrown in class {self.model.__class__.__name__ }, method load_checkpoint\")\n",
        "            print(e)\n",
        "            print('\\n')\n",
        "            if(mlflow.active_run()):\n",
        "                mlflow.end_run()\n",
        "\n",
        "\n",
        "    def train(self, train_loader, val_loader = None,  experiment_prefix = ''):\n",
        "\n",
        "        try:\n",
        "            # Set MLFlow experiment\n",
        "            if(experiment_prefix):\n",
        "                mlflow.set_experiment(experiment_prefix + self.model.__class__.__name__)\n",
        "            else:\n",
        "                mlflow.set_experiment('BraTS_'+self.model.__class__.__name__)\n",
        "\n",
        "            # Start a new run if the model wasn't loaded\n",
        "            if(not mlflow.active_run()):\n",
        "                # Track metrics in the current run\n",
        "                mlflow.start_run()\n",
        "\n",
        "            for i in range(len(self.training_loss)):\n",
        "                mlflow.log_metric('train_loss', self.training_loss[i], step=i)\n",
        "\n",
        "            for i in range(len(self.validation_loss)):\n",
        "                mlflow.log_metric('val_loss', self.validation_loss[i], step=i)\n",
        "\n",
        "            param_dict = {\n",
        "                'batch_size':train_loader.batch_size,\n",
        "                'loss_fn':self.loss_fn.__class__.__name__,\n",
        "                'optimizer':self.optimizer.__class__.__name__,\n",
        "                'learning_rate':self.optimizer.state_dict()['param_groups'][0]['lr'],\n",
        "                'weight_decay':self.optimizer.state_dict()['param_groups'][0]['weight_decay'],\n",
        "            }\n",
        "            mlflow.log_params(param_dict)\n",
        "\n",
        "            training_loss = self.training_loss\n",
        "            validation_loss = self.validation_loss\n",
        "\n",
        "            self.tot_epochs = self.elapsed_epochs + self.num_epochs+1\n",
        "            self.tot_time = time.time()\n",
        "\n",
        "            # Train\n",
        "            for epoch in range(self.elapsed_epochs+1, self.tot_epochs):\n",
        "                start = time.time() # track time\n",
        "\n",
        "              # Evaluate first if loaded model missed the evaluation during an epoch\n",
        "                if(len(training_loss) > len(validation_loss)):\n",
        "                    if(val_loader is not None):\n",
        "\n",
        "                      ## COMPLETE EVALUATION OF PREVIOUS EPOCH ##\n",
        "                      # NB: epoch = epoch - 1\n",
        "                        val_batch_loss = self.__eval(val_loader, (epoch-1) )\n",
        "                        validation_loss.append(np.array(val_batch_loss).mean())\n",
        "                        self.dict_metrics = self.__eval_metrics(val_loader)\n",
        "\n",
        "                        for k in self.dict_metrics.keys():\n",
        "                            mlflow.log_metric(str(k), self.dict_metrics[k], step=epoch-1)\n",
        "                        # Log metric\n",
        "                        mlflow.log_metric('val_loss',validation_loss[-1], step=epoch-1)\n",
        "\n",
        "                        print(f\"Epoch: {epoch-1}/{self.tot_epochs-1}, Validation Loss: {validation_loss[-1]:.4f}, Elapsed time: {time.time() - start:.0f} sec \")\n",
        "\n",
        "                      # Update training time\n",
        "                        epoch_time = int(time.time() - self.tot_time) + self.elapsed_seconds\n",
        "\n",
        "                      #Create checkpoint\n",
        "                        val_dict = {\n",
        "                                  'model_state_dict': self.model.state_dict(),\n",
        "                                  'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                                  'training_loss': training_loss,\n",
        "                                  'validation_loss': validation_loss,\n",
        "                                  'dict_metrics': self.dict_metrics,\n",
        "                                  'elapsed_seconds': epoch_time\n",
        "                                  }\n",
        "                        self.log_checkpoint(val_dict)\n",
        "                    else:\n",
        "                        # Kind of exception, needed to keep the vectors of the same size\n",
        "                        validation_loss.append(np.mean(validation_loss))\n",
        "\n",
        "                        #Log metric\n",
        "                        mlflow.log_metric('val_loss',validation_loss[-1], step=epoch-1)\n",
        "\n",
        "                #### TRAIN ######\n",
        "                train_batch_loss = self.__train(train_loader, epoch)\n",
        "                training_loss.append(np.array(train_batch_loss).mean())\n",
        "\n",
        "                # Log metric\n",
        "                mlflow.log_metric('train_loss',training_loss[-1], step=epoch) # MLFLOW tracking\n",
        "                print(f\"\\nEpoch: {epoch}/{self.tot_epochs-1}, Loss: {training_loss[-1]:.4f}, Epoch elapsed time: {time.time() - start:.0f} sec \\n\")\n",
        "\n",
        "                #Save model every elapsed epoch\n",
        "                self.elapsed_epochs = epoch\n",
        "                epoch_time = int(time.time() - self.tot_time) + self.elapsed_seconds\n",
        "\n",
        "                train_dict = {\n",
        "                          'model_state_dict': self.model.state_dict(),\n",
        "                          'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                          'training_loss': training_loss,\n",
        "                          'validation_loss': validation_loss,\n",
        "                          'dict_metrics':self.dict_metrics,\n",
        "                          'elapsed_seconds': epoch_time\n",
        "                          }\n",
        "                self.log_checkpoint(train_dict)\n",
        "\n",
        "                #### EVALUATE ######\n",
        "                torch.cuda.empty_cache()\n",
        "                time.sleep(5)\n",
        "                if(val_loader is not None):\n",
        "\n",
        "                    val_batch_loss = self.__eval(val_loader, epoch)\n",
        "                    validation_loss.append(np.array(val_batch_loss).mean())\n",
        "\n",
        "                    self.dict_metrics = self.__eval_metrics(val_loader)\n",
        "\n",
        "                    for k in self.dict_metrics.keys():\n",
        "                        mlflow.log_metric(str(k), self.dict_metrics[k], step=epoch)\n",
        "\n",
        "                    # Log metric\n",
        "                    mlflow.log_metric('val_loss',validation_loss[-1], step=epoch)\n",
        "                    print(f\"Epoch: {epoch}/{self.tot_epochs-1}, Validation Loss: {validation_loss[-1]:.4f}, Elapsed time: {time.time() - start:.0f} sec \")\n",
        "\n",
        "                    #Checkpoint\n",
        "                    epoch_time = int(time.time() - self.tot_time) + self.elapsed_seconds\n",
        "                    val_dict = {\n",
        "                              'model_state_dict': self.model.state_dict(),\n",
        "                              'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                              'training_loss': training_loss,\n",
        "                              'validation_loss': validation_loss,\n",
        "                              'dict_metrics':self.dict_metrics,\n",
        "                              'elapsed_seconds': epoch_time\n",
        "                              }\n",
        "                    self.log_checkpoint(val_dict)\n",
        "\n",
        "                print(f\"Total training time: {time.time()-self.tot_time:.0f} sec\")\n",
        "\n",
        "            # Log model --> end run\n",
        "            mlflow.pytorch.log_model(self.model, artifact_path='model')\n",
        "            mlflow.end_run()\n",
        "        except Exception as e:\n",
        "            print(f\"Exception thrown in class {self.model.__class__.__name__ }, method train:\")\n",
        "            print(e)\n",
        "            print('\\n')\n",
        "            mlflow.end_run()\n",
        "\n",
        "\n",
        "        return training_loss, validation_loss\n",
        "\n",
        "    def __train(self, train_loader: DataLoader, epoch:int):\n",
        "\n",
        "        \"\"\" Train for an epoch \"\"\"\n",
        "\n",
        "        self.model.train()\n",
        "        train_batch_loss = []\n",
        "        train_steps = int(len(train_loader.dataset.all_ids)/train_loader.batch_size)\n",
        "\n",
        "        for i, (data,labels) in enumerate(train_loader):\n",
        "\n",
        "          torch.cuda.empty_cache()\n",
        "          self.optimizer.zero_grad()\n",
        "\n",
        "          if self.device == 'cuda':\n",
        "            data = data.type(torch.cuda.FloatTensor)\n",
        "          else:\n",
        "            data = data.type(torch.FloatTensor)\n",
        "\n",
        "          data = data.to(self.device)\n",
        "\n",
        "          outputs = self.model(data)\n",
        "\n",
        "          if(self.supervised):\n",
        "            loss = self.loss_fn(outputs,labels)\n",
        "          else:\n",
        "            loss = self.loss_fn(outputs, data)\n",
        "\n",
        "          loss.backward()\n",
        "          self.optimizer.step()\n",
        "          train_batch_loss.append(loss.detach().item())\n",
        "\n",
        "          out = f\"Epoch: {epoch}/{self.tot_epochs-1}, Step: {i+1}/{train_steps}, Loss: {loss.item():.4f}, Elapsed time: {time.time() - self.tot_time:.0f} sec \"\n",
        "          sys.stdout.write(\"\\r\" + out)\n",
        "          sys.stdout.flush()\n",
        "\n",
        "        return train_batch_loss\n",
        "\n",
        "\n",
        "    def __eval(self, val_loader: DataLoader, epoch:int):\n",
        "\n",
        "        \"\"\" Evaluate for an epoch \"\"\"\n",
        "\n",
        "        val_steps = int(len(val_loader.dataset.all_ids)/val_loader.batch_size)\n",
        "        self.model.eval()\n",
        "        val_batch_loss = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "          for i, (data,labels) in enumerate(val_loader):\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            if self.device == 'cuda':\n",
        "              data = data.type(torch.cuda.FloatTensor)\n",
        "            else:\n",
        "              data = data.type(torch.FloatTensor)\n",
        "\n",
        "            data = data.to(self.device)\n",
        "            outputs = self.model(data)\n",
        "\n",
        "            if(self.supervised):\n",
        "                val_loss = self.loss_fn(outputs, labels)\n",
        "            else:\n",
        "                val_loss = self.loss_fn(outputs, data)\n",
        "\n",
        "            val_batch_loss.append(val_loss.detach().item())\n",
        "\n",
        "            out = f\"Epoch: {epoch}/{self.tot_epochs-1}, Validation Step: {i+1}/{val_steps}, Validation Loss: {val_loss.item():.4f}, Elapsed time: {time.time() - self.tot_time:.0f} sec \"\n",
        "            sys.stdout.write(\"\\r\" + out)\n",
        "            sys.stdout.flush()\n",
        "\n",
        "        return val_batch_loss\n",
        "\n",
        "\n",
        "    def __eval_metrics(self, data_loader:DataLoader):\n",
        "        \"\"\" Evaluates additional metrics aside the loss function \"\"\"\n",
        "        metrics_dict = {}\n",
        "        try:\n",
        "            self.model.eval()\n",
        "            if(self.eval_metrics is not None):\n",
        "\n",
        "                metrics_dict = {k.__class__.__name__:[] for k in self.eval_metrics}\n",
        "\n",
        "                with torch.no_grad():\n",
        "\n",
        "                    for i, (data,labels) in enumerate(data_loader):\n",
        "                        torch.cuda.empty_cache()\n",
        "                        self.optimizer.zero_grad()\n",
        "\n",
        "                        for metric in self.eval_metrics:\n",
        "\n",
        "                            if self.device == 'cuda':\n",
        "                                data = data.type(torch.cuda.FloatTensor)\n",
        "                            else:\n",
        "                                data = data.type(torch.FloatTensor)\n",
        "\n",
        "                            data = data.to(self.device)\n",
        "                            outputs = self.model(data)\n",
        "\n",
        "                            if(self.supervised):\n",
        "                                metric_value = metric(outputs, labels)\n",
        "                            else:\n",
        "                                metric_value = metric(outputs, data)\n",
        "\n",
        "                            metrics_dict[metric.__class__.__name__].append(metric_value.detach().item())\n",
        "\n",
        "                    for k in metrics_dict.keys():\n",
        "                        metrics_dict[k] = np.array(metrics_dict[k]).mean()\n",
        "\n",
        "        except Exception as e:\n",
        "            print('Exception thrown in wrapper.__eval_metrics')\n",
        "            print(e)\n",
        "        finally:\n",
        "            return metrics_dict\n",
        "\n",
        "\n",
        "\n",
        "    def predict_batch(self, data_loader:DataLoader):\n",
        "\n",
        "        output = []\n",
        "        self.model = self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            try:\n",
        "              for i, batch in enumerate(data_loader):\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "                if(len(batch) == 1):\n",
        "                  data = batch\n",
        "                else:\n",
        "                  data,label = batch\n",
        "\n",
        "                if self.device == 'cuda':\n",
        "                  data = data.type(torch.cuda.FloatTensor)\n",
        "                else:\n",
        "                  data = data.type(torch.FloatTensor)\n",
        "\n",
        "                data.to(self.device)\n",
        "\n",
        "                out = self.model(data)\n",
        "                out = out.cpu().detach().numpy()\n",
        "                output.append(out)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Exception thrown in class {self.model.__class__.__name__ }, method predict_batch:\")\n",
        "                print(e)\n",
        "                print('\\n')\n",
        "\n",
        "        return np.array(output)\n",
        "\n",
        "\n",
        "    def predict(self, data):\n",
        "\n",
        "        if device == 'cuda':\n",
        "          data = data.type(torch.cuda.FloatTensor)\n",
        "        else:\n",
        "          data = data.type(torch.FloatTensor)\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            data.to(device)\n",
        "            output = self.model(data)\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "biiQzha9JP8G"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss ðŸ•³"
      ],
      "metadata": {
        "id": "he-C8aZXQkry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Loss(nn.Module):\n",
        "    def __init__(self, focal):\n",
        "        super(Loss, self).__init__()\n",
        "        if focal:\n",
        "            self.loss_fn = DiceFocalLoss(\n",
        "                include_background=False, softmax=True, to_onehot_y=True, batch=True, gamma=2.0\n",
        "            )\n",
        "        else:\n",
        "            self.loss_fn = DiceCELoss(include_background=False, softmax=True, to_onehot_y=True, batch=True)\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        return self.loss_fn(y_pred, y_true)\n",
        "\n",
        "\n",
        "class LossBraTS(nn.Module):\n",
        "    def __init__(self, focal):\n",
        "        super(LossBraTS, self).__init__()\n",
        "        self.dice = DiceLoss(sigmoid=True, batch=True)\n",
        "        self.ce = FocalLoss(gamma=2.0, to_onehot_y=False) if focal else nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def _loss(self, p, y):\n",
        "        print('p '+str(p.size()))\n",
        "        print('y '+str(y.size()))\n",
        "        return self.dice(p, y) + self.ce(p, y.float())\n",
        "\n",
        "    def forward(self, p, y):\n",
        "        y_wt, y_tc, y_et = y > 0, ((y == 1) + (y == 3)) > 0, y == 3\n",
        "        p_wt, p_tc, p_et = p[:, 0].unsqueeze(1), p[:, 1].unsqueeze(1), p[:, 2].unsqueeze(1)\n",
        "        l_wt, l_tc, l_et = self._loss(p_wt, y_wt), self._loss(p_tc, y_tc), self._loss(p_et, y_et)\n",
        "        return l_wt + l_tc + l_et"
      ],
      "metadata": {
        "id": "pUxP6_HiQiP8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build dataset ðŸ—"
      ],
      "metadata": {
        "id": "vsRN0nOwDif5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dotenv_path = \"/content/drive/MyDrive/Lorusso/BraTS/.env\"\n",
        "load_dotenv(dotenv_path)\n",
        "\n",
        "\n",
        "INPUT_PATH = os.getenv(\"INPUT_DATA_DIR\")\n",
        "PROCESSED_PATH = os.getenv('PROCESSED_DATA_DIR')\n",
        "INPUT_PATH_PARENT = '/'.join(INPUT_PATH.split('/')[:-1])\n",
        "\n",
        "TRAIN_PATH = os.path.join(INPUT_PATH_PARENT,'train')\n",
        "VAL_PATH = os.path.join(INPUT_PATH_PARENT,'val')\n",
        "TEST_PATH = os.path.join(INPUT_PATH_PARENT,'test')\n",
        "\n",
        "TAR_PATH = os.path.join(INPUT_PATH_PARENT,'BraTS2021_Training_Data.tar')\n",
        "BUILD_DATASET = False\n",
        "\n",
        "if(BUILD_DATASET):\n",
        "  untar_brats(tar_path = '/content/drive/MyDrive/Lorusso/BraTS/data/raw/BraTS2021_Training_Data.tar', extract_path = INPUT_PATH )\n",
        "  dataset = DataPreprocessor()\n",
        "  dataset.split_dataset()\n",
        "\n",
        "#dataset = DataPreprocessor()\n",
        "#train_loader = DataLoader(dataset, sampler = SeqSampler(dataset), batch_size = 1, num_workers = 0)\n",
        "#images, labels= next(iter(train_loader))\n",
        "#plot_brain_sections([images[0], labels[0]])\n",
        "#del images, labels, train_loader, dataset"
      ],
      "metadata": {
        "id": "9m9XrfCJDqWy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and predict âŒ›"
      ],
      "metadata": {
        "id": "mz-6k-tLLDbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_MODEL = False\n",
        "LOAD_MODEL = False\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "time.sleep(10)\n",
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "  num_workers = 0\n",
        "  batch_size = 1\n",
        "  num_epochs = 1\n",
        "  lr = 0.005\n",
        "  supervised = False\n",
        "\n",
        "  # MONAI AUTOENCODER\n",
        "  model = AutoEncoder(\n",
        "         spatial_dims=3,\n",
        "         kernel_size = 3,\n",
        "         up_kernel_size = 3,\n",
        "         in_channels=4,\n",
        "         out_channels=4,\n",
        "         channels=(5,),\n",
        "         strides=(2,),\n",
        "         inter_channels=(8, 16, 32),\n",
        "         inter_dilations=(1, 2, 4),\n",
        "         num_inter_units=2\n",
        "     )\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=1e-10)\n",
        "  loss_fn = nn.MSELoss() #SSIMLoss(spatial_dims=3)\n",
        "\n",
        "  wrapper = ModelWrapper(model = model,\n",
        "                            loss_fn = loss_fn,\n",
        "                            optimizer = optimizer,\n",
        "                            supervised = supervised,\n",
        "                            num_epochs = num_epochs,\n",
        "                            LOAD_MODEL = LOAD_MODEL\n",
        "                        )\n",
        "\n",
        "  dataset = DataPreprocessor(INPUT_PATH = INPUT_PATH)\n",
        "\n",
        "  # Split dataset if it's not\n",
        "  if(not os.path.exists(TRAIN_PATH)):\n",
        "    dataset.split_dataset()\n",
        "\n",
        "\n",
        "  train_dataset = DataPreprocessor(INPUT_PATH = TRAIN_PATH)\n",
        "  val_dataset = DataPreprocessor(INPUT_PATH = VAL_PATH)\n",
        "  test_dataset = DataPreprocessor(INPUT_PATH = TEST_PATH)\n",
        "\n",
        "  train_loader = DataLoader(dataset = train_dataset,\n",
        "                           sampler = SeqSampler(train_dataset),\n",
        "                           batch_size = batch_size,\n",
        "                           num_workers = num_workers)\n",
        "\n",
        "  val_loader = DataLoader(dataset = val_dataset,\n",
        "                           sampler = SeqSampler(val_dataset),\n",
        "                           batch_size = batch_size,\n",
        "                           num_workers = num_workers)\n",
        "\n",
        "  test_loader = DataLoader(dataset = test_dataset,\n",
        "                           sampler = SeqSampler(test_dataset),\n",
        "                           batch_size = batch_size,\n",
        "                           num_workers = num_workers)\n",
        "\n",
        "\n",
        "  print('Elapsed epochs: ' + str(wrapper.elapsed_epochs))\n",
        "\n",
        "if(TRAIN_MODEL):\n",
        "      training_loss, validation_loss = wrapper.train(train_loader = train_loader, val_loader = val_loader )\n",
        "      torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "UZ5ItOcISTzW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "  xx = range(1,wrapper.elapsed_epochs+1)\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.plot(xx, wrapper.training_loss, '-o', label = 'Train')\n",
        "  plt.plot(xx, wrapper.validation_loss,'-o', label = 'Val')\n",
        "  plt.legend(loc='lower left')"
      ],
      "metadata": {
        "id": "Bo0aQf08rHvn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "\n",
        "  slice_index = 150\n",
        "  ax = 0\n",
        "\n",
        "  im_test, lab = next(iter(test_loader))\n",
        "  output = wrapper.predict(data = im_test)\n",
        "  out = output[0]\n",
        "  out_numpy = out.cpu().detach().numpy()\n",
        "  im_test_numpy = im_test.cpu().detach().numpy()\n",
        "\n",
        "  plot_reconstruction(im_orig = np.sum(im_test_numpy[0], axis=0), im_rec = np.sum(out_numpy, axis = 0), ax = ax, slice_index = slice_index)\n",
        "  plot_brain_sections([im_test[0], lab[0]], ax = ax, slice_index = slice_index)"
      ],
      "metadata": {
        "id": "DvvSdXEvIw5w"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "  ker = wrapper.model.decode[0][0][0].weight.detach().clone()\n",
        "  print(ker.size())\n",
        "  #\n",
        "  visTensor(ker[0], allkernels=True)\n",
        "\n",
        "  ker = wrapper.model.decode[0][0][0].weight.detach().clone()\n",
        "  print(ker.size())\n",
        "  #\n",
        "  visTensor(torch.sum(ker, dim=(0)), allkernels=True)\n",
        "\n",
        "  kk = torch.sum(ker, dim= 0)\n",
        "  kk = torch.sum(kk, dim = 0)\n",
        "  plt.imshow(kk[0,:,:].cpu().detach().numpy())"
      ],
      "metadata": {
        "id": "ETwFBvf1Zjyp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING SECTION ðŸš§"
      ],
      "metadata": {
        "id": "n1_TRMmsm6jY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#! rm -r /content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled\n",
        "#! rm -r /content/drive/MyDrive/Lorusso/BraTS/data/interim/train\n",
        "#! rm -r /content/drive/MyDrive/Lorusso/BraTS/data/interim/test\n",
        "#! rm -r /content/drive/MyDrive/Lorusso/BraTS/data/interim/val"
      ],
      "metadata": {
        "id": "bC-ortIQ3vXX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "TEST_MODE = True\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if(TEST_MODE):\n",
        "\n",
        "    INPUT_PATH = '/content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled'\n",
        "    INPUT_PATH_PARENT = '/'.join(INPUT_PATH.split('/')[:-1])\n",
        "    TRAIN_PATH = os.path.join(INPUT_PATH_PARENT,'train')\n",
        "    VAL_PATH = os.path.join(INPUT_PATH_PARENT,'val')\n",
        "    TEST_PATH = os.path.join(INPUT_PATH_PARENT,'test')\n",
        "\n",
        "    TRAIN_MODEL = False\n",
        "    LOAD_MODEL = False # resume training\n",
        "\n",
        "    num_workers = 0\n",
        "    batch_size = 1\n",
        "    num_epochs = 2\n",
        "    lr = 0.01\n",
        "    supervised = False\n",
        "    eval_metrics = [nn.MSELoss()]\n",
        "\n",
        "  # MONAI AUTOENCODER\n",
        "    model = AutoEncoder(\n",
        "           spatial_dims=3,\n",
        "           kernel_size = 3,\n",
        "           up_kernel_size = 3,\n",
        "           in_channels=4,\n",
        "           out_channels=4,\n",
        "           channels=(5,),\n",
        "           strides=(2,),\n",
        "           inter_channels=(8, 16, 32),\n",
        "           inter_dilations=(1, 2, 4),\n",
        "           num_inter_units=2\n",
        "       )\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=1e-10)\n",
        "    loss_fn = nn.MSELoss() #SSIMLoss(spatial_dims=3)\n",
        "\n",
        "    wrapper = ModelWrapper(model = model,\n",
        "                              loss_fn = loss_fn,\n",
        "                              optimizer = optimizer,\n",
        "                              supervised = supervised,\n",
        "                              num_epochs = num_epochs,\n",
        "                              LOAD_MODEL = LOAD_MODEL,\n",
        "                              eval_metrics = eval_metrics\n",
        "                          )\n",
        "\n",
        "    dataset = DataPreprocessor(INPUT_PATH = INPUT_PATH)\n",
        "\n",
        "    # Split dataset if it's not\n",
        "    if(not os.path.exists(TRAIN_PATH)):\n",
        "      dataset.split_dataset()\n",
        "\n",
        "\n",
        "    train_dataset = DataPreprocessor(INPUT_PATH = TRAIN_PATH)\n",
        "    val_dataset = DataPreprocessor(INPUT_PATH = VAL_PATH)\n",
        "    test_dataset = DataPreprocessor(INPUT_PATH = TEST_PATH)\n",
        "\n",
        "    train_loader = DataLoader(dataset = train_dataset,\n",
        "                             sampler = SeqSampler(train_dataset),\n",
        "                             batch_size = batch_size,\n",
        "                             num_workers = num_workers)\n",
        "\n",
        "    val_loader = DataLoader(dataset = val_dataset,\n",
        "                             sampler = SeqSampler(val_dataset),\n",
        "                             batch_size = batch_size,\n",
        "                             num_workers = num_workers)\n",
        "\n",
        "    test_loader = DataLoader(dataset = test_dataset,\n",
        "                             sampler = SeqSampler(test_dataset),\n",
        "                             batch_size = batch_size,\n",
        "                             num_workers = num_workers)\n",
        "\n",
        "\n",
        "    print('Elapsed epochs: ' + str(wrapper.elapsed_epochs))\n",
        "\n",
        "    if(TRAIN_MODEL):\n",
        "        training_loss, validation_loss = wrapper.train(train_loader = train_loader, val_loader = val_loader, experiment_prefix = 'Test' )\n",
        "        torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "eHHzhDDF_3G9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65166b37-ab3b-4e6d-8b41-955d29f0e4bc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No MRI found at /content/drive/MyDrive/Lorusso/BraTS/data/interim/val\n",
            "Elapsed epochs: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "# Create graphs\n",
        "train_dataset.run()\n",
        "end = time.time() - start\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vIn18EWucHU",
        "outputId": "7037dec4-bc59-4fd0-e83a-379fb9443868"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Set up Threads, starting execution\n",
            "Finished BraTS2021_00003\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.766425132751465"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "  xx = range(1,wrapper.elapsed_epochs+1)\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.plot(xx, wrapper.training_loss, '-o', label = 'Train')\n",
        "  plt.plot(xx, wrapper.validation_loss,'-o', label = 'Val')\n",
        "  plt.legend(loc='lower left')"
      ],
      "metadata": {
        "id": "CcuxwsmW9OYS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "\n",
        "  slice_index = 90\n",
        "  ax = 0\n",
        "\n",
        "  im_test, lab = next(iter(test_loader))\n",
        "  output = wrapper.predict(data = im_test)\n",
        "  out = output[0]\n",
        "  out_numpy = out.cpu().detach().numpy()\n",
        "  im_test_numpy = im_test.cpu().detach().numpy()\n",
        "\n",
        "  plot_reconstruction(im_orig = np.sum(im_test_numpy[0], axis=0), im_rec = np.sum(out_numpy, axis = 0), ax = ax, slice_index = slice_index)\n",
        "  plot_brain_sections([im_test[0], lab[0]], ax = ax, slice_index = slice_index)"
      ],
      "metadata": {
        "id": "V3TKi4A9O4NA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "  ker = wrapper.model.decode[0][0][0].weight.detach().clone()\n",
        "  print(ker.size())\n",
        "  #\n",
        "  visTensor(ker[1], allkernels=True)\n",
        "\n",
        "  ker = wrapper.model.decode[0][0][0].weight.detach().clone()\n",
        "  print(ker.size())\n",
        "  #\n",
        "  visTensor(torch.sum(ker, dim=(0)), allkernels=True)\n",
        "\n",
        "  kk = torch.sum(ker, dim= 0)\n",
        "  kk = torch.sum(kk, dim = 0)\n",
        "  plt.imshow(kk[0,:,:].cpu().detach().numpy())"
      ],
      "metadata": {
        "id": "s5fwjWaWOhXN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLFlow transitioner\n",
        "\n",
        "Helps to bring a model saved with pickle to MLFlow"
      ],
      "metadata": {
        "id": "kVH1teeglI4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if(False):\n",
        "    checkpoint = torch.load(wrapper.save_path, map_location=torch.device(wrapper.device))\n",
        "    wrapper.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    wrapper.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    wrapper.elapsed_epochs = checkpoint['epochs']\n",
        "    wrapper.training_loss = checkpoint['training_loss']\n",
        "    wrapper.validation_loss = checkpoint['validation_loss']\n",
        "    wrapper.elapsed_seconds = checkpoint['elapsed_seconds']\n",
        "    try:\n",
        "        mlflow.set_experiment('BraTS_'+wrapper.model.__class__.__name__)\n",
        "        mlflow.start_run()\n",
        "        param_dict = {\n",
        "            'batch_size':train_loader.batch_size,\n",
        "            'optimizer':wrapper.optimizer.__class__.__name__,\n",
        "            'learning_rate':wrapper.optimizer.state_dict()['param_groups'][0]['lr'],\n",
        "            'loss_fn':wrapper.loss_fn.__class__.__name__\n",
        "        }\n",
        "        mlflow.log_params(param_dict)\n",
        "\n",
        "        #sample_input,_ = next(iter(train_loader))\n",
        "        #sample_output = wrapper.predict(sample_input)\n",
        "        #signature = infer_signature(sample_input.numpy(), sample_output.numpy())\n",
        "    #\n",
        "        #print(\"Model signature:\", signature)\n",
        "\n",
        "        for i in range(len(wrapper.training_loss)):\n",
        "            mlflow.log_metric('train_loss',wrapper.training_loss[i], step =i+1)\n",
        "        for i in range(len(wrapper.validation_loss)):\n",
        "            mlflow.log_metric('val_loss',wrapper.validation_loss[i], step =i+1)\n",
        "\n",
        "        val_dict = {\n",
        "              'model_state_dict': wrapper.model.state_dict(),\n",
        "              'optimizer_state_dict': wrapper.optimizer.state_dict(),\n",
        "              'elapsed_seconds': wrapper.elapsed_seconds,\n",
        "              'training_loss':wrapper.training_loss,\n",
        "              'validation_loss':wrapper.validation_loss\n",
        "              }\n",
        "\n",
        "        mlflow.pytorch.log_state_dict(val_dict,artifact_path=\"checkpoint\")\n",
        "        mlflow.pytorch.log_model(wrapper.model, artifact_path='model')\n",
        "\n",
        "        mlflow.end_run()\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        mlflow.end_run()"
      ],
      "metadata": {
        "id": "_xjPxt_lhQ7z"
      },
      "execution_count": 23,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Ub1h-Y7DIpYf",
        "q7ygOSsiEAWs",
        "cgINpL8BK3hL",
        "0u3q4OhjYyGq",
        "he-C8aZXQkry",
        "vsRN0nOwDif5",
        "mz-6k-tLLDbh",
        "kVH1teeglI4t"
      ],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}