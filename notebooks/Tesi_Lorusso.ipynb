{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## README ‚ùó\n",
        "\n",
        "Be sure that  torch.use_deterministic_algorithms() is set to True in the Environment Setup section. Otherwise the Autoencoder will produce different results for each epoch!\n",
        "\n",
        "References:\n",
        "\n",
        "- See [Reproducibility](https://pytorch.org/docs/stable/notes/randomness.html)"
      ],
      "metadata": {
        "id": "Ub1h-Y7DIpYf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment setup üèõ\n"
      ],
      "metadata": {
        "id": "mwFJcAuef07T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install python-dotenv\n",
        "! pip install monai\n",
        "! pip install shutil\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dotenv import load_dotenv\n",
        "import tarfile\n",
        "import nibabel as nib\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "from distutils.dir_util import copy_tree\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import SequentialSampler\n",
        "from torchvision import utils\n",
        "\n",
        "from monai.losses import DiceCELoss, DiceFocalLoss, DiceLoss, FocalLoss\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "\n",
        "torch.use_deterministic_algorithms(True)\n",
        "\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "id": "45BU03HjgAgT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ad2a976-1d02-49e8-cf1d-f3771f068ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: monai in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from monai) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from monai) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->monai) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->monai) (17.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->monai) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->monai) (1.3.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement shutil (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for shutil\u001b[0m\u001b[31m\n",
            "\u001b[0mDrive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "if [ ! -f '/content/drive/MyDrive/Lorusso/BraTS/.env' ]; then\n",
        "    echo \"Creating .env file...\"\n",
        "    echo \"INPUT_DATA_DIR='/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats'\" > '/content/drive/MyDrive/Lorusso/BraTS/.env'\n",
        "    echo \"PROCESSED_DATA_DIR='/content/drive/MyDrive/Lorusso/BraTS/data/processed'\" >> '/content/drive/MyDrive/Lorusso/BraTS/.env'\n",
        "fi"
      ],
      "metadata": {
        "id": "MkZwkHg4Wn_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "if [ ! -f '/content/drive/MyDrive/Lorusso/BraTS/data/raw/BraTS2021_Training_Data.tar'  ]; then\n",
        "    echo \"Downloading BraTS dataset at /content/drive/MyDrive/Lorusso/BraTS/data/raw ...\"\n",
        "    mkdir /root/.kaggle/\n",
        "    cp '/content/drive/MyDrive/Lorusso/kaggle.json' /root/.kaggle\n",
        "    chmod 600 '/root/.kaggle/kaggle.json'\n",
        "    cd '/content/drive/MyDrive/Lorusso/BraTS/data/raw' && kaggle datasets download -d dschettler8845/brats-2021-task1\n",
        "    ls '/content/drive/MyDrive/Lorusso/BraTS/data/raw'\n",
        "    unzip '/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats-2021-task1.zip' -d '/content/drive/MyDrive/Lorusso/BraTS/data/raw/'\n",
        "    rm -r '/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats-2021-task1.zip'\n",
        "fi"
      ],
      "metadata": {
        "id": "0u_tX1q-hh-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "rm -r /content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled\n",
        "if [ ! -d '/content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled' ]; then\n",
        "      mkdir '/content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled'\n",
        "fi\n",
        "\n",
        "path='/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats'\n",
        "dst='/content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled/'\n",
        "\n",
        "for el in $(ls $path | head -n 10);\n",
        "do\n",
        "    echo \"$path/$el -> $dst\"\n",
        "    cp -R \"$path/$el\" $dst\n",
        "done\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dm-FkQK1izU",
        "outputId": "168144ed-52a7-45ad-8bc3-dfa76c305ad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00000 -> /content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled/\n",
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00002 -> /content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled/\n",
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00003 -> /content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled/\n",
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00005 -> /content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled/\n",
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00006 -> /content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled/\n",
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00008 -> /content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled/\n",
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00009 -> /content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled/\n",
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00011 -> /content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled/\n",
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00012 -> /content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled/\n",
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00014 -> /content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils üõ†"
      ],
      "metadata": {
        "id": "q7ygOSsiEAWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def untar_brats(tar_path, extract_path):\n",
        "    tar = tarfile.open(tar_path)\n",
        "    tar.extractall(extract_path)\n",
        "    tar.close()\n",
        "\n",
        "\n",
        "def plot_brain_sections(images,ax = 1,slice_index = 90):\n",
        "\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "\n",
        "    d1,d2,d3 = np.shape(images[1])\n",
        "    dims = [d1,d2,d3]\n",
        "    dims.pop(ax)\n",
        "    color_segmentation = np.zeros((dims[0],dims[1],3))\n",
        "\n",
        "    gray_segmentation = np.take(images[1],slice_index,axis = ax)\n",
        "    color_segmentation[gray_segmentation == 1] = [255,0,0] # Red (necrotic tumor core)\n",
        "    color_segmentation[gray_segmentation == 2] = [0,255,0] # Green (peritumoral edematous/invaded tissue)\n",
        "    color_segmentation[gray_segmentation == 4] = [0,0,255] # Blue (enhancing tumor)\n",
        "\n",
        "    t1 = images[0][0]\n",
        "    flair = images[0][1]\n",
        "    t2 = images[0][2]\n",
        "    t1ce = images[0][3]\n",
        "\n",
        "    image = t1+t2+flair+t1ce\n",
        "\n",
        "    plt.figure(figsize=(15,15))\n",
        "    plt.subplot(1,4,1)\n",
        "    plt.imshow(np.take(image,slice_index,axis = 0),cmap='gray')\n",
        "\n",
        "    plt.subplot(1,4,2)\n",
        "    plt.imshow(np.take(image,slice_index,axis = 1),cmap='gray')\n",
        "\n",
        "    plt.subplot(1,4,3)\n",
        "    plt.imshow(np.take(image,slice_index,axis = 2),cmap='gray')\n",
        "\n",
        "    plt.subplot(1,4,4)\n",
        "    plt.imshow(color_segmentation,cmap='gray')\n",
        "    plt.xlabel('Segmentation')\n",
        "\n",
        "\n",
        "def visTensor(tensor, ch=0, allkernels=False, nrow=8, padding=1):\n",
        "    n,c,w,h = tensor.shape\n",
        "    if allkernels: tensor = tensor.view(n*c, -1, w, h)\n",
        "    elif c != 3: tensor = tensor[:,ch,:,:].unsqueeze(dim=1)\n",
        "    rows = np.min((tensor.shape[0] // nrow + 1, 64))\n",
        "    grid = utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n",
        "    plt.figure( figsize=(nrow,rows) )\n",
        "    plt.imshow(grid.cpu().permute((1, 2, 0)))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Lrs_wCJEAJpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset class  üíæ\n"
      ],
      "metadata": {
        "id": "aKEY_j_lCzCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Preprocessing script to convert from data provided by BraTS to data used by our model. Should be the first thing you run.\n",
        "Fulfills the following four functions:\n",
        "1. Normalize and standardize each image of each MRI modality\n",
        "2. Combine multiple MRI modalitities into one image array\n",
        "3. Swap labels from BraTS order (0,2,1,4) to more intuitive order (0,1,2,3)\n",
        "4. Convert image into a graph\n",
        "    Using Simple Linear Iterative Clustering algorithm\n",
        "    Parameters passed on command line\n",
        "\n",
        "If no labels are present (e.g. at test time, in deployment) can also build graph without labels.\n",
        "\n",
        "Saves the following in the specified output directory for each sample\n",
        "MRI_ID/\n",
        "    _input.nii.gz (processed and combined modalities for a sample as nifti file)\n",
        "    _label.nii.gz\n",
        "    _nxgraph.json (networkx graph containing both graph topography and features and labels for each node)\n",
        "    _supervoxels.nii.gz (supervoxel partitioning produced by SLIC)\n",
        "    _crop.npy (optionally the crop of the processed data relative to the original data) (crops out empty image planes)\n",
        "'''\n",
        "\n",
        "\n",
        "class DataPreprocessor(Dataset):\n",
        "  def __init__(self, dotenv_path = \"/content/drive/MyDrive/Lorusso/BraTS/.env\", transform = True, INPUT_PATH = None):\n",
        "\n",
        "    load_dotenv(dotenv_path)\n",
        "    # Data mean and variance\n",
        "    data_stats = ([0.4645, 0.6625, 0.4064, 0.3648], [0.1593, 0.1703, 0.1216, 0.1627])\n",
        "\n",
        "    if(INPUT_PATH is not None and os.path.exists(INPUT_PATH)):\n",
        "        self.data_dir = INPUT_PATH\n",
        "    else:\n",
        "        self.data_dir = os.getenv('INPUT_DATA_DIR')\n",
        "    self.output_dir = os.getenv('PROCESSED_DATA_DIR')\n",
        "    self.mri_prefix = 'BraTS2021'\n",
        "    self.modality_extensions = [\"_flair.nii.gz\", \"_t1.nii.gz\", \"_t1ce.nii.gz\", \"_t2.nii.gz\"]\n",
        "    self.label_extension = \"_seg.nii.gz\"\n",
        "    self.include_labels = self.label_extension is not None\n",
        "    self.all_ids, self.id_to_fp = self.get_all_mris_in_dataset()\n",
        "    self.LABEL_MAP = {4: 3, 2: 1, 1: 2}\n",
        "    self.dataset_mean = np.array(data_stats[0], dtype=np.float32)\n",
        "    self.dataset_std = np.array(data_stats[1], dtype=np.float32)\n",
        "    self.transform = transform if isinstance(transform, bool) else True\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.all_ids)\n",
        "\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    images = []\n",
        "    # Load the image corresponding to idx\n",
        "    try:\n",
        "      fp = [self.id_to_fp[k] for k in self.all_ids if k.split('_')[-1] == idx][0]\n",
        "      bn = os.path.basename(os.path.split(fp)[0])\n",
        "      images.append([nib.load(os.path.join(fp, bn + level)).get_fdata(dtype=np.float32).T\n",
        "                     for level in self.modality_extensions])\n",
        "      labels = nib.load(os.path.join(fp, bn + self.label_extension)).get_fdata(dtype=np.float32).T\n",
        "\n",
        "      # Convert to numpy array otherwise you'll experience RAM leak\n",
        "      images = np.asarray(images[0])\n",
        "      imstack = np.stack(np.array(images, dtype=np.float32), axis = 0)\n",
        "      imstack, labels = self.padding(imstack, labels)\n",
        "\n",
        "      if (self.transform):\n",
        "          imstack,labels = self.get_standardized_image(imstack, labels)\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Exception thrown in class {self.__class__.__name__ }, method __getitem__\")\n",
        "      print(e)\n",
        "      imstack = np.zeros([4,240,240,240],dtype=np.float32)\n",
        "      labels = np.zeros([240, 240, 240])\n",
        "\n",
        "    return np.array(imstack), labels\n",
        "\n",
        "\n",
        "  def get_all_mris_in_dataset(self):\n",
        "    mri_folders = glob.glob(f\"{self.data_dir}**/{self.mri_prefix}*/\",\n",
        "                            recursive=True)\n",
        "    mri_folders = self.remove_incomplete_mris(mri_folders)\n",
        "    scan_dic = {os.path.split(fp)[0].split(\"/\")[-1]: fp for fp in mri_folders}\n",
        "    if(len(mri_folders) == 0):\n",
        "        print(\"No MRI found at \" + self.data_dir)\n",
        "    return list(scan_dic.keys()), scan_dic\n",
        "\n",
        "\n",
        "  def remove_incomplete_mris(self, mri_folders):\n",
        "    # if there are any you want to ignore just add them to this list\n",
        "    removed_mris = []\n",
        "    return [fp for fp in mri_folders if fp.split(\"/\")[-2] not in removed_mris]\n",
        "\n",
        "\n",
        "  def split_dataset(self, ratio = (.6,.2,.2),seed = 42):\n",
        "\n",
        "    random.seed(seed)\n",
        "    if(np.sum(ratio) != 1 or ratio is None):\n",
        "      print(\"Error: ratio does not sum up to one.\\nSwitching to default (.6,.2,.2))\")\n",
        "      ratio = (.6,.2,.2)\n",
        "\n",
        "    train_length = int(len(self.all_ids)*ratio[0])\n",
        "    val_length = int(len(self.all_ids)*ratio[1])\n",
        "    test_length = int(len(self.all_ids)*ratio[2])\n",
        "    pos = random.sample(range(0,len(self.all_ids)), len(self.all_ids))\n",
        "\n",
        "    split_dict = {\n",
        "        'train': [self.all_ids[i] for i in pos[:train_length]],\n",
        "        'val': [self.all_ids[i] for i in pos[train_length :train_length + val_length]],\n",
        "        'test': [self.all_ids[i] for i in pos[train_length + val_length:]]\n",
        "    }\n",
        "\n",
        "    for k in split_dict.keys():\n",
        "      parent = '/'.join(self.data_dir.split('/')[:-1])\n",
        "      dst = os.path.join(parent,k)\n",
        "\n",
        "      try:\n",
        "        # create train,val,test dirs\n",
        "        if(not os.path.exists(dst)):\n",
        "          os.mkdir(dst)\n",
        "\n",
        "        # copy splitted data inside folders\n",
        "        for id in split_dict[k]:\n",
        "          if(not os.path.exists(os.path.join(dst,id))):\n",
        "             os.mkdir(os.path.join(dst,id))\n",
        "          copy_tree(self.id_to_fp[id],os.path.join(dst,id))\n",
        "\n",
        "      except Exception as e:\n",
        "        print(f\"Exception thrown in class {self.__class__.__name__ }, method split_dataset\")\n",
        "        print(e)\n",
        "\n",
        "\n",
        "  def padding(self,image, labels):\n",
        "    n_channels = np.shape(image)[0]\n",
        "    max_val = max(np.shape(image))\n",
        "    pad_list = np.zeros([n_channels,max_val,max_val,max_val],dtype=np.float32)\n",
        "\n",
        "    for channel in range(0, n_channels): # pad every channel\n",
        "        pad_list[channel] = np.pad(image[channel],[(0,85),(0,0),(0,0)],'constant')\n",
        "    labels = np.pad(labels, [(0,85),(0,0),(0,0)],'constant')\n",
        "\n",
        "    return pad_list, labels\n",
        "\n",
        "\n",
        "  def get_standardized_image(self, image_data, label_data):\n",
        "    # Swapped order of standardization and normalization\n",
        "    standardized_labels = self.swap_labels_from_brats(label_data)\n",
        "    #standardized_data = self.standardize_img(\n",
        "    #    image_data, self.dataset_mean, self.dataset_std)\n",
        "    normalized_data = self.normalize_img(image_data)\n",
        "    return normalized_data, standardized_labels\n",
        "\n",
        "\n",
        "  def normalize_img(self, img_array):\n",
        "    new_image = np.zeros(img_array.shape, dtype=np.float32)\n",
        "    n_channel = img_array.shape[0] # channel-first images\n",
        "\n",
        "    for channel in range(0, n_channel): # normalize every channel\n",
        "\n",
        "        maxval, minval= np.max(img_array[channel]), np.min(img_array[channel])\n",
        "        new_image[channel] = (img_array[channel] - minval)/(maxval-minval)\n",
        "        #print(np.max(new_image[channel]), np.min(new_image[channel]))\n",
        "\n",
        "    return new_image\n",
        "\n",
        "\n",
        "\n",
        "  def standardize_img(self,img_array, mean, std):\n",
        "    img_array = img_array.T # Align shapes\n",
        "    centered = img_array-mean\n",
        "    standardized = centered/std\n",
        "    return standardized.T\n",
        "\n",
        "\n",
        "  def swap_labels_from_brats(self,label_data):\n",
        "    uniques = np.unique(label_data)\n",
        "    for u in uniques:\n",
        "        if u not in [0, 1, 2, 4]:\n",
        "            raise RuntimeError('unexpected label')\n",
        "    new_label_data = np.zeros_like(label_data, dtype=np.int16)\n",
        "    new_label_data[label_data == 4] = self.LABEL_MAP[4]\n",
        "    new_label_data[label_data == 2] = self.LABEL_MAP[2]\n",
        "    new_label_data[label_data == 1] = self.LABEL_MAP[1]\n",
        "    return new_label_data\n",
        "\n",
        "\n",
        "  def swap_labels_to_brats(self,label_data):\n",
        "    uniques = np.unique(label_data)\n",
        "    for u in uniques:\n",
        "        if u not in [0, 1, 2, 3]:\n",
        "            raise RuntimeError('unexpected label')\n",
        "    new_label_data = np.zeros_like(label_data, dtype=np.int16)\n",
        "    new_label_data[label_data == self.LABEL_MAP[4]] = 4\n",
        "    new_label_data[label_data == self.LABEL_MAP[2]] = 2\n",
        "    new_label_data[label_data == self.LABEL_MAP[1]] = 1\n",
        "    return new_label_data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class SeqSampler(SequentialSampler):\n",
        "  \"\"\"Samples elements sequentially, always in the same order.\n",
        "\n",
        "    Args:\n",
        "        data_source (Dataset): dataset to sample from\n",
        "  \"\"\"\n",
        "  def __init__(self, data_source:Dataset):\n",
        "    self.data_source = data_source\n",
        "    self.indexDict = [id.split('_')[1] for id in data_source.all_ids]\n",
        "  def __iter__(self):\n",
        "    return iter(self.indexDict)\n",
        "  def __len__(self):\n",
        "    return len(self.indexDict)\n"
      ],
      "metadata": {
        "id": "-Pa_KNzpRi0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models üì™\n"
      ],
      "metadata": {
        "id": "cgINpL8BK3hL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder_9(nn.Module):\n",
        "    def __init__(self, slope):\n",
        "        super(Autoencoder_9, self).__init__()\n",
        "        self.slope = slope\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv3d(4, 16, kernel_size=9, stride=1, padding=4),\n",
        "            nn.LeakyReLU(negative_slope=self.slope),\n",
        "            nn.BatchNorm3d(16),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "            nn.Conv3d(16, 32 , kernel_size=5, stride=1, padding=2),\n",
        "            nn.LeakyReLU(negative_slope=self.slope),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "            nn.BatchNorm3d(32),\n",
        "            nn.Conv3d(32, 64 , kernel_size=5, stride=1, padding=2),\n",
        "            nn.LeakyReLU(negative_slope=self.slope),\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose3d(64, 32, kernel_size=5, stride=2, padding=2,output_padding=1),\n",
        "            nn.LeakyReLU(negative_slope=self.slope),\n",
        "            nn.ConvTranspose3d(32, 16, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
        "            nn.LeakyReLU(negative_slope=self.slope),\n",
        "            nn.ConvTranspose3d(16, 4, kernel_size=9, stride=1, padding=4,),\n",
        "            #nn.Sigmoid()  # Output between 0 and 1 for image data\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n"
      ],
      "metadata": {
        "id": "V3jHoKR_hppH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self,  slope = 0.5):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv3d(4, 16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(negative_slope=slope),\n",
        "            nn.BatchNorm3d(16),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "            nn.Conv3d(16, 32 , kernel_size=3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(negative_slope=slope),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "            nn.BatchNorm3d(32),\n",
        "            nn.Conv3d(32, 64 , kernel_size=3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(negative_slope=slope),\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose3d(64, 32, kernel_size=3, stride=2, padding=1,output_padding=1),\n",
        "            nn.LeakyReLU(negative_slope=slope),\n",
        "            nn.ConvTranspose3d(32, 16, kernel_size=3, stride=1, padding=1,),\n",
        "            nn.LeakyReLU(negative_slope=slope),\n",
        "            nn.ConvTranspose3d(16, 4, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            #nn.Sigmoid()  # Output between 0 and 1 for image data\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n"
      ],
      "metadata": {
        "id": "dj9rmyw_LXS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Wrapper üì®\n"
      ],
      "metadata": {
        "id": "0u3q4OhjYyGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelWrapper():\n",
        "  \"\"\"\n",
        "  Allows train, prediction and I/O operations on generic models\n",
        "\n",
        "  Every model is saved at every epoch, the name will be equal to:\n",
        "\n",
        "    - epochs_{num_epochs} if the model is not loaded\n",
        "    - epochs_{num_epochs + elapsed_epochs} if the model is loaded\n",
        "\n",
        "    The model is saved at every epoch.\n",
        "  \"\"\"\n",
        "  def __init__(self, model, optimizer, loss_fn,  num_epochs,  model_path = '/content/drive/MyDrive/Lorusso/models', LOAD_MODEL = False):\n",
        "\n",
        "    self.device = (\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "    self.model = model\n",
        "    self.model = self.model.to(self.device)\n",
        "    self.model = self.model.to(torch.float)\n",
        "    self.num_epochs = num_epochs\n",
        "    self.loss_fn = loss_fn\n",
        "    self.optimizer = optimizer\n",
        "    self.model_path = model_path\n",
        "    self.save_path = self.model_path + '/' + self.model.__class__.__name__ + '/model.pt'\n",
        "\n",
        "    self.training_loss = []\n",
        "    self.validation_loss = []\n",
        "    self.elapsed_epochs = 0\n",
        "    self.elapsed_seconds = 0\n",
        "\n",
        "    if(LOAD_MODEL):\n",
        "      self.load_model()\n",
        "\n",
        "    # Create directory for model loading\n",
        "    try:\n",
        "      if(not os.path.exists(self.model_path + '/' + self.model.__class__.__name__)):\n",
        "        os.mkdir(self.model_path + '/' + self.model.__class__.__name__)\n",
        "    except Exception as e:\n",
        "      print(f\"Exception thrown in class {self.model.__class__.__name__ }, method __init__\")\n",
        "      print(e)\n",
        "      print('\\n')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def load_model(self):\n",
        "    try:\n",
        "      checkpoint = torch.load(self.save_path, map_location=torch.device(self.device))\n",
        "      self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "      self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "      self.elapsed_epochs = checkpoint['epochs']\n",
        "      self.training_loss = checkpoint['training_loss']\n",
        "      self.validation_loss = checkpoint['validation_loss']\n",
        "      self.elapsed_seconds = checkpoint['elapsed_seconds']\n",
        "      #self.validation_loss.append(self.validation_loss[-1])\n",
        "      #self.model = self.model.to(self.device)\n",
        "    except Exception as e:\n",
        "      print(f\"Exception thrown in class {self.model.__class__.__name__ }, method load_model\")\n",
        "      print(e)\n",
        "      print('\\n')\n",
        "\n",
        "\n",
        "  def train(self, train_loader, val_loader = None):\n",
        "\n",
        "    #self.model = self.model.to(self.device)\n",
        "    #self.model = self.model.to(torch.float)\n",
        "\n",
        "    try:\n",
        "\n",
        "      training_loss = self.training_loss\n",
        "      validation_loss = self.validation_loss\n",
        "      train_steps = int(len(train_loader.dataset.all_ids)/train_loader.batch_size)\n",
        "\n",
        "      tot_epochs = self.elapsed_epochs + self.num_epochs+1\n",
        "      tot_time = time.time()\n",
        "\n",
        "      # Train\n",
        "      for epoch in range(self.elapsed_epochs+1, tot_epochs):\n",
        "\n",
        "        train_batch_loss = []\n",
        "        val_batch_loss = []\n",
        "        start = time.time() # track time\n",
        "\n",
        "        self.model.train()\n",
        "        for i, (data,_) in enumerate(train_loader):\n",
        "\n",
        "          torch.cuda.empty_cache()\n",
        "\n",
        "          if self.device == 'cuda':\n",
        "            data = data.type(torch.cuda.FloatTensor)\n",
        "          else:\n",
        "            data = data.type(torch.FloatTensor)\n",
        "\n",
        "          data = data.to(self.device)\n",
        "          self.optimizer.zero_grad()\n",
        "          outputs = self.model(data)\n",
        "          loss = self.loss_fn(outputs, data)\n",
        "          loss.backward()\n",
        "          self.optimizer.step()\n",
        "\n",
        "          train_batch_loss.append(loss.detach().item())\n",
        "          out = f\"Epoch: {epoch}/{tot_epochs-1}, Step: {i+1}/{train_steps}, Loss: {loss.item():.4f}, Elapsed time: {time.time() - tot_time:.0f} sec \"\n",
        "          sys.stdout.write(\"\\r\" + out)\n",
        "          sys.stdout.flush()\n",
        "\n",
        "        self.elapsed_epochs = epoch\n",
        "        training_loss.append(np.array(train_batch_loss).mean())\n",
        "        print(f\"\\nEpoch: {epoch}/{tot_epochs-1}, Loss: {training_loss[-1]:.4f}, Epoch elapsed time: {time.time() - start:.0f} sec \\n\")\n",
        "\n",
        "        epoch_time = int(time.time() - tot_time) + self.elapsed_seconds\n",
        "        #Save model every epoch\n",
        "        torch.save({\n",
        "                  'epochs': epoch,\n",
        "                  'model_state_dict': self.model.state_dict(),\n",
        "                  'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                  'batch_size': train_loader.batch_size,\n",
        "                  'training_loss': training_loss,\n",
        "                  'validation_loss': validation_loss,\n",
        "                  'elapsed_seconds': epoch_time\n",
        "                  }, self.save_path )\n",
        "\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "        time.sleep(10)\n",
        "\n",
        "        if(val_loader is not None):\n",
        "          val_steps = int(len(val_loader.dataset.all_ids)/val_loader.batch_size)\n",
        "\n",
        "          self.model.eval()\n",
        "          for i, (data,_) in enumerate(val_loader):\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "            if self.device == 'cuda':\n",
        "              data = data.type(torch.cuda.FloatTensor)\n",
        "            else:\n",
        "              data = data.type(torch.FloatTensor)\n",
        "\n",
        "            data = data.to(self.device)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(data)\n",
        "            val_loss = self.loss_fn(outputs, data)\n",
        "            val_batch_loss.append(val_loss.detach().item())\n",
        "\n",
        "            out = f\"Epoch: {epoch}/{tot_epochs-1}, Validation Step: {i+1}/{val_steps}, Validation Loss: {val_loss.item():.4f}, Elapsed time: {time.time() - tot_time:.0f} sec \"\n",
        "            sys.stdout.write(\"\\r\" + out)\n",
        "            sys.stdout.flush()\n",
        "\n",
        "          validation_loss.append(np.array(val_batch_loss).mean())\n",
        "          print(f\"Epoch: {epoch}/{tot_epochs-1}, Validation Step: {i+1}/{val_steps}, Validation Loss: {validation_loss[-1]:.4f}, Elapsed time: {time.time() - start:.0f} sec \")\n",
        "\n",
        "          # Update training time\n",
        "          epoch_time = int(time.time() - tot_time) + self.elapsed_seconds\n",
        "          #Save model every epoch\n",
        "          torch.save({\n",
        "                    'epochs': epoch,\n",
        "                    'model_state_dict': self.model.state_dict(),\n",
        "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                    'batch_size': train_loader.batch_size,\n",
        "                    'training_loss': training_loss,\n",
        "                    'validation_loss': validation_loss,\n",
        "                    'elapsed_seconds': epoch_time\n",
        "                    }, self.save_path )\n",
        "\n",
        "\n",
        "      print(f\"Total training time: {time.time()-tot_time:.0f} sec\")\n",
        "\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Exception thrown in class {self.model.__class__.__name__ }, method train:\")\n",
        "      print(e)\n",
        "      print('\\n')\n",
        "\n",
        "    return training_loss, validation_loss\n",
        "\n",
        "\n",
        "\n",
        "  def predict_batch(self, data_loader):\n",
        "\n",
        "    output = []\n",
        "    self.model = self.model.to(self.device)\n",
        "    self.model.eval()\n",
        "    try:\n",
        "      for i, batch in enumerate(data_loader):\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        if(len(batch) == 1):\n",
        "          data = batch\n",
        "        else:\n",
        "          data,_ = batch\n",
        "\n",
        "        if self.device == 'cuda':\n",
        "          data = data.type(torch.cuda.FloatTensor)\n",
        "        else:\n",
        "          data = data.type(torch.FloatTensor)\n",
        "\n",
        "        data.to(self.device)\n",
        "        out = self.model(data)\n",
        "        out = out.cpu().detach().numpy()\n",
        "        output.append(out)\n",
        "    except Exception as e:\n",
        "        print(f\"Exception thrown in class {self.model.__class__.__name__ }, method predict_batch:\")\n",
        "        print(e)\n",
        "        print('\\n')\n",
        "\n",
        "    return np.array(output)\n",
        "\n",
        "\n",
        "  def predict(self, data):\n",
        "\n",
        "    if device == 'cuda':\n",
        "      data = data.type(torch.cuda.FloatTensor)\n",
        "    else:\n",
        "      data = data.type(torch.FloatTensor)\n",
        "\n",
        "    self.model.eval()\n",
        "    data.to(device)\n",
        "    output = self.model(data)\n",
        "    #output = output.cpu().detach().numpy()\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "biiQzha9JP8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build dataset üèó"
      ],
      "metadata": {
        "id": "vsRN0nOwDif5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dotenv_path = \"/content/drive/MyDrive/Lorusso/BraTS/.env\"\n",
        "load_dotenv(dotenv_path)\n",
        "\n",
        "\n",
        "INPUT_PATH = os.getenv(\"INPUT_DATA_DIR\")\n",
        "PROCESSED_PATH = os.getenv('PROCESSED_DATA_DIR')\n",
        "INPUT_PATH_PARENT = '/'.join(INPUT_PATH.split('/')[:-1])\n",
        "\n",
        "TRAIN_PATH = os.path.join(INPUT_PATH_PARENT,'train')\n",
        "VAL_PATH = os.path.join(INPUT_PATH_PARENT,'val')\n",
        "TEST_PATH = os.path.join(INPUT_PATH_PARENT,'test')\n",
        "\n",
        "TAR_PATH = os.path.join(INPUT_PATH_PARENT,'BraTS2021_Training_Data.tar')\n",
        "BUILD_DATASET = False\n",
        "\n",
        "if(BUILD_DATASET):\n",
        "  untar_brats(tar_path = '/content/drive/MyDrive/Lorusso/BraTS/data/raw/BraTS2021_Training_Data.tar', extract_path = INPUT_PATH )\n",
        "  dataset = DataPreprocessor()\n",
        "  dataset.split_dataset()\n",
        "\n",
        "#dataset = DataPreprocessor()\n",
        "#train_loader = DataLoader(dataset, sampler = SeqSampler(dataset), batch_size = 1, num_workers = 0)\n",
        "#images, labels= next(iter(train_loader))\n",
        "#plot_brain_sections([images[0], labels[0]])\n",
        "#del images, labels, train_loader, dataset"
      ],
      "metadata": {
        "id": "9m9XrfCJDqWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and predict ‚åõ"
      ],
      "metadata": {
        "id": "mz-6k-tLLDbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "num_epochs = 1\n",
        "lr = 0.005\n",
        "TRAIN_MODEL = False\n",
        "LOAD_MODEL = True # resume training\n",
        "\n",
        "\n",
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "  # Directory with full dataset, split it\n",
        "  torch.cuda.empty_cache()\n",
        "  time.sleep(5)\n",
        "  model = Autoencoder(slope = 0.)\n",
        "\n",
        "  dataset = DataPreprocessor(INPUT_PATH = INPUT_PATH)\n",
        "  if(not os.path.exists(TRAIN_PATH)):\n",
        "    dataset.split_dataset()\n",
        "\n",
        "\n",
        "  train_dataset = DataPreprocessor(INPUT_PATH = TRAIN_PATH,)\n",
        "  val_dataset = DataPreprocessor(INPUT_PATH = VAL_PATH,  )\n",
        "  test_dataset = DataPreprocessor(INPUT_PATH = TEST_PATH, )\n",
        "\n",
        "  train_loader = DataLoader(dataset = train_dataset,\n",
        "                           sampler = SeqSampler(train_dataset),\n",
        "                           batch_size = batch_size,\n",
        "                           num_workers = 0)\n",
        "\n",
        "  val_loader = DataLoader(dataset = val_dataset,\n",
        "                           sampler = SeqSampler(val_dataset),\n",
        "                           batch_size = batch_size,\n",
        "                           num_workers = 0)\n",
        "\n",
        "  test_loader = DataLoader(dataset = test_dataset,\n",
        "                           sampler = SeqSampler(test_dataset),\n",
        "                           batch_size = batch_size,\n",
        "                           num_workers = 0)\n",
        "\n",
        "  wrapper = ModelWrapper(model = model,\n",
        "                         loss_fn = nn.MSELoss(),\n",
        "                         optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay = 0),\n",
        "                         num_epochs = num_epochs,\n",
        "                         LOAD_MODEL = LOAD_MODEL\n",
        "                         )\n",
        "\n",
        "  print('Elapsed epochs: ' + str(wrapper.elapsed_epochs))\n",
        "\n",
        "if(TRAIN_MODEL):\n",
        "    training_loss, validation_loss = wrapper.train(train_loader = train_loader, val_loader = val_loader )\n",
        "    torch.cuda.empty_cache()\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "UZ5ItOcISTzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "  xx = range(1,wrapper.elapsed_epochs+1)\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.plot(xx, wrapper.training_loss, '-o', label = 'Train')\n",
        "  plt.plot(xx, wrapper.validation_loss,'-o', label = 'Val')\n",
        "  plt.legend(loc='lower left')"
      ],
      "metadata": {
        "id": "Bo0aQf08rHvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "  im_test, lab = next(iter(test_loader))\n",
        "  output = wrapper.predict(data = im_test)\n",
        "  out = output[0]\n",
        "  out_numpy = out.cpu().detach().numpy()\n",
        "  slice_index = 100\n",
        "  ax = 0\n",
        "  f, ax_array = plt.subplots(1,2, figsize=(10,10))\n",
        "  ax_array[0].imshow((np.sum(im_test.cpu().detach().numpy()[0], axis=0)[slice_index,:,:]), cmap='gray')\n",
        "  ax_array[1].imshow((np.sum(out_numpy, axis=0)[slice_index,:,:]), cmap='gray')\n",
        "  plot_brain_sections([im_test[0], lab[0]], ax = ax, slice_index = slice_index)"
      ],
      "metadata": {
        "id": "DvvSdXEvIw5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp /content/drive/MyDrive/Lorusso/models/Autoencoder/model.pt /content/drive/MyDrive/Lorusso/models/saved/autoencoder_6_epochs_bad_model.pt"
      ],
      "metadata": {
        "id": "jFGbQE6q1Rld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm /content/drive/MyDrive/Lorusso/models/Autoencoder/model.pt\n",
        "! cp /content/drive/MyDrive/Lorusso/models/saved/autoencoder_6_epochs_model.pt /content/drive/MyDrive/Lorusso/models/Autoencoder/model.pt"
      ],
      "metadata": {
        "id": "HpRKNEqj3YrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "  ker = wrapper.model.decoder[2].weight.detach().clone()\n",
        "  print(ker.size())\n",
        "  #\n",
        "  visTensor(torch.sum(ker, dim=(0)), allkernels=True)\n",
        "\n",
        "\n",
        "  ker = wrapper.model.decoder[2].weight.detach().clone()\n",
        "  print(ker.size())\n",
        "  #\n",
        "  visTensor(torch.sum(ker, dim=(0)), allkernels=True)\n",
        "\n",
        "  kk = torch.sum(ker, dim= 0)\n",
        "  kk = torch.sum(kk, dim = 0)\n",
        "  plt.imshow(kk[0,:,:].cpu().detach().numpy())"
      ],
      "metadata": {
        "id": "ETwFBvf1Zjyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TO-DO ‚úÖ\n",
        "\n"
      ],
      "metadata": {
        "id": "qIbk2-LzCSH6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### FIX üßØ\n",
        "\n",
        "- Actually the wrapper works only with unsupervised models because i'm not considering the labels in the training, evaluation and prediciton for simplicity.\n",
        "\n",
        "- The net is learning a black image probably because there is a great amount of black  pixels. Use another activation function such as Tanh?"
      ],
      "metadata": {
        "id": "wlZrePlNCp-_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ERRORS üî¥\n",
        "\n",
        "#### 1\n",
        "ERROR Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n",
        "\n",
        "batch_size = 1\n",
        "num_epochs = 2\n",
        "lr = 0.05\n",
        "TRAIN_MODEL =  True\n",
        "LOAD_MODEL = True # resume training\n",
        "\n",
        "\n",
        "Answer: it depends on load_model method, probably not sending model.to(device) when loading it.\n",
        "\n",
        "Il problema era nel caricamento di un vecchio modello, eliminandolo fuziona tutto\n",
        "\n",
        "#### 2\n",
        "\n",
        "Quando carico il modello e lo riaddestro, nel momento un cui effettua una predizione il risultato √® tutto nero.\n",
        "\n",
        "ACTION: Ho eliminato il layer sigmoid dal decoder e ho modificato la loss da MSE a L1\n",
        "\n",
        "Quando l'immagine √® nera la loss rimane uguale nelle diverse epoche.\n",
        "\n",
        "Penso che la sigmoid combinata con la MSELoss porti i valori dell'immagine a zero.\n",
        "\n",
        "\n",
        "\n",
        "#### 3\n",
        "\n",
        "2 epocha di trianing al 4 step di 750 no such file or no access BraTS2021_00709_flair.nii.gz e poi list out of range generato dall'istruzione images[0] all'interno di __ getitem __\n",
        "\n",
        "Infatti train_loader.dataset.all_ids[4] √® uguale a 00709\n",
        "\n",
        "\n",
        "\n",
        "Action: inserire un continue all'interno del train loop nel caso in cui l'immagine caricata sia vuota. L'immagine vuota (tutti zero) verr√† restituita da getitem nel caso in cui il file non viene trovato.\n",
        "\n",
        "PROBLEM: in un'ottica di batch questo farebbe scartare un'intera batch. Bisognerebbe sostituire all'immagine vuota una di quelle presenti nel batch. √à una soluzione che va implementata solo in casi estremi\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fdNXwX_M7DSv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vLvvBpV_RAVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING SECTION üöß"
      ],
      "metadata": {
        "id": "n1_TRMmsm6jY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_MODE = False\n",
        "\n",
        "#torch.cuda.empty_cache()\n",
        "if(TEST_MODE):\n",
        "\n",
        "  INPUT_PATH = '/content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled'\n",
        "  INPUT_PATH_PARENT = '/'.join(INPUT_PATH.split('/')[:-1])\n",
        "\n",
        "  TRAIN_PATH = os.path.join(INPUT_PATH_PARENT,'train')\n",
        "  VAL_PATH = os.path.join(INPUT_PATH_PARENT,'val')\n",
        "  TEST_PATH = os.path.join(INPUT_PATH_PARENT,'test')\n",
        "\n",
        "\n",
        "  batch_size = 1\n",
        "  num_epochs = 3\n",
        "  lr = 0.005\n",
        "  TRAIN_MODEL = True\n",
        "  LOAD_MODEL = False # resume training\n",
        "\n",
        "\n",
        "  # Directory with full dataset, split it\n",
        "  model = Autoencoder()\n",
        "\n",
        "  dataset = DataPreprocessor(INPUT_PATH = INPUT_PATH)\n",
        "  if(not os.path.exists(TRAIN_PATH)):\n",
        "    dataset.split_dataset()\n",
        "\n",
        "\n",
        "  train_dataset = DataPreprocessor(INPUT_PATH = TRAIN_PATH)\n",
        "  val_dataset = DataPreprocessor(INPUT_PATH = VAL_PATH)\n",
        "  test_dataset = DataPreprocessor(INPUT_PATH = TEST_PATH)\n",
        "\n",
        "  train_loader = DataLoader(dataset = train_dataset,\n",
        "                           sampler = SeqSampler(train_dataset),\n",
        "                           batch_size = batch_size,\n",
        "                           num_workers = 0)\n",
        "\n",
        "  val_loader = DataLoader(dataset = val_dataset,\n",
        "                           sampler = SeqSampler(val_dataset),\n",
        "                           batch_size = batch_size,\n",
        "                           num_workers = 0)\n",
        "\n",
        "  test_loader = DataLoader(dataset = test_dataset,\n",
        "                           sampler = SeqSampler(test_dataset),\n",
        "                           batch_size = batch_size,\n",
        "                           num_workers = 0)\n",
        "\n",
        "  wrapper = ModelWrapper(model = model,\n",
        "                         loss_fn = nn.MSELoss(),\n",
        "                         optimizer = torch.optim.Adam(model.parameters(), lr=lr,),\n",
        "                         num_epochs = num_epochs,\n",
        "                         LOAD_MODEL = LOAD_MODEL\n",
        "                         )\n",
        "\n",
        "  print('Elapsed epochs: ' + str(wrapper.elapsed_epochs))\n",
        "\n",
        "  if(TRAIN_MODEL):\n",
        "      training_loss, validation_loss = wrapper.train(train_loader = train_loader, val_loader = val_loader )\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eHHzhDDF_3G9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "  xx = range(1,wrapper.elapsed_epochs+1)\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.plot(xx, wrapper.training_loss, '-o', label = 'Train')\n",
        "  plt.plot(xx, wrapper.validation_loss,'-o', label = 'Val')\n",
        "  plt.legend(loc='lower left')"
      ],
      "metadata": {
        "id": "CcuxwsmW9OYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "  im_test, lab = next(iter(test_loader))\n",
        "  output = wrapper.predict(data = im_test)\n",
        "  out = output[0]\n",
        "  out_numpy = out.cpu().detach().numpy()\n",
        "  slice_index = 80\n",
        "  ax = 2\n",
        "  f, ax_array = plt.subplots(1,2, figsize=(10,10))\n",
        "  ax_array[0].imshow((np.sum(im_test.cpu().detach().numpy()[0], axis=0)[:,:,slice_index]), cmap='gray')\n",
        "  ax_array[1].imshow((np.sum(out_numpy, axis=0)[:,:,slice_index]), cmap='gray')\n",
        "  plot_brain_sections([im_test[0], lab[0]], ax = ax, slice_index = slice_index)"
      ],
      "metadata": {
        "id": "V3TKi4A9O4NA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import torchvision\n",
        "#kernels =  ker[2]\n",
        "#kernels = kernels - kernels.min()\n",
        "#kernels = kernels / kernels.max()\n",
        "#filter_img = torchvision.utils.make_grid(kernels, nrow = 10)\n",
        "#\n",
        "## change ordering since matplotlib requires images to\n",
        "## be (H, W, C)\n",
        "#plt.imshow(filter_img.cpu().permute(1, 2, 0).flatten(1))"
      ],
      "metadata": {
        "id": "H0I-TfE3iHeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Successful models (?)\n"
      ],
      "metadata": {
        "id": "DKQGv12UJ6Vz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        slope = 0.5\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv3d(4, 16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(negative_slope=slope),\n",
        "            nn.BatchNorm3d(16),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "            nn.Conv3d(16, 32 , kernel_size=3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(negative_slope=slope),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "            nn.BatchNorm3d(32),\n",
        "            nn.Conv3d(32, 64 , kernel_size=3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(negative_slope=slope),\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose3d(64, 32, kernel_size=3, stride=2, padding=1,output_padding=1),\n",
        "            nn.LeakyReLU(negative_slope=slope),\n",
        "            nn.ConvTranspose3d(32, 16, kernel_size=3, stride=1, padding=1,),\n",
        "            nn.LeakyReLU(negative_slope=slope),\n",
        "            nn.ConvTranspose3d(16, 4, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            #nn.Sigmoid()  # Output between 0 and 1 for image data\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n"
      ],
      "metadata": {
        "id": "PtHDMbItJ-cx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mwFJcAuef07T",
        "q7ygOSsiEAWs",
        "aKEY_j_lCzCa",
        "cgINpL8BK3hL",
        "0u3q4OhjYyGq",
        "vsRN0nOwDif5",
        "qIbk2-LzCSH6",
        "DKQGv12UJ6Vz"
      ],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}