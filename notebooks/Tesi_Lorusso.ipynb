{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHYH1gJre0Ks"
      },
      "source": [
        "# Definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment setup\n"
      ],
      "metadata": {
        "id": "mwFJcAuef07T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install python-dotenv\n",
        "! pip install monai\n",
        "! pip install shutil\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dotenv import load_dotenv\n",
        "import tarfile\n",
        "import nibabel as nib\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "from distutils.dir_util import copy_tree\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import SequentialSampler\n",
        "\n",
        "from monai.losses import DiceCELoss, DiceFocalLoss, DiceLoss, FocalLoss\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "id": "45BU03HjgAgT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28f402b1-41a6-44da-911d-6809773ceafe"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: monai in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from monai) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from monai) (1.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->monai) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->monai) (17.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->monai) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->monai) (1.3.0)\n",
            "Requirement already satisfied: split-folders[full] in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from split-folders[full]) (4.66.1)\n",
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "if [ ! -f '/content/drive/MyDrive/Lorusso/BraTS/.env' ]; then\n",
        "    echo \"Creating .env file...\"\n",
        "    echo \"INPUT_DATA_DIR='/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats'\" > '/content/drive/MyDrive/Lorusso/BraTS/.env'\n",
        "    echo \"PROCESSED_DATA_DIR='/content/drive/MyDrive/Lorusso/BraTS/data/processed'\" >> '/content/drive/MyDrive/Lorusso/BraTS/.env'\n",
        "fi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkZwkHg4Wn_e",
        "outputId": "3f0fec12-043a-420b-8455-1be592f404e4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating .env file...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "if [ ! -f '/content/drive/MyDrive/Lorusso/BraTS/data/raw/BraTS2021_Training_Data.tar'  ]; then\n",
        "    echo \"Downloading BraTS dataset at /content/drive/MyDrive/Lorusso/BraTS/data/raw ...\"\n",
        "    mkdir /root/.kaggle/\n",
        "    cp '/content/drive/MyDrive/Lorusso/kaggle.json' /root/.kaggle\n",
        "    chmod 600 '/root/.kaggle/kaggle.json'\n",
        "    cd '/content/drive/MyDrive/Lorusso/BraTS/data/raw' && kaggle datasets download -d dschettler8845/brats-2021-task1\n",
        "    ls '/content/drive/MyDrive/Lorusso/BraTS/data/raw'\n",
        "    unzip '/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats-2021-task1.zip' -d '/content/drive/MyDrive/Lorusso/BraTS/data/raw/'\n",
        "    rm -r '/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats-2021-task1.zip'\n",
        "fi"
      ],
      "metadata": {
        "id": "0u_tX1q-hh-L"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Select a subset of data for testing purposes ##\n",
        "\n",
        "%%bash\n",
        "\n",
        "if [ ! -d '/content/drive/MyDrive/Lorusso/BraTS/data/raw/sampled' ]; then\n",
        "      mkdir '/content/drive/MyDrive/Lorusso/BraTS/data/raw/sampled'\n",
        "fi\n",
        "\n",
        "path='/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats'\n",
        "dst='/content/drive/MyDrive/Lorusso/BraTS/data/raw/sampled/'\n",
        "\n",
        "for el in $(ls $path | head -n 10);\n",
        "do\n",
        "    echo \"$path/$el -> $dst\"\n",
        "    cp -R \"$path/$el\" $dst\n",
        "done\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dm-FkQK1izU",
        "outputId": "11d4077f-014a-4b4b-8325-7b9e02bf5798"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00000 -> /content/drive/MyDrive/Lorusso/BraTS/data/raw/sampled/\n",
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00002 -> /content/drive/MyDrive/Lorusso/BraTS/data/raw/sampled/\n",
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00003 -> /content/drive/MyDrive/Lorusso/BraTS/data/raw/sampled/\n",
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00005 -> /content/drive/MyDrive/Lorusso/BraTS/data/raw/sampled/\n",
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00006 -> /content/drive/MyDrive/Lorusso/BraTS/data/raw/sampled/\n",
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00008 -> /content/drive/MyDrive/Lorusso/BraTS/data/raw/sampled/\n",
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00009 -> /content/drive/MyDrive/Lorusso/BraTS/data/raw/sampled/\n",
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00011 -> /content/drive/MyDrive/Lorusso/BraTS/data/raw/sampled/\n",
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00012 -> /content/drive/MyDrive/Lorusso/BraTS/data/raw/sampled/\n",
            "/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats/BraTS2021_00014 -> /content/drive/MyDrive/Lorusso/BraTS/data/raw/sampled/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def untar_brats(tar_path, extract_path):\n",
        "    tar = tarfile.open(tar_path)\n",
        "    tar.extractall(extract_path)\n",
        "    tar.close()\n",
        "\n",
        "\n",
        "def plot_brain_sections(images,ax = 1,slice_index = 90):\n",
        "\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "\n",
        "    d1,d2,d3 = np.shape(images[1])\n",
        "    dims = [d1,d2,d3]\n",
        "    dims.pop(ax)\n",
        "    color_segmentation = np.zeros((dims[0],dims[1],3))\n",
        "\n",
        "    gray_segmentation = np.take(images[1],slice_index,axis = ax)\n",
        "    color_segmentation[gray_segmentation == 1] = [255,0,0] # Red (necrotic tumor core)\n",
        "    color_segmentation[gray_segmentation == 2] = [0,255,0] # Green (peritumoral edematous/invaded tissue)\n",
        "    color_segmentation[gray_segmentation == 4] = [0,0,255] # Blue (enhancing tumor)\n",
        "\n",
        "    t1 = images[0][0]\n",
        "    flair = images[0][1]\n",
        "    t2 = images[0][2]\n",
        "    t1ce = images[0][3]\n",
        "\n",
        "    image = t1+t2+flair+t1ce\n",
        "\n",
        "    plt.figure(figsize=(15,15))\n",
        "    plt.subplot(1,4,1)\n",
        "    plt.imshow(np.take(image,slice_index,axis = 0),cmap='gray')\n",
        "\n",
        "    plt.subplot(1,4,2)\n",
        "    plt.imshow(np.take(image,slice_index,axis = 1),cmap='gray')\n",
        "\n",
        "    plt.subplot(1,4,3)\n",
        "    plt.imshow(np.take(image,slice_index,axis = 2),cmap='gray')\n",
        "\n",
        "    plt.subplot(1,4,4)\n",
        "    plt.imshow(color_segmentation,cmap='gray')\n",
        "    plt.xlabel('Segmentation')"
      ],
      "metadata": {
        "id": "Lrs_wCJEAJpS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Preprocessing script to convert from data provided by BraTS to data used by our model. Should be the first thing you run.\n",
        "Fulfills the following four functions:\n",
        "1. Normalize and standardize each image of each MRI modality\n",
        "2. Combine multiple MRI modalitities into one image array\n",
        "3. Swap labels from BraTS order (0,2,1,4) to more intuitive order (0,1,2,3)\n",
        "4. Convert image into a graph\n",
        "    Using Simple Linear Iterative Clustering algorithm\n",
        "    Parameters passed on command line\n",
        "\n",
        "If no labels are present (e.g. at test time, in deployment) can also build graph without labels.\n",
        "\n",
        "Saves the following in the specified output directory for each sample\n",
        "MRI_ID/\n",
        "    _input.nii.gz (processed and combined modalities for a sample as nifti file)\n",
        "    _label.nii.gz\n",
        "    _nxgraph.json (networkx graph containing both graph topography and features and labels for each node)\n",
        "    _supervoxels.nii.gz (supervoxel partitioning produced by SLIC)\n",
        "    _crop.npy (optionally the crop of the processed data relative to the original data) (crops out empty image planes)\n",
        "'''\n",
        "\n",
        "\n",
        "class DataPreprocessor(Dataset):\n",
        "    def __init__(self, dotenv_path = \"/content/drive/MyDrive/Lorusso/BraTS/.env\", transform = True, INPUT_PATH = None):\n",
        "\n",
        "        load_dotenv(dotenv_path)\n",
        "\n",
        "        # Data mean and variance\n",
        "        data_stats = ([0.4645, 0.6625, 0.4064, 0.3648], [0.1593, 0.1703, 0.1216, 0.1627])\n",
        "\n",
        "        if(INPUT_PATH is not None and os.path.exists(INPUT_PATH)):\n",
        "            self.data_dir = INPUT_PATH\n",
        "        else:\n",
        "            self.data_dir = os.getenv('INPUT_DATA_DIR')\n",
        "        self.output_dir = os.getenv('PROCESSED_DATA_DIR')\n",
        "        self.mri_prefix = 'BraTS2021'\n",
        "        self.modality_extensions = [\"_flair.nii.gz\", \"_t1.nii.gz\", \"_t1ce.nii.gz\", \"_t2.nii.gz\"]\n",
        "        self.label_extension = \"_seg.nii.gz\"\n",
        "        self.include_labels = self.label_extension is not None\n",
        "        self.all_ids, self.id_to_fp = self.get_all_mris_in_dataset()\n",
        "        self.LABEL_MAP = {4: 3, 2: 1, 1: 2}\n",
        "        self.dataset_mean = np.array(data_stats[0], dtype=np.float32)\n",
        "        self.dataset_std = np.array(data_stats[1], dtype=np.float32)\n",
        "        self.transform = transform if isinstance(transform, bool) else True\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.all_ids)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "\n",
        "        images = []\n",
        "        # Load the image corresponding to idx\n",
        "        try:\n",
        "            fp = [self.id_to_fp[k] for k in self.all_ids if k.split('_')[-1] == idx][0]\n",
        "            bn = os.path.basename(os.path.split(fp)[0])\n",
        "\n",
        "            images.append([nib.load(os.path.join(fp, bn + level)).get_fdata(dtype=np.float32).T\n",
        "                           for level in self.modality_extensions])\n",
        "            labels = nib.load(os.path.join(fp, bn + self.label_extension)).get_fdata(dtype=np.float32).T\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "\n",
        "        #### KEY INSTRUCTION #####\n",
        "        images = np.asarray(images[0]) # Convert to numpy array otherwise you'll\n",
        "                                      #    experience RAM leak\n",
        "\n",
        "        imstack = np.stack(np.array(images, dtype=np.float32), axis = 0)\n",
        "        imstack, labels = self.padding(imstack, labels)\n",
        "\n",
        "        if (self.transform):\n",
        "            imstack,labels = self.get_standardized_image(imstack, labels)\n",
        "\n",
        "\n",
        "        return np.array(imstack), labels\n",
        "\n",
        "\n",
        "    def get_all_mris_in_dataset(self):\n",
        "\n",
        "        mri_folders = glob.glob(\n",
        "            f\"{self.data_dir}**/{self.mri_prefix}*/\", recursive=True)\n",
        "        mri_folders = self.remove_incomplete_mris(mri_folders)\n",
        "\n",
        "        scan_dic = {os.path.split(fp)[0].split(\"/\")[-1]: fp for fp in mri_folders}\n",
        "\n",
        "        if(len(mri_folders) == 0):\n",
        "            print(\"No MRI found at \" + self.data_dir)\n",
        "\n",
        "        return list(scan_dic.keys()), scan_dic\n",
        "\n",
        "\n",
        "    def remove_incomplete_mris(self, mri_folders):\n",
        "        # if there are any you want to ignore just add them to this list\n",
        "        removed_mris = []\n",
        "        return [fp for fp in mri_folders if fp.split(\"/\")[-2] not in removed_mris]\n",
        "\n",
        "    def split_dataset(self, ratio = (.6,.2,.2),seed = 42):\n",
        "\n",
        "      random.seed(seed)\n",
        "      if(np.sum(ratio) != 1 or ratio is None):\n",
        "        print(\"Error: ratio does not sum up to one.\\nSwitching to default (.6,.2,.2))\")\n",
        "        ratio = (.6,.2,.2)\n",
        "\n",
        "      train_length = int(len(self.all_ids)*ratio[0])\n",
        "      val_length = int(len(self.all_ids)*ratio[1])\n",
        "      test_length = int(len(self.all_ids)*ratio[2])\n",
        "\n",
        "      pos = random.sample(range(0,len(self.all_ids)), len(self.all_ids))\n",
        "      split_dict = {\n",
        "          'train': [self.all_ids[i] for i in pos[:train_length]],\n",
        "          'val': [self.all_ids[i] for i in pos[train_length :train_length + val_length]],\n",
        "          'test': [self.all_ids[i] for i in pos[train_length + val_length:]]\n",
        "      }\n",
        "\n",
        "      for k in split_dict.keys():\n",
        "        parent = '/'.join(self.data_dir.split('/')[:-1])\n",
        "        dst = os.path.join(parent,k)\n",
        "        try:\n",
        "\n",
        "          if(not os.path.exists(dst)):\n",
        "            os.mkdir(dst)\n",
        "\n",
        "          for id in split_dict[k]:\n",
        "            if(not os.path.exists(os.path.join(dst,id))):\n",
        "               os.mkdir(os.path.join(dst,id))\n",
        "\n",
        "            copy_tree(self.id_to_fp[id],os.path.join(dst,id))\n",
        "\n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "\n",
        "\n",
        "    def padding(self,image, labels):\n",
        "\n",
        "        n_channels = np.shape(image)[0]\n",
        "        max_val = max(np.shape(image))\n",
        "        pad_list = np.zeros([n_channels,max_val,max_val,max_val],dtype=np.float32)\n",
        "\n",
        "        for channel in range(0, n_channels): # pad every channel\n",
        "            pad_list[channel] = np.pad(image[channel],[(0,85),(0,0),(0,0)],'constant')\n",
        "\n",
        "        labels = np.pad(labels, [(0,85),(0,0),(0,0)],'constant')\n",
        "        return pad_list, labels\n",
        "\n",
        "    def get_standardized_image(self, image_data, label_data):\n",
        "\n",
        "        standardized_labels = self.swap_labels_from_brats(label_data)\n",
        "        normalized_data = self.normalize_img(image_data)\n",
        "        standardized_data = self.standardize_img(\n",
        "            normalized_data, self.dataset_mean, self.dataset_std)\n",
        "\n",
        "        return standardized_data, standardized_labels\n",
        "\n",
        "\n",
        "\n",
        "    def normalize_img(self, img_array, is_flat=False):\n",
        "        if(is_flat):\n",
        "            maxes = np.quantile(img_array, 0.995, axis=0).astype(np.float32)\n",
        "        else:\n",
        "            maxes = np.quantile(img_array, 0.995, axis=(\n",
        "                0, 1, 2, 3)).astype(np.float32)\n",
        "        #print(\"Max value for each modality\", maxes)\n",
        "        return img_array/maxes\n",
        "\n",
        "\n",
        "    def standardize_img(self,img_array, mean, std):\n",
        "        img_array = img_array.T # Align shapes\n",
        "        centered = img_array-mean\n",
        "        standardized = centered/std\n",
        "        return standardized.T\n",
        "\n",
        "\n",
        "\n",
        "    def swap_labels_from_brats(self,label_data):\n",
        "        uniques = np.unique(label_data)\n",
        "        for u in uniques:\n",
        "            if u not in [0, 1, 2, 4]:\n",
        "                raise RuntimeError('unexpected label')\n",
        "\n",
        "        new_label_data = np.zeros_like(label_data, dtype=np.int16)\n",
        "        new_label_data[label_data == 4] = self.LABEL_MAP[4]\n",
        "        new_label_data[label_data == 2] = self.LABEL_MAP[2]\n",
        "        new_label_data[label_data == 1] = self.LABEL_MAP[1]\n",
        "        return new_label_data\n",
        "\n",
        "\n",
        "    def swap_labels_to_brats(self,label_data):\n",
        "        uniques = np.unique(label_data)\n",
        "        for u in uniques:\n",
        "            if u not in [0, 1, 2, 3]:\n",
        "                raise RuntimeError('unexpected label')\n",
        "\n",
        "        new_label_data = np.zeros_like(label_data, dtype=np.int16)\n",
        "        new_label_data[label_data == self.LABEL_MAP[4]] = 4\n",
        "        new_label_data[label_data == self.LABEL_MAP[2]] = 2\n",
        "        new_label_data[label_data == self.LABEL_MAP[1]] = 1\n",
        "        return new_label_data\n",
        "\n",
        "\n",
        "\n",
        "class SeqSampler(SequentialSampler):\n",
        "\n",
        "    r\"\"\"Samples elements sequentially, always in the same order.\n",
        "\n",
        "    Args:\n",
        "        data_source (Dataset): dataset to sample from\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_source:Dataset):\n",
        "        self.data_source = data_source\n",
        "        self.indexDict = [id.split('_')[1] for id in data_source.all_ids]\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(self.indexDict)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indexDict)\n"
      ],
      "metadata": {
        "id": "-Pa_KNzpRi0d"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dotenv_path = \"/content/drive/MyDrive/Lorusso/BraTS/.env\"\n",
        "load_dotenv(dotenv_path)\n",
        "\n",
        "\n",
        "INPUT_PATH = os.getenv(\"INPUT_DATA_DIR\")\n",
        "PROCESSED_PATH = os.getenv('PROCESSED_DATA_DIR')\n",
        "INPUT_PATH_PARENT = '/'.join(INPUT_PATH.split('/')[:-1])\n",
        "\n",
        "TRAIN_PATH = os.path.join(INPUT_PATH_PARENT,'train')\n",
        "VAL_PATH = os.path.join(INPUT_PATH_PARENT,'val')\n",
        "TEST_PATH = os.path.join(INPUT_PATH_PARENT,'test')\n",
        "\n",
        "TAR_PATH = os.path.join(INPUT_PATH_PARENT,'BraTS2021_Training_Data.tar')\n",
        "BUILD_DATASET = False\n",
        "\n",
        "if(BUILD_DATASET):\n",
        "  untar_brats(tar_path = '/content/drive/MyDrive/Lorusso/BraTS/data/raw/BraTS2021_Training_Data.tar', extract_path = INPUT_PATH )\n",
        "  dataset = DataPreprocessor()\n",
        "  dataset.split_dataset()\n"
      ],
      "metadata": {
        "id": "sYWFx00oN9Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = DataPreprocessor()\n",
        "train_loader = DataLoader(dataset, sampler = SeqSampler(dataset), batch_size = 1, num_workers = 0)\n",
        "images, labels= next(iter(train_loader))"
      ],
      "metadata": {
        "id": "PJBdF2Haw7V8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b_list = []\n",
        "for g in os.listdir('/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats'):\n",
        "  print(len(os.listdir(os.path.join('/content/drive/MyDrive/Lorusso/BraTS/data/raw/brats',g))))\n",
        "  if len(os.listdir(os.path.join('/content/drive/MyDrive/Lorusso/BraTS/data/raw/train',g))) == 4:\n",
        "    b_list.append(True)"
      ],
      "metadata": {
        "id": "O9KKos1edbUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_brain_sections([images[0], labels[0]])\n",
        "del images, labels, train_loader, dataset"
      ],
      "metadata": {
        "id": "BbEczVY6_FH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1cN46eXe0LK"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Models\n"
      ],
      "metadata": {
        "id": "cgINpL8BK3hL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IDB0bY7e0LK"
      },
      "outputs": [],
      "source": [
        "class Loss(nn.Module):\n",
        "    def __init__(self, focal):\n",
        "        super(Loss, self).__init__()\n",
        "        if focal:\n",
        "            self.loss_fn = DiceFocalLoss(\n",
        "                include_background=False, softmax=True, to_onehot_y=True, batch=True, gamma=2.0\n",
        "            )\n",
        "        else:\n",
        "            self.loss_fn = DiceCELoss(include_background=False, softmax=True, to_onehot_y=True, batch=True)\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        return self.loss_fn(y_pred, y_true)\n",
        "\n",
        "\n",
        "class LossBraTS(nn.Module):\n",
        "    def __init__(self, focal):\n",
        "        super(LossBraTS, self).__init__()\n",
        "        self.dice = DiceLoss(sigmoid=True, batch=True)\n",
        "        self.ce = FocalLoss(gamma=2.0, to_onehot_y=False) if focal else nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def _loss(self, p, y):\n",
        "        return self.dice(p, y) + self.ce(p, y.float())\n",
        "\n",
        "    def forward(self, p, y):\n",
        "        y_wt, y_tc, y_et = y > 0, ((y == 1) + (y == 3)) > 0, y == 3\n",
        "        p_wt, p_tc, p_et = p[:, 0].unsqueeze(1), p[:, 1].unsqueeze(1), p[:, 2].unsqueeze(1)\n",
        "        l_wt, l_tc, l_et = self._loss(p_wt, y_wt), self._loss(p_tc, y_tc), self._loss(p_et, y_et)\n",
        "        return l_wt + l_tc + l_et\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv3d(4, 16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "            nn.Conv3d(16, 32 , kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "            nn.Conv3d(32, 64 , kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose3d(64, 32, kernel_size=3, stride=2, padding=1,output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose3d(32, 16, kernel_size=3, stride=1, padding=1,),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose3d(16, 4, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.Sigmoid()  # Output between 0 and 1 for image data\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qdlE0Q5wWPS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv3d(4, 16, kernel_size=9, stride=1, padding=4),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv3d(16, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv3d(32, 64, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv3d(64, 128, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.deconv1 = nn.Sequential(\n",
        "            nn.ConvTranspose3d(128, 64, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.deconv2 = nn.Sequential(\n",
        "            nn.ConvTranspose3d(64, 32, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.deconv3 = nn.Sequential(\n",
        "            nn.ConvTranspose3d(32, 16, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.deconv4 = nn.Sequential(\n",
        "            nn.ConvTranspose3d(16, 4, kernel_size=9, stride=2, padding=4, output_padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.deconv1(x)\n",
        "        x = self.deconv2(x)\n",
        "        x = self.deconv3(x)\n",
        "        x = self.deconv4(x)\n",
        "        return x\n",
        "\n",
        "class Autoencoder3D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder3D, self).__init__()\n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m7JwGCl5p_4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wrapper\n"
      ],
      "metadata": {
        "id": "0u3q4OhjYyGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelWrapper():\n",
        "  \"\"\"\n",
        "  Allows train, prediction and I/O operations on generic models\n",
        "\n",
        "  The order of execution in __init__ is essential.\n",
        "  Every model is saved at every epoch, the name will be equal to:\n",
        "\n",
        "    - epochs_{num_epochs} if the model is not loaded\n",
        "    - epochs_{num_epochs + elapsed_epochs} if the model is loaded\n",
        "\n",
        "    The model is saved at every epoch.\n",
        "  \"\"\"\n",
        "  def __init__(self, model, optimizer, loss_fn,  num_epochs,  model_path = '/content/drive/MyDrive/Lorusso/models', LOAD_MODEL = False):\n",
        "\n",
        "    self.device = (\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "    self.model = model\n",
        "    self.num_epochs = num_epochs\n",
        "    self.loss_fn = loss_fn\n",
        "    self.optimizer = optimizer\n",
        "    self.model_path = model_path\n",
        "    self.elapsed_epochs = 0\n",
        "\n",
        "    try:\n",
        "      if(not os.path.exists(self.model_path + '/' + self.model.__class__.__name__)):\n",
        "        os.mkdir(self.model_path + '/' + self.model.__class__.__name__)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "\n",
        "    self.save_path = self.model_path + '/' + self.model.__class__.__name__ + '/model.pt'\n",
        "\n",
        "    if(LOAD_MODEL):\n",
        "      self.load_model()\n",
        "\n",
        "\n",
        "\n",
        "  def load_model(self):\n",
        "      try:\n",
        "        checkpoint = torch.load(self.save_path, map_location=torch.device(self.device))\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        self.elapsed_epochs = checkpoint['epoch']\n",
        "        self.elapsed_loss = checkpoint['loss']\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "\n",
        "  def train(self, data_loader):\n",
        "\n",
        "    self.model = self.model.to(device)\n",
        "    self.model = self.model.to(torch.float)\n",
        "\n",
        "    self.model.train()\n",
        "    try:\n",
        "\n",
        "      num_steps = int(len(data_loader.dataset.all_ids)/batch_size)\n",
        "      tot_epochs = self.elapsed_epochs + self.num_epochs+1\n",
        "      for epoch in range(self.elapsed_epochs+1, tot_epochs):\n",
        "        for i, batch in enumerate(data_loader):\n",
        "\n",
        "            data, _ = batch\n",
        "            self.optimizer.zero_grad()\n",
        "            data = data.to(device)\n",
        "\n",
        "            outputs = self.model(data)\n",
        "            loss = self.loss_fn(outputs, data)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            out = f\"Epoch: {epoch}/{tot_epochs-1}, Step: {i+1}/{num_steps}, Loss: {loss.item():.4f} \"\n",
        "            sys.stdout.write(\"\\r\" + out)\n",
        "            sys.stdout.flush()\n",
        "\n",
        "        print(f\"\\nEpoch: {epoch}/{tot_epochs-1}, Loss: {loss.item():.4f}\")\n",
        "        torch.save({\n",
        "                  'epoch': epoch,\n",
        "                  'model_state_dict': self.model.state_dict(),\n",
        "                  'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                  'batch_size': data_loader.batch_size,\n",
        "                  'loss': loss,\n",
        "                  }, self.save_path )\n",
        "\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def predict(self, data):\n",
        "\n",
        "    if device == 'cuda': data = data.type(torch.cuda.FloatTensor)\n",
        "\n",
        "    self.model.eval()\n",
        "    data.to(device)\n",
        "    self.model.to(device)\n",
        "\n",
        "    out = self.model(data)\n",
        "    out = out.cpu().detach().numpy()\n",
        "    return out\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "biiQzha9JP8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and predict"
      ],
      "metadata": {
        "id": "mz-6k-tLLDbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "num_epochs = 2\n",
        "lr = 0.005\n",
        "TRAIN_MODEL = False\n",
        "SAMPLED_PATH = '/content/drive/MyDrive/Lorusso/BraTS/data/raw/sampled'\n",
        "\n",
        "dataset = DataPreprocessor(INPUT_PATH = SAMPLED_PATH)\n",
        "data_loader = DataLoader(dataset = dataset,\n",
        "                         sampler = SeqSampler(dataset),\n",
        "                         batch_size = batch_size,\n",
        "                         num_workers = 0)\n",
        "\n",
        "wrapper = ModelWrapper(model = Autoencoder(),\n",
        "                       loss_fn = nn.MSELoss(),\n",
        "                       optimizer = torch.optim.Adam(Autoencoder().parameters(), lr=lr),\n",
        "                       num_epochs = num_epochs,\n",
        "                       LOAD_MODEL = True\n",
        "                       )\n",
        "print('Elapsed epochs: ' + str(wrapper.elapsed_epochs))\n",
        "if(TRAIN_MODEL):\n",
        "    wrapper.train(data_loader = data_loader)\n"
      ],
      "metadata": {
        "id": "UZ5ItOcISTzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDVtWMuIe0LQ"
      },
      "outputs": [],
      "source": [
        "data,_ = next(iter(data_loader))\n",
        "out = wrapper.predict(data = data)\n",
        "out = out[0]\n",
        "plt.imshow(np.sum(out, axis=0)[:,100,:], cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING SECTION"
      ],
      "metadata": {
        "id": "n1_TRMmsm6jY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLED_PATH = '/content/drive/MyDrive/Lorusso/BraTS/data/raw/sampled'\n",
        "\n",
        "INPUT_PATH_PARENT = '/'.join(SAMPLED_PATH.split('/')[:-1])\n",
        "\n",
        "TRAIN_PATH = os.path.join(INPUT_PATH_PARENT,'train')\n",
        "VAL_PATH = os.path.join(INPUT_PATH_PARENT,'val')\n",
        "TEST_PATH = os.path.join(INPUT_PATH_PARENT,'test')\n",
        "batch_size = 1\n",
        "\n",
        "dataset = DataPreprocessor(INPUT_PATH = SAMPLED_PATH)\n",
        "dataset.split_dataset()\n",
        "\n",
        "\n",
        "train_dataset = DataPreprocessor(INPUT_PATH = TRAIN_PATH)\n",
        "val_dataset = DataPreprocessor(INPUT_PATH = VAL_PATH)\n",
        "test_dataset = DataPreprocessor(INPUT_PATH = TEST_PATH)\n",
        "\n",
        "train_loader = DataLoader(dataset = train_dataset,\n",
        "                         sampler = SeqSampler(train_dataset),\n",
        "                         batch_size = batch_size,\n",
        "                         num_workers = 0)\n",
        "\n",
        "val_loader = DataLoader(dataset = val_dataset,\n",
        "                         sampler = SeqSampler(val_dataset),\n",
        "                         batch_size = batch_size,\n",
        "                         num_workers = 0)\n",
        "\n",
        "test_loader = DataLoader(dataset = test_dataset,\n",
        "                         sampler = SeqSampler(test_dataset),\n",
        "                         batch_size = batch_size,\n",
        "                         num_workers = 0)"
      ],
      "metadata": {
        "id": "9GqDLdPf65FR"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filters visualization"
      ],
      "metadata": {
        "id": "FcrKu0jdg3_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import utils\n",
        "def visTensor(tensor, ch=0, allkernels=False, nrow=8, padding=1):\n",
        "    n,c,w,h = tensor.shape\n",
        "    if allkernels: tensor = tensor.view(n*c, -1, w, h)\n",
        "    elif c != 3: tensor = tensor[:,ch,:,:].unsqueeze(dim=1)\n",
        "    rows = np.min((tensor.shape[0] // nrow + 1, 64))\n",
        "    grid = utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n",
        "    plt.figure( figsize=(nrow,rows) )\n",
        "    plt.imshow(grid.cpu().permute((1, 2, 0)))\n",
        "\n"
      ],
      "metadata": {
        "id": "ErKrIcaMN9n9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ker = wrapper.model.decoder.deconv4[0].weight.detach().clone()\n",
        "#print(ker.size())\n",
        "#\n",
        "#visTensor(torch.sum(ker, dim=(0)), allkernels=True)"
      ],
      "metadata": {
        "id": "ZM6hZF5MhKhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import torchvision\n",
        "#kernels =  ker[2]\n",
        "#kernels = kernels - kernels.min()\n",
        "#kernels = kernels / kernels.max()\n",
        "#filter_img = torchvision.utils.make_grid(kernels, nrow = 10)\n",
        "#\n",
        "## change ordering since matplotlib requires images to\n",
        "## be (H, W, C)\n",
        "#plt.imshow(filter_img.cpu().permute(1, 2, 0).flatten(1))"
      ],
      "metadata": {
        "id": "H0I-TfE3iHeX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "cgINpL8BK3hL",
        "FcrKu0jdg3_k"
      ],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}