{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwFJcAuef07T"
      },
      "source": [
        "## Environment setup ðŸ›\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (1.0.0)\n",
            "Requirement already satisfied: monai in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from monai) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.9 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from monai) (2.1.2)\n",
            "Requirement already satisfied: filelock in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.9->monai) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.9->monai) (4.7.1)\n",
            "Requirement already satisfied: sympy in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.9->monai) (1.12)\n",
            "Requirement already satisfied: networkx in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.9->monai) (3.1)\n",
            "Requirement already satisfied: jinja2 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.9->monai) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.9->monai) (2023.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from jinja2->torch>=1.9->monai) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sympy->torch>=1.9->monai) (1.3.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement shutil (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for shutil\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: mlflow in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (2.9.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (3.0.0)\n",
            "Requirement already satisfied: databricks-cli<1,>=0.8.7 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (0.18.0)\n",
            "Requirement already satisfied: entrypoints<1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (0.4)\n",
            "Requirement already satisfied: gitpython<4,>=2.1.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (3.1.40)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (6.0.1)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (4.25.1)\n",
            "Requirement already satisfied: pytz<2024 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (2023.3.post1)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (2.31.0)\n",
            "Requirement already satisfied: packaging<24 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (23.1)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (6.8.0)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (0.4.4)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (1.13.1)\n",
            "Requirement already satisfied: docker<7,>=4.0.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (6.1.3)\n",
            "Requirement already satisfied: Flask<4 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (3.0.0)\n",
            "Requirement already satisfied: numpy<2 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (1.25.2)\n",
            "Requirement already satisfied: scipy<2 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (1.11.2)\n",
            "Requirement already satisfied: pandas<3 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (2.1.4)\n",
            "Requirement already satisfied: querystring-parser<2 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (1.2.4)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (2.0.24)\n",
            "Requirement already satisfied: scikit-learn<2 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (1.3.2)\n",
            "Requirement already satisfied: pyarrow<15,>=4.0.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (14.0.2)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (3.5.1)\n",
            "Requirement already satisfied: matplotlib<4 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (3.7.2)\n",
            "Requirement already satisfied: gunicorn<22 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (21.2.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from mlflow) (3.1.2)\n",
            "Requirement already satisfied: Mako in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow) (4.7.1)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.8.0)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.7 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.0.4)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from docker<7,>=4.0.0->mlflow) (1.7.0)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from Flask<4->mlflow) (3.0.1)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from Flask<4->mlflow) (2.1.2)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from Flask<4->mlflow) (1.7.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from gitpython<4,>=2.1.0->mlflow) (4.0.11)\n",
            "Requirement already satisfied: zipp>=0.5 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.16.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from matplotlib<4->mlflow) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from matplotlib<4->mlflow) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from matplotlib<4->mlflow) (10.0.0)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from matplotlib<4->mlflow) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from pandas<3->mlflow) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (3.2.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow) (5.0.1)\n",
            "Requirement already satisfied: torchmetrics in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>1.20.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torchmetrics) (1.25.2)\n",
            "Requirement already satisfied: packaging>17.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torchmetrics) (23.1)\n",
            "Requirement already satisfied: torch>=1.8.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torchmetrics) (2.1.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torchmetrics) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (68.0.0)\n",
            "Requirement already satisfied: typing-extensions in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.7.1)\n",
            "Requirement already satisfied: filelock in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.8.1->torchmetrics) (3.12.2)\n",
            "Requirement already satisfied: sympy in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.8.1->torchmetrics) (2023.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: monai in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from monai) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.9 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from monai) (2.1.2)\n",
            "Requirement already satisfied: filelock in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.9->monai) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.9->monai) (4.7.1)\n",
            "Requirement already satisfied: sympy in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.9->monai) (1.12)\n",
            "Requirement already satisfied: networkx in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.9->monai) (3.1)\n",
            "Requirement already satisfied: jinja2 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.9->monai) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.9->monai) (2023.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from jinja2->torch>=1.9->monai) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sympy->torch>=1.9->monai) (1.3.0)\n",
            "Requirement already satisfied: torchvision in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (0.16.2)\n",
            "Requirement already satisfied: numpy in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: requests in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.2 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torchvision) (2.1.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torchvision) (10.0.0)\n",
            "Requirement already satisfied: filelock in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch==2.1.2->torchvision) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch==2.1.2->torchvision) (4.7.1)\n",
            "Requirement already satisfied: sympy in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch==2.1.2->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch==2.1.2->torchvision) (3.1)\n",
            "Requirement already satisfied: jinja2 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch==2.1.2->torchvision) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch==2.1.2->torchvision) (2023.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from requests->torchvision) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from requests->torchvision) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from jinja2->torch==2.1.2->torchvision) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sympy->torch==2.1.2->torchvision) (1.3.0)\n",
            "Looking in links: https://data.dgl.ai/wheels/cu121/repo.html\n",
            "Requirement already satisfied: dgl in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dgl) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dgl) (1.11.2)\n",
            "Requirement already satisfied: networkx>=2.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dgl) (3.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dgl) (4.66.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from requests>=2.19.0->dgl) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from requests>=2.19.0->dgl) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from requests>=2.19.0->dgl) (2023.7.22)\n",
            "Looking in links: https://data.dgl.ai/wheels-test/repo.html\n",
            "Requirement already satisfied: dglgo in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (0.0.2)\n",
            "Requirement already satisfied: typer>=0.4.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dglgo) (0.9.0)\n",
            "Requirement already satisfied: isort>=5.10.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dglgo) (5.13.2)\n",
            "Requirement already satisfied: autopep8>=1.6.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dglgo) (2.0.4)\n",
            "Requirement already satisfied: numpydoc>=1.1.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dglgo) (1.6.0)\n",
            "Requirement already satisfied: pydantic>=1.9.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dglgo) (2.5.3)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.20 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dglgo) (0.18.5)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dglgo) (6.0.1)\n",
            "Requirement already satisfied: ogb>=1.3.3 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dglgo) (1.3.6)\n",
            "Requirement already satisfied: rdkit-pypi in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dglgo) (2022.9.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from dglgo) (1.3.2)\n",
            "Requirement already satisfied: pycodestyle>=2.10.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from autopep8>=1.6.0->dglgo) (2.11.1)\n",
            "Requirement already satisfied: sphinx>=5 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from numpydoc>=1.1.0->dglgo) (7.2.6)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from numpydoc>=1.1.0->dglgo) (3.1.2)\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from numpydoc>=1.1.0->dglgo) (0.9.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from ogb>=1.3.3->dglgo) (2.1.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from ogb>=1.3.3->dglgo) (1.25.2)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from ogb>=1.3.3->dglgo) (4.66.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from ogb>=1.3.3->dglgo) (2.1.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from ogb>=1.3.3->dglgo) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from ogb>=1.3.3->dglgo) (2.0.4)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from ogb>=1.3.3->dglgo) (0.2.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from pydantic>=1.9.0->dglgo) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from pydantic>=1.9.0->dglgo) (2.14.6)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from pydantic>=1.9.0->dglgo) (4.7.1)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from ruamel.yaml>=0.17.20->dglgo) (0.2.8)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from scikit-learn>=0.20.0->dglgo) (1.11.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from scikit-learn>=0.20.0->dglgo) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from scikit-learn>=0.20.0->dglgo) (3.2.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from typer>=0.4.0->dglgo) (8.1.7)\n",
            "Requirement already satisfied: Pillow in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from rdkit-pypi->dglgo) (10.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.3)\n",
            "Requirement already satisfied: setuptools>=44 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (68.0.0)\n",
            "Requirement already satisfied: littleutils in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (0.2.2)\n",
            "Requirement already satisfied: requests in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2023.4)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.7)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.5)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.1.9)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.6)\n",
            "Requirement already satisfied: Pygments>=2.14 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.16.1)\n",
            "Requirement already satisfied: docutils<0.21,>=0.18.1 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (0.20.1)\n",
            "Requirement already satisfied: snowballstemmer>=2.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.9 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.14.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (0.7.13)\n",
            "Requirement already satisfied: imagesize>=1.3 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.4.1)\n",
            "Requirement already satisfied: packaging>=21.0 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (23.1)\n",
            "Requirement already satisfied: filelock in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.12.2)\n",
            "Requirement already satisfied: sympy in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (1.12)\n",
            "Requirement already satisfied: networkx in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.1)\n",
            "Requirement already satisfied: fsspec in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (2023.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages (from sympy->torch>=1.6.0->ogb>=1.3.3->dglgo) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install python-dotenv \n",
        "! pip install monai \n",
        "! pip install shutil \n",
        "! pip install mlflow \n",
        "! pip install torchmetrics\n",
        "! pip install monai \n",
        "! pip install torchvision\n",
        "#! pip install dgl\n",
        "! pip install  dgl -f https://data.dgl.ai/wheels/cu121/repo.html \n",
        "! pip install  dglgo -f https://data.dgl.ai/wheels-test/repo.html "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45BU03HjgAgT",
        "outputId": "ba11c780-b87d-4819-8828-548b16455b1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "\n",
        "sys.path.append('/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/')\n",
        "\n",
        "from src.preprocess import evaluation\n",
        "from src.preprocess.image_processing import *\n",
        "from src.preprocess.nifti_io import *\n",
        "from src.preprocess.graphgen import *\n",
        "from src.preprocess.graph_io import *\n",
        "\n",
        "from mlflow.models.signature import infer_signature\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dotenv import load_dotenv\n",
        "import concurrent.futures\n",
        "import tarfile\n",
        "import nibabel as nib\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "from distutils.dir_util import copy_tree\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import SequentialSampler\n",
        "#from torchvision import utils\n",
        "\n",
        "from monai.networks.nets import AutoEncoder\n",
        "from monai.losses import DiceCELoss, DiceFocalLoss, DiceLoss, FocalLoss\n",
        "\n",
        "from dgl import from_networkx as to_dgl_graph\n",
        "from dgl import batch as dgl_batch\n",
        "\n",
        "#torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE7OwGBES7sa"
      },
      "source": [
        "## MLFlow server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4-kysoZS-i4",
        "outputId": "57489038-2408-4bf9-9032-13010e78121c"
      },
      "outputs": [],
      "source": [
        "mlflow.set_tracking_uri('file:///Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/mlruns')\n",
        "# run tracking UI in the background\n",
        "get_ipython().system_raw(\"mlflow ui --backend-store-uri file:///Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/mlruns --port 5000 & \")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7ygOSsiEAWs"
      },
      "source": [
        "## Utils ðŸ› "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Lrs_wCJEAJpS"
      },
      "outputs": [],
      "source": [
        "class Logger:\n",
        "    def __init__(self,filename):\n",
        "        self.filename = filename\n",
        "        try:  #try to open file in 'r' (read) mode, if file does not exists the statement will throw an IOexception\n",
        "            log_file = open(self.filename, \"r\")\n",
        "            log_file.close()\n",
        "        except Exception as e: #catch the Exception raised from the block above and create the missing file in the specified path\n",
        "            log_file = open(self.filename, \"w\")\n",
        "            log_file.close()\n",
        "\n",
        "    def log_msg(self,*args):\n",
        "        try:\n",
        "            with open(self.filename, \"a+\") as log_file:\n",
        "                for el in args:\n",
        "                    if(type(el) is list or type(el) is tuple):\n",
        "                        for subel in el:\n",
        "                            log_file.write(subel)\n",
        "                            log_file.write('\\n')\n",
        "                    else:\n",
        "                        log_file.write(el)\n",
        "                        log_file.write('\\n')\n",
        "        except Exception as e:\n",
        "            print('Exception in Logger.log_msg')\n",
        "            print(e)\n",
        "\n",
        "    def read_msg(self):\n",
        "        content = []\n",
        "        try:\n",
        "            with open(self.filename) as file:\n",
        "                for el in file:\n",
        "                    content.append(el)\n",
        "        except Exception as e:\n",
        "            print('Exception in Logger.read_msg')\n",
        "            print(e)\n",
        "        finally:\n",
        "            return content\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def untar_brats(tar_path, extract_path):\n",
        "    tar = tarfile.open(tar_path)\n",
        "    tar.extractall(extract_path)\n",
        "    tar.close()\n",
        "\n",
        "def plot_reconstruction(im_orig, im_rec, ax:int = 0, slice_index:int = 100):\n",
        "\n",
        "    f, ax_array = plt.subplots(1,2, figsize=(10,10))\n",
        "    ax_array[0].imshow(np.take(im_orig, indices = slice_index, axis = ax), cmap='gray')\n",
        "    ax_array[1].imshow(np.take( im_rec , indices=slice_index, axis = ax), cmap='gray')\n",
        "\n",
        "def plot_brain_sections(images,ax = 1,slice_index = 90):\n",
        "\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "\n",
        "    d1,d2,d3 = np.shape(images[1])\n",
        "    dims = [d1,d2,d3]\n",
        "    dims.pop(ax)\n",
        "    color_segmentation = np.zeros((dims[0],dims[1],3))\n",
        "\n",
        "    gray_segmentation = np.take(images[1],slice_index,axis = ax)\n",
        "    color_segmentation[gray_segmentation == 1] = [255,0,0] # Red (necrotic tumor core)\n",
        "    color_segmentation[gray_segmentation == 2] = [0,255,0] # Green (peritumoral edematous/invaded tissue)\n",
        "    color_segmentation[gray_segmentation == 4] = [0,0,255] # Blue (enhancing tumor)\n",
        "\n",
        "    t1 = images[0][0]\n",
        "    flair = images[0][1]\n",
        "    t2 = images[0][2]\n",
        "    t1ce = images[0][3]\n",
        "\n",
        "    image = t1+t2+flair+t1ce\n",
        "\n",
        "    plt.figure(figsize=(15,15))\n",
        "    plt.subplot(1,4,1)\n",
        "    plt.imshow(np.take(image,slice_index,axis = 0),cmap='gray')\n",
        "\n",
        "    plt.subplot(1,4,2)\n",
        "    plt.imshow(np.take(image,slice_index,axis = 1),cmap='gray')\n",
        "\n",
        "    plt.subplot(1,4,3)\n",
        "    plt.imshow(np.take(image,slice_index,axis = 2),cmap='gray')\n",
        "\n",
        "    plt.subplot(1,4,4)\n",
        "    plt.imshow(color_segmentation,cmap='gray')\n",
        "    plt.xlabel('Segmentation')\n",
        "\n",
        "\n",
        "def visTensor(tensor, ch=0, allkernels=False, nrow=8, padding=1):\n",
        "    n,c,w,h = tensor.shape\n",
        "    if allkernels: tensor = tensor.view(n*c, -1, w, h)\n",
        "    elif c != 3: tensor = tensor[:,ch,:,:].unsqueeze(dim=1)\n",
        "    rows = np.min((tensor.shape[0] // nrow + 1, 64))\n",
        "    grid = utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n",
        "    plt.figure( figsize=(nrow,rows) )\n",
        "    plt.imshow(grid.cpu().permute((1, 2, 0)))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKEY_j_lCzCa"
      },
      "source": [
        "## Dataset class  ðŸ’¾\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-Pa_KNzpRi0d"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Preprocessing script to convert from data provided by BraTS to data used by our model. Should be the first thing you run.\n",
        "Fulfills the following four functions:\n",
        "1. Normalize and standardize each image of each MRI modality\n",
        "2. Combine multiple MRI modalitities into one image array\n",
        "3. Swap labels from BraTS order (0,2,1,4) to more intuitive order (0,1,2,3)\n",
        "4. Convert image into a graph\n",
        "    Using Simple Linear Iterative Clustering algorithm\n",
        "    Parameters passed on command line\n",
        "\n",
        "If no labels are present (e.g. at test time, in deployment) can also build graph without labels.\n",
        "\n",
        "Saves the following in the specified output directory for each sample\n",
        "MRI_ID/\n",
        "    _input.nii.gz (processed and combined modalities for a sample as nifti file)\n",
        "    _label.nii.gz\n",
        "    _nxgraph.json (networkx graph containing both graph topography and features and labels for each node)\n",
        "    _supervoxels.nii.gz (supervoxel partitioning produced by SLIC)\n",
        "    _crop.npy (optionally the crop of the processed data relative to the original data) (crops out empty image planes)\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "class DataPreprocessor(Dataset):\n",
        "    def __init__(self, dotenv_path = \"/content/drive/MyDrive/Lorusso/BraTS/.env\", transform = True, INPUT_PATH = None,\n",
        "                 num_nodes = 5000, boxiness_coef = 0.5, num_neighbors = 10, **kwargs):\n",
        "\n",
        "        load_dotenv(dotenv_path)\n",
        "        # Data mean and variance\n",
        "        data_stats = ([0.4645, 0.6625, 0.4064, 0.3648],\n",
        "                      [0.1593, 0.1703, 0.1216, 0.1627])\n",
        "        self.N_THREADS = 6\n",
        "        self.num_nodes = num_nodes\n",
        "        self.boxiness_coef = boxiness_coef\n",
        "        self.num_neighbors = num_neighbors\n",
        "\n",
        "        if(INPUT_PATH is not None and os.path.exists(INPUT_PATH)):\n",
        "            self.data_dir = INPUT_PATH\n",
        "        else:\n",
        "            self.data_dir = os.getenv('INPUT_DATA_DIR')\n",
        "\n",
        "        self.output_dir = os.getenv('PROCESSED_DATA_DIR')\n",
        "        self.graph_dir = f\"{self.output_dir}_{self.num_nodes}_{self.boxiness_coef}_{self.num_neighbors}{os.sep}{os.path.basename(self.data_dir)}\"\n",
        "        self.logger = Logger(filename=os.path.join(os.getenv('LOG_PATH'), os.path.basename(self.data_dir)+'_logs.txt'))\n",
        "\n",
        "        self.mri_prefix = 'BraTS2021_'\n",
        "        self.modality_extensions = [\"_flair.nii.gz\", \"_t1.nii.gz\", \"_t1ce.nii.gz\", \"_t2.nii.gz\"]\n",
        "        self.label_extension = \"_seg.nii.gz\"\n",
        "        self.include_labels = self.label_extension is not None\n",
        "        self.LABEL_MAP = {4: 3, 2: 1, 1: 2}\n",
        "        self.dataset_mean = np.array(data_stats[0], dtype=np.float32)\n",
        "        self.dataset_std = np.array(data_stats[1], dtype=np.float32)\n",
        "        self.transform = transform if isinstance(transform, bool) else True\n",
        "        self.force_conversion = False\n",
        "\n",
        "        # Set or overwrite additional attributes\n",
        "        for el in kwargs.keys():\n",
        "            setattr(self,str(el),kwargs[el])\n",
        "\n",
        "        self.all_ids, self.id_to_fp = self.get_all_mris_in_dataset()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.all_ids)\n",
        "\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        images = []\n",
        "        # Load the image corresponding to idx\n",
        "        try:\n",
        "            fp = [self.id_to_fp[k] for k in self.all_ids if k == idx][0]\n",
        "            bn = os.path.basename(os.path.split(fp)[0])\n",
        "            images.append([nib.load(os.path.join(fp, bn + level)).get_fdata(dtype=np.float32).T\n",
        "                           for level in self.modality_extensions])\n",
        "            if(self.label_extension is not None):\n",
        "                labels = nib.load(os.path.join(fp, bn + self.label_extension)).get_fdata(dtype=np.float32).T\n",
        "            else:\n",
        "                labels = np.zeros([155, 240, 240])\n",
        "\n",
        "            # Convert to numpy array otherwise you'll experience RAM leak\n",
        "            images = np.asarray(images[0])\n",
        "            imstack = np.stack(np.array(images, dtype=np.float32), axis = 0)\n",
        "            imstack, labels = self.padding(imstack, labels)\n",
        "\n",
        "            if (self.transform):\n",
        "                imstack,labels = self.get_standardized_image(imstack, labels)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Exception thrown in class {self.__class__.__name__ }, method __getitem__\")\n",
        "            print(e)\n",
        "            imstack = np.zeros([4,240,240,240],dtype=np.float32)\n",
        "            labels = np.zeros([240, 240, 240])\n",
        "\n",
        "        return np.array(imstack), labels\n",
        "\n",
        "    def image_to_graph(self, mri_id):\n",
        "\n",
        "\n",
        "        save_path = f\"{self.graph_dir}{os.sep}{mri_id}\"\n",
        "        finished = self.get_status_ids()['Finished']\n",
        "\n",
        "        if(mri_id not in finished):\n",
        "            self.logger.log_msg('Converting ' + str(mri_id))\n",
        "        print('Converting ' + str(mri_id))\n",
        "\n",
        "        if not os.path.exists(save_path):\n",
        "            print('Creating saving path...')\n",
        "            os.makedirs(save_path)\n",
        "\n",
        "        if(not os.path.exists(f\"{save_path}{os.sep}{mri_id}_input.nii.gz\") or self.force_conversion == True):\n",
        "            imstack, labels = self.__getitem__(mri_id)\n",
        "        else:\n",
        "            imstack, labels = self.get_image(mri_id)\n",
        "\n",
        "        # Load supervoxels, if already exist, and save computational time avoiding the runnning of slic\n",
        "        sv_partitioning = None\n",
        "        if(os.path.exists(f\"{save_path}{os.sep}{mri_id}_supervoxels.nii.gz\")):\n",
        "            sv_partitioning = self.get_supervoxel_partitioning(mri_id)\n",
        "\n",
        "        # TRANSPOSE variable imstack because img2graph expects channel-first images\n",
        "        nx_graph,node_feats,region_img = img2graph(imstack.T,labels,sv_partitioning,self.num_nodes,self.boxiness_coef,self.num_neighbors)\n",
        "\n",
        "        save_networkx_graph(nx_graph, f\"{save_path}{os.sep}{mri_id}_nxgraph.json\")\n",
        "        save_as_nifti(imstack,f\"{save_path}{os.sep}{mri_id}_input.nii.gz\")\n",
        "        save_as_nifti(labels,f\"{save_path}{os.sep}{mri_id}_label.nii.gz\")\n",
        "        save_as_nifti(region_img,f\"{save_path}{os.sep}{mri_id}_supervoxels.nii.gz\")\n",
        "\n",
        "        return mri_id\n",
        "\n",
        "    def get_voxel_labels(self,mri_id):\n",
        "        fp=f\"{self.graph_dir}{os.sep}{mri_id}{os.sep}{mri_id}_label.nii.gz\"\n",
        "        return read_nifti(fp,np.int16)\n",
        "\n",
        "    def get_image(self,mri_id):\n",
        "        fp = f\"{self.graph_dir}{os.sep}{mri_id}{os.sep}{mri_id}_input.nii.gz\"\n",
        "        img = read_nifti(fp,np.float32)\n",
        "        return img,self.get_voxel_labels(mri_id)\n",
        "\n",
        "\n",
        "    def get_supervoxel_partitioning(self,mri_id):\n",
        "        fp=f\"{self.graph_dir}{os.sep}{mri_id}{os.sep}{mri_id}_supervoxels.nii.gz\"\n",
        "        return read_nifti(fp,np.int16)\n",
        "\n",
        "    def run(self):\n",
        "\n",
        "        self.remove_pending_graphs()\n",
        "\n",
        "        with concurrent.futures.ThreadPoolExecutor(max_workers=self.N_THREADS) as executor:\n",
        "            futures = [executor.submit(self.image_to_graph, mri_id) for mri_id in self.all_ids]\n",
        "            print(\"Set up Threads, starting execution\")\n",
        "            for future in concurrent.futures.as_completed(futures):\n",
        "                try:\n",
        "                    mri_id = future.result()\n",
        "                except Exception as exc:\n",
        "                    print(\"Exception caught in DataPreprocessor.run\")\n",
        "                    print(f\"{exc}\")\n",
        "                else:\n",
        "                    if(mri_id not in self.get_status_ids()['Finished']):\n",
        "                        # Log message\n",
        "                        self.logger.log_msg('Finished ' + str(mri_id))\n",
        "                    print(\"Finished \"+ str(mri_id))\n",
        "\n",
        "\n",
        "\n",
        "    def get_all_mris_in_dataset(self):\n",
        "        mri_folders = glob.glob(f\"{self.data_dir}**/{self.mri_prefix}*/\",\n",
        "                                recursive=True)\n",
        "        mri_folders = self.remove_incomplete_mris(mri_folders)\n",
        "        scan_dic = {os.path.split(fp)[0].split(\"/\")[-1]: fp for fp in mri_folders}\n",
        "        if(len(mri_folders) == 0):\n",
        "            print(\"No MRI found at \" + self.data_dir)\n",
        "        return list(scan_dic.keys()), scan_dic\n",
        "\n",
        "\n",
        "    def remove_incomplete_mris(self, mri_folders):\n",
        "        # if there are any you want to ignore just add them to this list\n",
        "        removed_mris = []\n",
        "        return [fp for fp in mri_folders if fp.split(\"/\")[-2] not in removed_mris]\n",
        "\n",
        "\n",
        "\n",
        "    def get_status_ids(self):\n",
        "\n",
        "        common_ids = set()\n",
        "        converting_ids = set()\n",
        "        finished_ids = set()\n",
        "\n",
        "        finished = []\n",
        "        pending = []\n",
        "\n",
        "        try:\n",
        "            regex= r'(Converting|Finished) '+ self.mri_prefix + '(\\d+)'\n",
        "\n",
        "            content = self.logger.read_msg()\n",
        "            # Define the regular expression pattern\n",
        "            pattern = re.compile(regex)\n",
        "\n",
        "            # Find all occurrences in the list\n",
        "            matches = [match.groups() for s in content if (match := pattern.match(s))]\n",
        "\n",
        "            for action, brats_id in matches:\n",
        "                if action == 'Converting':\n",
        "                    converting_ids.add(self.mri_prefix + brats_id)\n",
        "                elif action == 'Finished':\n",
        "                    finished_ids.add(self.mri_prefix + brats_id)\n",
        "\n",
        "            # Find finished and pending conversions\n",
        "            common_ids = converting_ids.intersection(finished_ids)\n",
        "            finished = [el for el in common_ids]\n",
        "            pending = [el for el in converting_ids.difference(common_ids)]\n",
        "\n",
        "        except Exception as e:\n",
        "            print('Exception in Logger.get_status_ids')\n",
        "            print(e)\n",
        "\n",
        "        return {'Finished':finished, 'Pending':pending}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def remove_pending_graphs(self):\n",
        "\n",
        "        pending = self.get_status_ids()['Pending']\n",
        "\n",
        "        for mri_id in pending:\n",
        "            remove_path = f\"{self.graph_dir}{os.sep}{mri_id}\"\n",
        "            try:\n",
        "                print('Removing pending graph: ' + remove_path)\n",
        "                shutil.rmtree(remove_path)\n",
        "            except Exception as e:\n",
        "                print('Exception in DataPreprocessor.remove_pending_graphs:')\n",
        "                print(e)\n",
        "\n",
        "\n",
        "\n",
        "    def split_dataset(self, fixed = (1001, 125, 125), ratio = None,seed = 42):\n",
        "\n",
        "        random.seed(seed)\n",
        "        pos = random.sample(range(0,len(self.all_ids)), len(self.all_ids))\n",
        "\n",
        "        if ratio:\n",
        "            if(np.sum(ratio) != 1):\n",
        "                print(\"Error: ratio does not sum up to one.\\nSwitching to default (.8,.1,.1))\")\n",
        "                ratio = (.8,.1,.1)\n",
        "            train_length = int(len(self.all_ids)*ratio[0])\n",
        "            val_length = int(len(self.all_ids)*ratio[1])\n",
        "            test_length = int(len(self.all_ids)*ratio[2])\n",
        "\n",
        "        if fixed:\n",
        "            if(np.sum(fixed) != len(self.all_ids)):\n",
        "                print(\"Error: fixed ratio does not sum up to one.\\nSwitching to default (1001,125,125))\")\n",
        "                fixed = (1001,125,125)\n",
        "\n",
        "            train_length = fixed[0]\n",
        "            val_length = fixed[1]\n",
        "            test_length = fixed[2]\n",
        "\n",
        "\n",
        "        split_dict = {\n",
        "            'train': [self.all_ids[i] for i in pos[:train_length]],\n",
        "            'val': [self.all_ids[i] for i in pos[train_length :train_length + val_length]],\n",
        "            'test': [self.all_ids[i] for i in pos[train_length + val_length:]]\n",
        "        }\n",
        "\n",
        "        for k in split_dict.keys():\n",
        "            parent = '/'.join(self.data_dir.split('/')[:-1])\n",
        "            dst = os.path.join(parent,k)\n",
        "\n",
        "            try:\n",
        "              # create train,val,test dirs\n",
        "              if(not os.path.exists(dst)):\n",
        "                os.mkdir(dst)\n",
        "\n",
        "              # copy splitted data inside folders\n",
        "              for id in split_dict[k]:\n",
        "                if(not os.path.exists(os.path.join(dst,id))):\n",
        "                   os.mkdir(os.path.join(dst,id))\n",
        "                copy_tree(self.id_to_fp[id],os.path.join(dst,id))\n",
        "\n",
        "            except Exception as e:\n",
        "              print(f\"Exception thrown in class {self.__class__.__name__ }, method split_dataset\")\n",
        "              print(e)\n",
        "\n",
        "\n",
        "    def padding(self,image, labels):\n",
        "        n_channels = np.shape(image)[0]\n",
        "        max_val = max(np.shape(image))\n",
        "        pad_list = np.zeros([n_channels,max_val,max_val,max_val],dtype=np.float32)\n",
        "\n",
        "        for channel in range(0, n_channels): # pad every channel\n",
        "            pad_list[channel] = np.pad(image[channel],[(42,43),(0,0),(0,0)],'constant')\n",
        "        labels = np.pad(labels, [(42,43),(0,0),(0,0)],'constant')\n",
        "\n",
        "        return pad_list, labels\n",
        "\n",
        "\n",
        "    def get_standardized_image(self, image_data, label_data):\n",
        "\n",
        "        standardized_labels = self.swap_labels_from_brats(label_data)\n",
        "        normalized_data = self.normalize_img_quantile(image_data)\n",
        "        standardized_data = self.standardize_img(normalized_data)\n",
        "        return standardized_data, standardized_labels\n",
        "\n",
        "\n",
        "    def normalize_img(self, img_array):\n",
        "        new_image = np.zeros(img_array.shape, dtype=np.float32)\n",
        "        n_channel = img_array.shape[0] # channel-first images\n",
        "\n",
        "        for channel in range(0, n_channel): # normalize every channel\n",
        "\n",
        "            maxval, minval= np.max(img_array[channel]), np.min(img_array[channel])\n",
        "            new_image[channel] = (img_array[channel] - minval)/(maxval-minval)\n",
        "        return new_image\n",
        "\n",
        "\n",
        "    def normalize_img_quantile(self, img_array):\n",
        "        quantile = np.quantile(img_array, 0.995, axis = (0,1,2,3) )\n",
        "        return img_array/quantile\n",
        "\n",
        "\n",
        "\n",
        "    def standardize_img(self,img_array):\n",
        "        img_array = img_array.T # Align shapes\n",
        "        centered = img_array-self.dataset_mean\n",
        "        standardized = centered/self.dataset_std\n",
        "        return standardized.T\n",
        "\n",
        "\n",
        "    def swap_labels_from_brats(self,label_data):\n",
        "        uniques = np.unique(label_data)\n",
        "        for u in uniques:\n",
        "            if u not in [0, 1, 2, 4]:\n",
        "                raise RuntimeError('unexpected label')\n",
        "        new_label_data = np.zeros_like(label_data, dtype=np.int16)\n",
        "        new_label_data[label_data == 4] = self.LABEL_MAP[4]\n",
        "        new_label_data[label_data == 2] = self.LABEL_MAP[2]\n",
        "        new_label_data[label_data == 1] = self.LABEL_MAP[1]\n",
        "        return new_label_data\n",
        "\n",
        "    def swap_labels_to_brats(self,label_data):\n",
        "        uniques = np.unique(label_data)\n",
        "        for u in uniques:\n",
        "            if u not in [0, 1, 2, 3]:\n",
        "                raise RuntimeError('unexpected label')\n",
        "        new_label_data = np.zeros_like(label_data, dtype=np.int16)\n",
        "        new_label_data[label_data == self.LABEL_MAP[4]] = 4\n",
        "        new_label_data[label_data == self.LABEL_MAP[2]] = 2\n",
        "        new_label_data[label_data == self.LABEL_MAP[1]] = 1\n",
        "        return new_label_data\n",
        "\n",
        "\n",
        "'''\n",
        "A Dataset similar to a torch dataset which iterates over all samples in a directory and returns the contents as numpy arrays.\n",
        "Expects to receive a filepath to the output of the preprocess script which should have the following:\n",
        "1.processed image (nifti)\n",
        "2.label image (nifti)\n",
        "3.networkx graph (json)\n",
        "4.supervoxel partitioning (nifti)\n",
        "5. (optionally) a .npy file containing the crop of the processed image relative to the original image\n",
        "\n",
        "\n",
        "#Input#\n",
        "dataset_root_dir: filepath to preprocessed dataset (generated by running preprocess script)\n",
        "mri_start_string: a prefix that every image folder starts with (can be empty string)\n",
        "read_image: whether to read in and return preprocessed images for each sample (only necessary for CNN model)\n",
        "read_graph: whether to return graphs for each sample (for training GNN)\n",
        "read_label: whether to read in labels. Will be returned in vector form (one label per node if )\n",
        "\n",
        "#Output#\n",
        "\n",
        "If graph:\n",
        "Returns a DGL Graph, features for each node, and (optionally) labels for each node\n",
        "If image:\n",
        "Returns a numpy image array and (optionally) a numpy label array\n",
        "\n",
        "'''\n",
        "\n",
        "class ImageGraphDataset(Dataset):\n",
        "    def __init__(self, dataset_root_dir,mri_start_string,read_image=True,read_graph=True,read_label=True):\n",
        "        self.dataset_root_dir=dataset_root_dir\n",
        "        self.all_ids = self.get_all_mris_in_dataset(dataset_root_dir,mri_start_string)\n",
        "        self.read_image=read_image\n",
        "        self.read_graph=read_graph\n",
        "        self.read_label = read_label\n",
        "        assert(self.read_graph or self.read_image)\n",
        "\n",
        "    def get_all_mris_in_dataset(self,dataset_root_dir,mri_start_string):\n",
        "        mri_folders = glob.glob(f\"{dataset_root_dir}**/{mri_start_string}*/\",recursive=True)\n",
        "        mri_ids = [fp.split(os.sep)[-2] for fp in mri_folders]\n",
        "        print(f\"Found {len(mri_folders)} MRIs\")\n",
        "        return mri_ids\n",
        "\n",
        "    def get_one(self,mri_id):\n",
        "        if(self.read_graph and not self.read_image):\n",
        "            return (mri_id, *self.get_graph(mri_id))\n",
        "        elif(self.read_image  and not self.read_graph):\n",
        "            return (mri_id, *self.get_image(mri_id))\n",
        "        elif(self.read_image and self.read_graph):\n",
        "            return (mri_id, *self.get_graph(mri_id), *self.get_image(mri_id))\n",
        "        else:\n",
        "            print(\"Invalid combination of flags\")\n",
        "\n",
        "    '''\n",
        "    Reads in the saved networkx graph, converts it to a DGLGraph, normalizes the graph (not actually sure how useful this is),\n",
        "    and returns the DGLGraph as well as a vector of node features and optionally labels.\n",
        "    '''\n",
        "    def get_graph(self,mri_id):\n",
        "        nx_graph = load_networkx_graph(f\"{self.dataset_root_dir}{os.sep}{mri_id}{os.sep}{mri_id}_nxgraph.json\")\n",
        "        features = np.array([nx_graph.nodes[n]['features'] for n in nx_graph.nodes])\n",
        "        if(self.read_label):\n",
        "            labels = np.array([nx_graph.nodes[n]['label'] for n in nx_graph.nodes])\n",
        "        G = to_dgl_graph(nx_graph)\n",
        "        n_edges = G.number_of_edges()\n",
        "        # normalization\n",
        "        degs = G.in_degrees().float()\n",
        "        norm = torch.pow(degs, -0.5)\n",
        "        norm[torch.isinf(norm)] = 0\n",
        "        G.ndata['norm'] = norm.unsqueeze(1)\n",
        "        #G.ndata['feat'] = features\n",
        "        if(self.read_label):\n",
        "            #G.ndata['label'] = labels\n",
        "            return G, features, labels\n",
        "        return G, features\n",
        "\n",
        "    def get_voxel_labels(self,mri_id):\n",
        "        fp=f\"{self.dataset_root_dir}{os.sep}{mri_id}{os.sep}{mri_id}_label.nii.gz\"\n",
        "        return read_nifti(fp,np.int16)\n",
        "\n",
        "    def get_image(self,mri_id):\n",
        "        fp = f\"{self.dataset_root_dir}{os.sep}{mri_id}{os.sep}{mri_id}_input.nii.gz\"\n",
        "        img = read_nifti(fp,np.float32)\n",
        "        if(self.read_label):\n",
        "            return img,self.get_voxel_labels(mri_id)\n",
        "        else:\n",
        "            return (img,)\n",
        "\n",
        "    def get_supervoxel_partitioning(self,mri_id):\n",
        "        fp=f\"{self.dataset_root_dir}{os.sep}{mri_id}{os.sep}{mri_id}_supervoxels.nii.gz\"\n",
        "        return read_nifti(fp,np.int16)\n",
        "\n",
        "    def get_crop(self,mri_id):\n",
        "        fp=f\"{self.dataset_root_dir}{os.sep}{mri_id}{os.sep}{mri_id}_crop.npy\"\n",
        "        return tuple(np.load(fp,allow_pickle=True))\n",
        "\n",
        "    def __iter__(self):\n",
        "        for mri_id in self.all_ids:\n",
        "            yield self.get_one(mri_id)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        mri_id = self.all_ids[index]\n",
        "        #print(index)\n",
        "        #mri_id = [el for el in self.all_ids if el == index][0]\n",
        "        return self.get_one(mri_id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.all_ids)\n",
        "\n",
        "\n",
        "\n",
        "class SeqSampler(SequentialSampler):\n",
        "    \"\"\"Samples elements sequentially, always in the same order.\n",
        "\n",
        "    Args:\n",
        "        data_source (Dataset): dataset to sample from\n",
        "    \"\"\"\n",
        "    def __init__(self, data_source:Dataset):\n",
        "        self.data_source = data_source\n",
        "        self.indexDict = [id for id in data_source.all_ids]\n",
        "    def __iter__(self):\n",
        "        return iter(self.indexDict)\n",
        "    def __len__(self):\n",
        "        return len(self.indexDict)\n",
        "\n",
        "\n",
        "def minibatch_graphs(samples):\n",
        "    mri_ids,graphs,features, labels = map(list, zip(*samples))\n",
        "    #print(\"Batch Mri Ids:\",mri_ids)\n",
        "    batched_graph = dgl_batch(graphs)\n",
        "    return mri_ids,batched_graph, torch.FloatTensor(np.concatenate(features)), torch.LongTensor(np.concatenate(labels))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgINpL8BK3hL"
      },
      "source": [
        "## Models ðŸ“ª\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "78WIjwSZRkGN"
      },
      "outputs": [],
      "source": [
        "\n",
        "from dgl.nn.pytorch import GATConv, GraphConv\n",
        "from dgl.nn.pytorch.conv import SAGEConv\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "'''\n",
        "Contains the actual neural network architectures.\n",
        "Supports GraphSAGE with either the pool,mean,gcn, or lstm aggregator as well as GAT.\n",
        "The input, output, and intermediate layer sizes can all be specified.\n",
        "Typically will call init_graph_net and pass along the desired model and hyperparameters.\n",
        "\n",
        "Also contains the CNN Refinement net which is a very simple 2 layer 3D convolutional neural network.\n",
        "As input, it expects 8 channels, which are the concatenated 4 input modalities and 4 output logits of the GNN predictions.\n",
        "'''\n",
        "\n",
        "\n",
        "class GraphSage(nn.Module):\n",
        "    def __init__(self,in_feats,layer_sizes,n_classes,aggregator_type,dropout):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        # input layer\n",
        "        self.layers.append(SAGEConv(in_feats, layer_sizes[0], aggregator_type, feat_drop=dropout, activation=F.relu))\n",
        "        # hidden layers\n",
        "        for i in range(1,len(layer_sizes)):\n",
        "            self.layers.append(SAGEConv(layer_sizes[i-1], layer_sizes[i], aggregator_type, feat_drop=dropout, activation=F.relu))\n",
        "        # output layer\n",
        "        self.layers.append(SAGEConv(layer_sizes[-1], n_classes, aggregator_type, feat_drop=0, activation=None))\n",
        "\n",
        "    def forward(self,graph,features):\n",
        "        h = features\n",
        "        for layer in self.layers:\n",
        "            h = layer(graph, h)\n",
        "        return h\n",
        "\n",
        "\n",
        "class GAT(nn.Module):\n",
        "    def __init__(self,in_feats,layer_sizes,n_classes,heads,residuals,\n",
        "                activation=F.elu,feat_drop=0,attn_drop=0,negative_slope=0.2):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.activation = activation\n",
        "        # input projection (no residual)\n",
        "        self.layers.append(GATConv(\n",
        "            in_feats, layer_sizes[0], heads[0],\n",
        "            feat_drop, attn_drop, negative_slope, False, self.activation))\n",
        "        # hidden layers\n",
        "        for i in range(1, len(layer_sizes)):\n",
        "            # due to multi-head, the in_dim = num_hidden * num_heads\n",
        "            self.layers.append(GATConv(\n",
        "                layer_sizes[i-1] * heads[i-1], layer_sizes[i], heads[i],\n",
        "                feat_drop, attn_drop, negative_slope, residuals[i], self.activation))\n",
        "        # output projection\n",
        "        self.layers.append(GATConv(\n",
        "            layer_sizes[-1] * heads[-1], n_classes, 1,\n",
        "            feat_drop, attn_drop, negative_slope, False, None))\n",
        "\n",
        "    def forward(self,g, inputs):\n",
        "        h = inputs\n",
        "        for l in range(len(self.layers)-1):\n",
        "            h = self.layers[l](g, h).flatten(1)\n",
        "        # output projection\n",
        "        logits = self.layers[-1](g, h).mean(1)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u3q4OhjYyGq"
      },
      "source": [
        "## Model Wrapper ðŸ“¨\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "biiQzha9JP8G"
      },
      "outputs": [],
      "source": [
        "class ModelWrapper():\n",
        "    \"\"\"\n",
        "    Allows train, evaluation, prediction and I/O operations on generic PyTorch models\n",
        "    The model is saved at every epoch.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model: nn.Module, optimizer: nn.Module, loss_fn: nn.Module,\n",
        "                 num_epochs: int, supervised: bool = True, dict_params:dict = {}, eval_metrics = None, isgnn:bool = False, LOAD_MODEL: bool = False,\n",
        "                 model_path: str  = '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/models',):\n",
        "\n",
        "        self.device = (\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "        self.model = model\n",
        "        self.model = self.model.to(self.device)\n",
        "        self.model = self.model.to(torch.float)\n",
        "        self.num_epochs = num_epochs\n",
        "        self.loss_fn = loss_fn\n",
        "        self.loss_fn = self.loss_fn.to(self.device)\n",
        "        self.eval_metrics = eval_metrics\n",
        "        self.optimizer = optimizer\n",
        "        self.model_path = model_path\n",
        "        self.save_path = self.model_path + '/' + self.model.__class__.__name__ + '/model.pt'\n",
        "\n",
        "        self.isgnn = isgnn\n",
        "        self.supervised = supervised\n",
        "        self.training_loss = []\n",
        "        self.validation_loss = []\n",
        "        self.dict_metrics = {}\n",
        "        self.elapsed_epochs = 0\n",
        "        self.elapsed_seconds = 0\n",
        "\n",
        "        self.dict_params = dict_params\n",
        "        self.update_params({'loss_fn':self.loss_fn.__class__.__name__})\n",
        "        self.update_params({'optimizer':self.optimizer.__class__.__name__})\n",
        "        self.update_params({'learning_rate':self.optimizer.state_dict()['param_groups'][0]['lr']})\n",
        "        self.update_params({'weight_decay':self.optimizer.state_dict()['param_groups'][0]['weight_decay']})\n",
        "\n",
        "        if(LOAD_MODEL):\n",
        "          self.load_checkpoint()\n",
        "\n",
        "        # Create directory for model loading\n",
        "        try:\n",
        "          if(not os.path.exists(self.model_path + '/' + self.model.__class__.__name__)):\n",
        "            os.mkdir(self.model_path + '/' + self.model.__class__.__name__)\n",
        "        except Exception as e:\n",
        "          print(f\"Exception thrown in class {self.model.__class__.__name__ }, method __init__\")\n",
        "          print(e)\n",
        "          print('\\n')\n",
        "\n",
        "\n",
        "    def update_params(self, new_params):\n",
        "        try:\n",
        "            self.dict_params.update(new_params)\n",
        "        except Exception as e:\n",
        "            print('Exception raised in WrapperModel.update_params')\n",
        "            print(e)\n",
        "\n",
        "    def log_checkpoint(self, info: dict):\n",
        "        mlflow.pytorch.log_state_dict(info, artifact_path='checkpoint')\n",
        "        #torch.save(info, self.save_path)\n",
        "\n",
        "    def load_checkpoint(self, run_id = None):\n",
        "        \"\"\" Loads the last checkpoint for the given model \"\"\"\n",
        "        try:\n",
        "            if(run_id is None):\n",
        "                run_id = mlflow.search_runs(experiment_names=['BraTS_'+type(self.model).__name__],\n",
        "                                        order_by=[\"start_time DESC\"]).iloc[0].run_id\n",
        "\n",
        "            checkpoint = mlflow.pytorch.load_state_dict('runs:/'+run_id+'/checkpoint',\n",
        "                                                        map_location=torch.device(self.device))\n",
        "\n",
        "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            self.elapsed_epochs = len(checkpoint['training_loss'])\n",
        "            self.training_loss = checkpoint['training_loss']\n",
        "            self.validation_loss = checkpoint['validation_loss']\n",
        "            self.dict_metrics = checkpoint['dict_metrics']\n",
        "            self.elapsed_seconds = checkpoint['elapsed_seconds']\n",
        "            #print(self.elapsed_epochs)\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Exception thrown in class {self.model.__class__.__name__ }, method load_checkpoint\")\n",
        "            print(e)\n",
        "            print('\\n')\n",
        "            if(mlflow.active_run()):\n",
        "                mlflow.end_run()\n",
        "\n",
        "\n",
        "    #Calculates a slew of different metrics that might be interesting such as the number of nodes of each label and voxel and node Dice scores\n",
        "    def calculate_all_metrics_for_brain(self,mri_id,dataset,node_preds,node_labels):\n",
        "        label_counts = np.concatenate([evaluation.count_node_labels(node_preds),evaluation.count_node_labels(node_labels)])\n",
        "        node_dices = evaluation.calculate_node_dices(node_preds,node_labels)\n",
        "        #read in voxel_labels and supervoxel mapping to compute the image metrics\n",
        "        sv_partitioning = dataset.get_supervoxel_partitioning(mri_id)\n",
        "        true_voxels = dataset.get_voxel_labels(mri_id)\n",
        "        pred_voxels = project_nodes_to_img(sv_partitioning,node_preds)\n",
        "        voxel_metrics = evaluation.calculate_brats_metrics(pred_voxels,true_voxels)\n",
        "        return label_counts,np.concatenate([node_dices,voxel_metrics])\n",
        "\n",
        "\n",
        "    def train(self, train_loader, val_loader = None,  experiment_prefix = ''):\n",
        "\n",
        "        try:\n",
        "            # Set MLFlow experiment\n",
        "            if(experiment_prefix):\n",
        "                mlflow.set_experiment(experiment_prefix + self.model.__class__.__name__)\n",
        "            else:\n",
        "                mlflow.set_experiment('BraTS_'+self.model.__class__.__name__)\n",
        "\n",
        "            # Start a new run if the model wasn't loaded\n",
        "            if(not mlflow.active_run()):\n",
        "                # Track metrics in the current run\n",
        "                mlflow.start_run()\n",
        "            elif(LOAD_MODEL == False and mlflow.active_run()):\n",
        "                mlflow.end_run()\n",
        "                mlflow.start_run()\n",
        "\n",
        "            for i in range(len(self.training_loss)):\n",
        "                mlflow.log_metric('train_loss', self.training_loss[i], step=i)\n",
        "\n",
        "            for i in range(len(self.validation_loss)):\n",
        "                mlflow.log_metric('val_loss', self.validation_loss[i], step=i)\n",
        "\n",
        "            self.update_params({'batch_size':train_loader.batch_size})\n",
        "            mlflow.log_params(self.dict_params)\n",
        "\n",
        "            training_loss = self.training_loss\n",
        "            validation_loss = self.validation_loss\n",
        "\n",
        "            self.tot_epochs = self.elapsed_epochs + self.num_epochs+1\n",
        "            self.tot_time = time.time()\n",
        "\n",
        "            # Train\n",
        "            for epoch in range(self.elapsed_epochs+1, self.tot_epochs):\n",
        "                start = time.time() # track time\n",
        "\n",
        "              # Evaluate first if loaded model missed the evaluation during an epoch\n",
        "                if(len(training_loss) > len(validation_loss)):\n",
        "\n",
        "                    # COMPLETE EVALUATION OF PREVIOUS EPOCH\n",
        "                    # NB: epoch = epoch - 1\n",
        "                    if(val_loader is not None):\n",
        "\n",
        "                        val_batch_loss = self.__eval(val_loader, (epoch-1) )\n",
        "                        validation_loss.append(np.array(val_batch_loss).mean())\n",
        "                        self.dict_metrics = self.__eval_metrics(val_loader)\n",
        "\n",
        "                        # Log metrics\n",
        "                        for k in self.dict_metrics.keys():\n",
        "                            mlflow.log_metric(str(k), self.dict_metrics[k], step=epoch-1)\n",
        "\n",
        "                        mlflow.log_metric('val_loss',validation_loss[-1], step=epoch-1)\n",
        "\n",
        "                        print(f\"Epoch: {epoch-1}/{self.tot_epochs-1}, Validation Loss: {validation_loss[-1]:.4f}, Elapsed time: {time.time() - start:.0f} sec \")\n",
        "\n",
        "                      # Update training time\n",
        "                        epoch_time = int(time.time() - self.tot_time) + self.elapsed_seconds\n",
        "\n",
        "                      #Create checkpoint\n",
        "                        val_dict = {\n",
        "                                  'model_state_dict': self.model.state_dict(),\n",
        "                                  'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                                  'training_loss': training_loss,\n",
        "                                  'validation_loss': validation_loss,\n",
        "                                  'dict_metrics': self.dict_metrics,\n",
        "                                  'elapsed_seconds': epoch_time\n",
        "                                  }\n",
        "                        self.log_checkpoint(val_dict)\n",
        "                    else:\n",
        "                        # Kind of exception, needed to keep the vectors of the same size\n",
        "                        validation_loss.append(np.mean(validation_loss))\n",
        "\n",
        "                        #Log metric\n",
        "                        mlflow.log_metric('val_loss',validation_loss[-1], step=epoch-1)\n",
        "\n",
        "                #### TRAIN ######\n",
        "                train_batch_loss = self.__train(train_loader, epoch)\n",
        "                training_loss.append(np.array(train_batch_loss).mean())\n",
        "\n",
        "                # Log metrics\n",
        "                mlflow.log_metric('train_loss',training_loss[-1], step=epoch) # MLFLOW tracking\n",
        "                print(f\"\\nEpoch: {epoch}/{self.tot_epochs-1}, Loss: {training_loss[-1]:.4f}, Epoch elapsed time: {time.time() - start:.0f} sec \\n\")\n",
        "\n",
        "                #Save model every elapsed epoch\n",
        "                self.elapsed_epochs = epoch\n",
        "                epoch_time = int(time.time() - self.tot_time) + self.elapsed_seconds\n",
        "\n",
        "                train_dict = {\n",
        "                          'model_state_dict': self.model.state_dict(),\n",
        "                          'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                          'training_loss': training_loss,\n",
        "                          'validation_loss': validation_loss,\n",
        "                          'dict_metrics':self.dict_metrics,\n",
        "                          'elapsed_seconds': epoch_time\n",
        "                          }\n",
        "                self.log_checkpoint(train_dict)\n",
        "\n",
        "                #### EVALUATE ######\n",
        "                if(val_loader is not None):\n",
        "\n",
        "                    val_batch_loss = self.__eval(val_loader, epoch)\n",
        "                    validation_loss.append(np.array(val_batch_loss).mean())\n",
        "\n",
        "                    self.dict_metrics = self.__eval_metrics(val_loader)\n",
        "\n",
        "                    for k in self.dict_metrics.keys():\n",
        "                        mlflow.log_metric(str(k), self.dict_metrics[k], step=epoch)\n",
        "\n",
        "                    # Log metric\n",
        "                    mlflow.log_metric('val_loss',validation_loss[-1], step=epoch)\n",
        "                    print(f\"Epoch: {epoch}/{self.tot_epochs-1}, Validation Loss: {validation_loss[-1]:.4f}, Elapsed time: {time.time() - start:.0f} sec \")\n",
        "\n",
        "                    #Checkpoint\n",
        "                    epoch_time = int(time.time() - self.tot_time) + self.elapsed_seconds\n",
        "                    val_dict = {\n",
        "                              'model_state_dict': self.model.state_dict(),\n",
        "                              'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                              'training_loss': training_loss,\n",
        "                              'validation_loss': validation_loss,\n",
        "                              'dict_metrics':self.dict_metrics,\n",
        "                              'elapsed_seconds': epoch_time\n",
        "                              }\n",
        "                    self.log_checkpoint(val_dict)\n",
        "\n",
        "            print(f\"Total training time: {time.time()-self.tot_time:.0f} sec\")\n",
        "\n",
        "            # Log model --> end run\n",
        "            mlflow.pytorch.log_model(self.model, artifact_path='model')\n",
        "            mlflow.end_run()\n",
        "        except Exception as e:\n",
        "            print(f\"Exception thrown in class Wrapper, method train:\")\n",
        "            print(e)\n",
        "            print('\\n')\n",
        "            mlflow.end_run()\n",
        "\n",
        "\n",
        "        return training_loss, validation_loss\n",
        "\n",
        "    def __train(self, train_loader: DataLoader, epoch:int):\n",
        "\n",
        "        \"\"\" Train for an epoch \"\"\"\n",
        "\n",
        "        self.model.train()\n",
        "        train_batch_loss = []\n",
        "        train_steps = int(len(train_loader.dataset.all_ids)/train_loader.batch_size)\n",
        "        #torch.cuda.empty_cache()\n",
        "        #time.sleep(3)\n",
        "        if(self.isgnn):\n",
        "            i = 0\n",
        "            for batch_mris, batch_graphs, batch_features, batch_labels in train_loader:\n",
        "\n",
        "                batch_graphs = batch_graphs.to(self.device)\n",
        "                batch_features = batch_features.to(self.device)\n",
        "                batch_labels = batch_labels.to(self.device)\n",
        "                logits = self.model(batch_graphs,batch_features)\n",
        "                logits = logits.to(self.device)\n",
        "\n",
        "                loss = self.loss_fn(logits, batch_labels)\n",
        "                train_batch_loss.append(loss.detach().item())\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                i = i+1\n",
        "\n",
        "                out = f\"Epoch: {epoch}/{self.tot_epochs-1}, Step: {i+1}/{train_steps}, Loss: {loss.item():.4f}, Elapsed time: {time.time() - self.tot_time:.0f} sec \"\n",
        "                sys.stdout.write(\"\\r\" + out)\n",
        "                sys.stdout.flush()\n",
        "\n",
        "        else:\n",
        "\n",
        "            for i, (data,labels) in enumerate(train_loader):\n",
        "\n",
        "                #torch.cuda.empty_cache()\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                if self.device == 'cuda':\n",
        "                  data = data.type(torch.cuda.FloatTensor)\n",
        "                else:\n",
        "                  data = data.type(torch.FloatTensor)\n",
        "\n",
        "                data = data.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                outputs = self.model(data)\n",
        "\n",
        "                if(self.supervised):\n",
        "                  loss = self.loss_fn(outputs,labels)\n",
        "                else:\n",
        "                  loss = self.loss_fn(outputs, data)\n",
        "\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                train_batch_loss.append(loss.detach().item())\n",
        "\n",
        "                out = f\"Epoch: {epoch}/{self.tot_epochs-1}, Step: {i+1}/{train_steps}, Loss: {loss.item():.4f}, Elapsed time: {time.time() - self.tot_time:.0f} sec \"\n",
        "                sys.stdout.write(\"\\r\" + out)\n",
        "                sys.stdout.flush()\n",
        "            torch.cuda.empty_cache()\n",
        "            time.sleep(1.5)\n",
        "\n",
        "        return train_batch_loss\n",
        "\n",
        "\n",
        "    def __eval(self, val_loader: DataLoader, epoch:int):\n",
        "\n",
        "        \"\"\" Evaluate for an epoch \"\"\"\n",
        "\n",
        "        val_steps = int(len(val_loader.dataset.all_ids)/val_loader.batch_size)\n",
        "        self.model.eval()\n",
        "        val_batch_loss = []\n",
        "        #torch.cuda.empty_cache()\n",
        "        #time.sleep(3)\n",
        "        with torch.no_grad():\n",
        "\n",
        "            if(self.isgnn):\n",
        "\n",
        "                #metrics stores loss,label counts, node dices,voxel dices,voxel hausdorff\n",
        "                dataset = val_loader.dataset\n",
        "                metrics = np.zeros((len(dataset),10))\n",
        "                counts = np.zeros((len(dataset),8))\n",
        "                i=0\n",
        "\n",
        "                for curr_id,curr_graph,curr_feats,curr_labels in dataset:\n",
        "\n",
        "                    curr_graph = curr_graph.to(self.device)\n",
        "                    curr_feats = torch.FloatTensor(curr_feats).to(self.device)\n",
        "                    curr_labels = torch.LongTensor(curr_labels).to(self.device)\n",
        "\n",
        "                    logits = self.model(curr_graph,curr_feats)\n",
        "                    val_loss = self.loss_fn(logits, curr_labels)\n",
        "\n",
        "                    val_batch_loss.append(val_loss.detach().item())\n",
        "\n",
        "                    _, predicted_classes = torch.max(logits, dim=1)\n",
        "                    predicted_classes=predicted_classes.detach().cpu().numpy()\n",
        "\n",
        "                    #metrics stores loss,label counts, node dices,voxel dices,voxel hausdorff\n",
        "                    metrics[i][0]=val_loss.detach().item()\n",
        "\n",
        "                    ct, res = self.calculate_all_metrics_for_brain(curr_id,dataset,predicted_classes,curr_labels.detach().cpu().numpy())\n",
        "                    metrics[i][1:] = res\n",
        "                    counts[i]=ct\n",
        "                    i+=1\n",
        "\n",
        "                    out = f\"Epoch: {epoch}/{self.tot_epochs-1}, Validation Step: {i+1}/{val_steps}, Validation Loss: {val_loss.item():.4f}, Elapsed time: {time.time() - self.tot_time:.0f} sec \"\n",
        "                    sys.stdout.write(\"\\r\" + out)\n",
        "                    sys.stdout.flush()\n",
        "\n",
        "                avg_metrics = np.mean(metrics,axis=0)\n",
        "                total_counts = np.sum(counts,axis=0)\n",
        "\n",
        "                mlflow.log_metric('node_wt_dice', avg_metrics[1], step = epoch)\n",
        "                mlflow.log_metric('node_ct_dice', avg_metrics[2], step = epoch)\n",
        "                mlflow.log_metric('node_at_dice', avg_metrics[3], step = epoch)\n",
        "                mlflow.log_metric('voxel_wt_dice', avg_metrics[4], step = epoch)\n",
        "                mlflow.log_metric('voxel_ct_dice', avg_metrics[5], step = epoch)\n",
        "                mlflow.log_metric('voxel_at_dice', avg_metrics[6], step = epoch)\n",
        "                mlflow.log_metric('voxel_wt_hd', avg_metrics[7], step = epoch)\n",
        "                mlflow.log_metric('voxel_ct_hd', avg_metrics[8], step = epoch)\n",
        "                mlflow.log_metric('voxel_at_hd', avg_metrics[9], step = epoch)\n",
        "\n",
        "\n",
        "                #return metrics, total_counts\n",
        "                return val_batch_loss\n",
        "\n",
        "            else:\n",
        "                for i, (data,labels) in enumerate(val_loader):\n",
        "\n",
        "                  #torch.cuda.empty_cache()\n",
        "                  self.optimizer.zero_grad()\n",
        "\n",
        "                  if self.device == 'cuda':\n",
        "                    data = data.type(torch.cuda.FloatTensor)\n",
        "                  else:\n",
        "                    data = data.type(torch.FloatTensor)\n",
        "\n",
        "                  data = data.to(self.device)\n",
        "                  outputs = self.model(data)\n",
        "\n",
        "                  if(self.supervised):\n",
        "                      val_loss = self.loss_fn(outputs, labels)\n",
        "                  else:\n",
        "                      val_loss = self.loss_fn(outputs, data)\n",
        "\n",
        "                  val_batch_loss.append(val_loss.detach().item())\n",
        "\n",
        "                  out = f\"Epoch: {epoch}/{self.tot_epochs-1}, Validation Step: {i+1}/{val_steps}, Validation Loss: {val_loss.item():.4f}, Elapsed time: {time.time() - self.tot_time:.0f} sec \"\n",
        "                  sys.stdout.write(\"\\r\" + out)\n",
        "                  sys.stdout.flush()\n",
        "\n",
        "                torch.cuda.empty_cache()\n",
        "                time.sleep(1.5)\n",
        "\n",
        "        return val_batch_loss\n",
        "\n",
        "\n",
        "    def __eval_metrics(self, data_loader:DataLoader):\n",
        "        \"\"\" Evaluates additional metrics aside the loss function \"\"\"\n",
        "        metrics_dict = {}\n",
        "        try:\n",
        "            self.model.eval()\n",
        "            if(self.eval_metrics is not None):\n",
        "\n",
        "                metrics_dict = {k.__class__.__name__:[] for k in self.eval_metrics}\n",
        "\n",
        "                with torch.no_grad():\n",
        "\n",
        "                    for i, (data,labels) in enumerate(data_loader):\n",
        "                        torch.cuda.empty_cache()\n",
        "                        self.optimizer.zero_grad()\n",
        "\n",
        "                        for metric in self.eval_metrics:\n",
        "\n",
        "                            if self.device == 'cuda':\n",
        "                                data = data.type(torch.cuda.FloatTensor)\n",
        "                            else:\n",
        "                                data = data.type(torch.FloatTensor)\n",
        "\n",
        "                            data = data.to(self.device)\n",
        "                            outputs = self.model(data)\n",
        "\n",
        "                            if(self.supervised):\n",
        "                                metric_value = metric(outputs, labels)\n",
        "                            else:\n",
        "                                metric_value = metric(outputs, data)\n",
        "\n",
        "                            metrics_dict[metric.__class__.__name__].append(metric_value.detach().item())\n",
        "\n",
        "                    for k in metrics_dict.keys():\n",
        "                        metrics_dict[k] = np.array(metrics_dict[k]).mean()\n",
        "\n",
        "        except Exception as e:\n",
        "            print('Exception thrown in wrapper.__eval_metrics')\n",
        "            print(e)\n",
        "        finally:\n",
        "            return metrics_dict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def predict_graph(self, val_loader:DataLoader):\n",
        "\n",
        "        \"\"\" Evaluate for an epoch \"\"\"\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "\n",
        "            #metrics stores loss,label counts, node dices,voxel dices,voxel hausdorff\n",
        "            dataset = val_loader.dataset\n",
        "            metrics = np.zeros((len(dataset),10))\n",
        "            counts = np.zeros((len(dataset),8))\n",
        "            i=0\n",
        "            for curr_id,curr_graph,curr_feats,curr_labels in dataset:\n",
        "                print(i)\n",
        "                curr_graph = curr_graph.to(self.device)\n",
        "                curr_feats = torch.FloatTensor(curr_feats).to(self.device)\n",
        "                curr_labels = torch.LongTensor(curr_labels).to(self.device)\n",
        "\n",
        "                logits = self.model(curr_graph,curr_feats)\n",
        "                val_loss = self.loss_fn(logits, curr_labels)\n",
        "\n",
        "                _, predicted_classes = torch.max(logits, dim=1)\n",
        "                predicted_classes=predicted_classes.detach().cpu().numpy()\n",
        "\n",
        "                #metrics stores loss,label counts, node dices,voxel dices,voxel hausdorff\n",
        "                metrics[i][0]=val_loss.detach().item()\n",
        "                ct, res = self.calculate_all_metrics_for_brain(curr_id,dataset,predicted_classes,curr_labels.detach().cpu().numpy())\n",
        "                metrics[i][1:] = res\n",
        "                counts[i]=ct\n",
        "                i+=1\n",
        "\n",
        "            avg_metrics = np.mean(metrics,axis=0)\n",
        "            total_counts = np.sum(counts,axis=0)\n",
        "\n",
        "\n",
        "            return avg_metrics, total_counts\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def predict_batch(self, data_loader:DataLoader):\n",
        "\n",
        "        output = []\n",
        "        self.model = self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            try:\n",
        "              for i, batch in enumerate(data_loader):\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "                if(len(batch) == 1):\n",
        "                  data = batch\n",
        "                else:\n",
        "                  data,label = batch\n",
        "\n",
        "                if self.device == 'cuda':\n",
        "                  data = data.type(torch.cuda.FloatTensor)\n",
        "                else:\n",
        "                  data = data.type(torch.FloatTensor)\n",
        "\n",
        "                data.to(self.device)\n",
        "\n",
        "                out = self.model(data)\n",
        "                out = out.cpu().detach().numpy()\n",
        "                output.append(out)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Exception thrown in class {self.model.__class__.__name__ }, method predict_batch:\")\n",
        "                print(e)\n",
        "                print('\\n')\n",
        "\n",
        "        return np.array(output)\n",
        "\n",
        "\n",
        "    def predict(self, data):\n",
        "\n",
        "        if device == 'cuda':\n",
        "          data = data.type(torch.cuda.FloatTensor)\n",
        "        else:\n",
        "          data = data.type(torch.FloatTensor)\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            data.to(device)\n",
        "            output = self.model(data)\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he-C8aZXQkry"
      },
      "source": [
        "## Loss ðŸ•³"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pUxP6_HiQiP8"
      },
      "outputs": [],
      "source": [
        "class Loss(nn.Module):\n",
        "    def __init__(self, focal):\n",
        "        super(Loss, self).__init__()\n",
        "        if focal:\n",
        "            self.loss_fn = DiceFocalLoss(\n",
        "                include_background=False, softmax=True, to_onehot_y=True, batch=True, gamma=2.0\n",
        "            )\n",
        "        else:\n",
        "            self.loss_fn = DiceCELoss(include_background=False, softmax=True, to_onehot_y=True, batch=True)\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        return self.loss_fn(y_pred, y_true)\n",
        "\n",
        "\n",
        "class LossBraTS(nn.Module):\n",
        "    def __init__(self, focal):\n",
        "        super(LossBraTS, self).__init__()\n",
        "        self.dice = DiceLoss(sigmoid=True, batch=True)\n",
        "        self.ce = FocalLoss(gamma=2.0, to_onehot_y=False) if focal else nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def _loss(self, p, y):\n",
        "        print('p '+str(p.size()))\n",
        "        print('y '+str(y.size()))\n",
        "        return self.dice(p, y) + self.ce(p, y.float())\n",
        "\n",
        "    def forward(self, p, y):\n",
        "        y_wt, y_tc, y_et = y > 0, ((y == 1) + (y == 3)) > 0, y == 3\n",
        "        p_wt, p_tc, p_et = p[:, 0].unsqueeze(1), p[:, 1].unsqueeze(1), p[:, 2].unsqueeze(1)\n",
        "        l_wt, l_tc, l_et = self._loss(p_wt, y_wt), self._loss(p_tc, y_tc), self._loss(p_et, y_et)\n",
        "        return l_wt + l_tc + l_et"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsRN0nOwDif5"
      },
      "source": [
        "## Build dataset ðŸ—"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9m9XrfCJDqWy"
      },
      "outputs": [],
      "source": [
        "dotenv_path = '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/.env'\n",
        "load_dotenv(dotenv_path)\n",
        "\n",
        "\n",
        "INPUT_PATH = os.getenv(\"INPUT_DATA_DIR\")\n",
        "PROCESSED_PATH = os.getenv('PROCESSED_DATA_DIR')\n",
        "INPUT_PATH_PARENT = '/'.join(INPUT_PATH.split('/')[:-1])\n",
        "\n",
        "TRAIN_PATH = os.path.join(INPUT_PATH_PARENT,'train')\n",
        "VAL_PATH = os.path.join(INPUT_PATH_PARENT,'val')\n",
        "TEST_PATH = os.path.join(INPUT_PATH_PARENT,'test')\n",
        "\n",
        "TAR_PATH = os.path.join(INPUT_PATH_PARENT,'BraTS2021_Training_Data.tar')\n",
        "BUILD_DATASET = False\n",
        "\n",
        "if(BUILD_DATASET):\n",
        "  untar_brats(tar_path = '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/BraTS2021_Training_Data.tar', extract_path = INPUT_PATH )\n",
        "  dataset = DataPreprocessor()\n",
        "  dataset.split_dataset()\n",
        "\n",
        "#dataset = DataPreprocessor()\n",
        "#train_loader = DataLoader(dataset, sampler = SeqSampler(dataset), batch_size = 1, num_workers = 0)\n",
        "#images, labels= next(iter(train_loader))\n",
        "#plot_brain_sections([images[0], labels[0]])\n",
        "#del images, labels, train_loader, dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz-6k-tLLDbh"
      },
      "source": [
        "# Train and predict âŒ›"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwDBKoXvkno1"
      },
      "source": [
        "## Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2p95MseIK7tF"
      },
      "outputs": [],
      "source": [
        "TRAIN_MODEL = False\n",
        "LOAD_MODEL = False\n",
        "\n",
        "\n",
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "    torch.cuda.empty_cache()\n",
        "    time.sleep(5)\n",
        "    num_workers = 2\n",
        "    batch_size = 3\n",
        "    num_epochs = 10\n",
        "    lr = 0.005\n",
        "    supervised = False\n",
        "\n",
        "  # MONAI AUTOENCODER\n",
        "    model = AutoEncoder(\n",
        "         spatial_dims=3,\n",
        "         kernel_size = 3,\n",
        "         up_kernel_size = 3,\n",
        "         in_channels=4,\n",
        "         out_channels=4,\n",
        "         channels=(5,),\n",
        "         strides=(2,),\n",
        "         inter_channels=(8, 8, 16),\n",
        "         inter_dilations=(1, 2, 4),\n",
        "         num_inter_units=2\n",
        "     )\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=1e-10)\n",
        "    loss_fn = nn.MSELoss() #SSIMLoss(spatial_dims=3)\n",
        "\n",
        "    wrapper = ModelWrapper(model = model,\n",
        "                            loss_fn = loss_fn,\n",
        "                            optimizer = optimizer,\n",
        "                            supervised = supervised,\n",
        "                            num_epochs = num_epochs,\n",
        "                            LOAD_MODEL = LOAD_MODEL\n",
        "                        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    train_dataset = ImageGraphDataset('/content/drive/MyDrive/Lorusso/BraTS/data/processed_5000_0.5_10/train',\n",
        "                                  'BraTS2021',read_image=True,read_graph=False,read_label=True)\n",
        "    val_dataset = ImageGraphDataset('/content/drive/MyDrive/Lorusso/BraTS/data/processed_5000_0.5_10/val',\n",
        "                                  'BraTS2021',read_image=True,read_graph=False,read_label=True)\n",
        "\n",
        "    train_loader = DataLoader(dataset = train_dataset,\n",
        "                             batch_size = batch_size,\n",
        "                             num_workers = num_workers,\n",
        "                              )\n",
        "    val_loader = DataLoader(dataset = val_dataset,\n",
        "                           batch_size = batch_size,\n",
        "                           num_workers = num_workers)\n",
        "\n",
        "    print('Elapsed epochs: ' + str(wrapper.elapsed_epochs))\n",
        "\n",
        "if(TRAIN_MODEL):\n",
        "    training_loss, validation_loss = wrapper.train(train_loader = train_loader, val_loader = val_loader )\n",
        "    #torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bo0aQf08rHvn"
      },
      "outputs": [],
      "source": [
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "  xx = range(1,wrapper.elapsed_epochs+1)\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.plot(xx, wrapper.training_loss, '-o', label = 'Train')\n",
        "  plt.plot(xx, wrapper.validation_loss,'-o', label = 'Val')\n",
        "  plt.legend(loc='lower left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvvSdXEvIw5w"
      },
      "outputs": [],
      "source": [
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "\n",
        "  slice_index = 100\n",
        "  ax = 0\n",
        "\n",
        "  im_test, lab = next(iter(val_loader))\n",
        "  output = wrapper.predict(data = im_test)\n",
        "  out = output[0]\n",
        "  out_numpy = out.cpu().detach().numpy()\n",
        "  im_test_numpy = im_test.cpu().detach().numpy()\n",
        "  print(np.shape(im_test_numpy))\n",
        "\n",
        "  plot_reconstruction(im_orig = np.sum(im_test_numpy[0], axis=0), im_rec = np.sum(out_numpy, axis = 0), ax = ax, slice_index = slice_index)\n",
        "  plot_brain_sections([im_test[0], lab[0]], ax = ax, slice_index = slice_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETwFBvf1Zjyp"
      },
      "outputs": [],
      "source": [
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "  ker = wrapper.model.decode[0][0][0].weight.detach().clone()\n",
        "  print(ker.size())\n",
        "  #\n",
        "  visTensor(ker[0], allkernels=True)\n",
        "\n",
        "  ker = wrapper.model.decode[0][0][0].weight.detach().clone()\n",
        "  print(ker.size())\n",
        "  #\n",
        "  visTensor(torch.sum(ker, dim=(0)), allkernels=True)\n",
        "\n",
        "  kk = torch.sum(ker, dim= 0)\n",
        "  kk = torch.sum(kk, dim = 0)\n",
        "  plt.imshow(kk[0,:,:].cpu().detach().numpy())\n",
        "\n",
        "  # Sum over the channels\n",
        "  #ker =ker.sum(axis=(0,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CScy9Z1UXCD2"
      },
      "outputs": [],
      "source": [
        "#import torch.nn.functional as F\n",
        "#im_test, lab = next(iter(test_loader))\n",
        "#ker = wrapper.model.decode[0][0][0].weight.detach().clone()\n",
        "#print(ker.size(), im_test.size())\n",
        "##ker =ker.sum(axis=0)\n",
        "##im_test = im_test.sum(axis=0)\n",
        "#result = F.conv3d(im_test,ker)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNn9uFyniXlr"
      },
      "source": [
        "#GNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "xtS7HG4ciZi5",
        "outputId": "429d800e-82f4-45ea-b27d-a3ae915b047c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1126 MRIs\n",
            "Found 125 MRIs\n",
            "Elapsed epochs: 24\n",
            "Epoch: 25/34, Step: 16/17, Loss: 0.2151, Elapsed time: 1098 sec "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-12-30T19:49:10+0000 lvl=warn msg=\"Stopping forwarder\" name=http-5000-b70841e6-d112-4c96-81cd-b3e16f4e1ee3 acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-47bd2450799d>\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_MODEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mtraining_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;31m#torch.cuda.empty_cache()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-9f5f29735b63>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader, val_loader, experiment_prefix)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0;31m#### TRAIN ######\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                 \u001b[0mtrain_batch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m                 \u001b[0mtraining_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-9f5f29735b63>\u001b[0m in \u001b[0;36m__train\u001b[0;34m(self, train_loader, epoch)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misgnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_mris\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_graphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mbatch_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_graphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-e752e9ab90c4>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m#print(index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m#mri_id = [el for el in self.all_ids if el == index][0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmri_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-e752e9ab90c4>\u001b[0m in \u001b[0;36mget_one\u001b[0;34m(self, mri_id)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmri_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_graph\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmri_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmri_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32melif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_image\u001b[0m  \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmri_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmri_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-e752e9ab90c4>\u001b[0m in \u001b[0;36mget_graph\u001b[0;34m(self, mri_id)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnx_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnx_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_dgl_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0mn_edges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;31m# normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/convert.py\u001b[0m in \u001b[0;36mfrom_networkx\u001b[0;34m(nx_graph, node_attrs, edge_attrs, edge_id_attr_name, idtype, device)\u001b[0m\n\u001b[1;32m   1355\u001b[0m         \u001b[0mnx_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_directed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1357\u001b[0;31m     (sparse_fmt, arrays), urange, vrange = utils.graphdata2tensors(\n\u001b[0m\u001b[1;32m   1358\u001b[0m         \u001b[0mnx_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_id_attr_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_id_attr_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/utils/data.py\u001b[0m in \u001b[0;36mgraphdata2tensors\u001b[0;34m(data, idtype, bipartite, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m             )\n\u001b[1;32m    217\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             src, dst = networkx2tensor(\n\u001b[0m\u001b[1;32m    219\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_id_attr_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_id_attr_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/utils/data.py\u001b[0m in \u001b[0;36mnetworkx2tensor\u001b[0;34m(nx_graph, idtype, edge_id_attr_name)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;31m# Relabel nodes using consecutive integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mnx_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_node_labels_to_integers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sorted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0mhas_edge_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_id_attr_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/networkx/utils/backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, backend, *args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0;31m# Fast path if no backends are installed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;31m# Use `backend_name` in this function instead of `backend`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/networkx/relabel.py\u001b[0m in \u001b[0;36mconvert_node_labels_to_integers\u001b[0;34m(G, first_label, ordering, label_attribute)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetworkXError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unknown node ordering: {ordering}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelabel_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m     \u001b[0;31m# create node attribute with the old label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabel_attribute\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/networkx/utils/backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, backend, *args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0;31m# Fast path if no backends are installed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;31m# Use `backend_name` in this function instead of `backend`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/networkx/relabel.py\u001b[0m in \u001b[0;36mrelabel_nodes\u001b[0;34m(G, mapping, copy)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_relabel_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_relabel_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/networkx/relabel.py\u001b[0m in \u001b[0;36m_relabel_copy\u001b[0;34m(G, mapping)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edges_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_edges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         H.add_edges_from(\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/networkx/classes/digraph.py\u001b[0m in \u001b[0;36madd_edges_from\u001b[0;34m(self, ebunch_to_add, **attr)\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mdatadict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_succ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatadict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatadict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mremove_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "INPUT_PATH = '/content/drive/MyDrive/Lorusso/BraTS/data/processed_5000_0.5_10'\n",
        "TRAIN_PATH = os.path.join(INPUT_PATH,'train')\n",
        "VAL_PATH = os.path.join(INPUT_PATH,'val')\n",
        "TEST_PATH = os.path.join(INPUT_PATH,'val') # set to 'test' in production\n",
        "\n",
        "TRAIN_MODEL = False\n",
        "LOAD_MODEL = False # resume training\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 64\n",
        "num_epochs = 10\n",
        "lr = 0.0001\n",
        "supervised = True\n",
        "eval_metrics = []\n",
        "\n",
        "dropout = 0\n",
        "input_feats = 20\n",
        "class_weights = torch.Tensor([0.1,1,3,4])\n",
        "layer_sizes=[256]*4\n",
        "n_classes=4\n",
        "aggregator_type='pool'\n",
        "\n",
        "heads = [128]*3\n",
        "residuals = [128]*3\n",
        "activation = F.relu\n",
        "\n",
        "dict_params = {k:eval(k) for k in ['input_feats', 'class_weights', 'layer_sizes', 'n_classes', 'aggregator_type', 'n_classes', 'heads', 'residuals']}\n",
        "model = GraphSage(in_feats=input_feats,\n",
        "                  layer_sizes=layer_sizes,\n",
        "                  n_classes=n_classes,\n",
        "                  aggregator_type=aggregator_type,\n",
        "                  dropout=dropout)\n",
        "\n",
        "#model = GAT(in_feats = input_feats, layer_sizes = layer_sizes, n_classes=n_classes, heads = heads, residuals = residuals, activation = activation)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(),lr=lr,weight_decay=1e-10)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "wrapper = ModelWrapper(model = model,\n",
        "                            loss_fn = loss_fn,\n",
        "                            optimizer = optimizer,\n",
        "                            supervised = supervised,\n",
        "                            dict_params = dict_params,\n",
        "                            isgnn = True,\n",
        "                            num_epochs = num_epochs,\n",
        "                            LOAD_MODEL = LOAD_MODEL,\n",
        "                            eval_metrics = eval_metrics\n",
        "                          )\n",
        "\n",
        "\n",
        "train_dataset = ImageGraphDataset(TRAIN_PATH,'BraTS2021',read_image=False,read_graph=True,read_label=True)\n",
        "val_dataset = ImageGraphDataset(VAL_PATH,'BraTS2021',read_image=False,read_graph=True,read_label=True)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dataset = train_dataset,\n",
        "                             batch_size = batch_size,\n",
        "                             num_workers = num_workers,\n",
        "                              collate_fn=minibatch_graphs)\n",
        "\n",
        "val_loader = DataLoader(dataset = val_dataset,\n",
        "                             batch_size = batch_size,\n",
        "                             num_workers = num_workers,\n",
        "                              collate_fn=minibatch_graphs)\n",
        "\n",
        "print('Elapsed epochs: ' + str(wrapper.elapsed_epochs))\n",
        "\n",
        "if(TRAIN_MODEL):\n",
        "    training_loss, validation_loss = wrapper.train(train_loader = train_loader, val_loader = val_loader )\n",
        "    #torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5BeAO17FgcH"
      },
      "outputs": [],
      "source": [
        "! rm -r /content/drive/MyDrive/Lorusso/BraTS/mlruns/134912204135972352/d458bb595b9846fc898de381b0aea782"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbEJvcMJLbRJ"
      },
      "source": [
        "# Generate Graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WS96H0W1Ljrl",
        "outputId": "7ea61404-0807-4979-c30c-bd62be76a54d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MRIs to convert:219\n",
            "Removing pending graph: /Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01673\n",
            "Exception in DataPreprocessor.remove_pending_graphs:\n",
            "[Errno 2] No such file or directory: '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01673'\n",
            "Removing pending graph: /Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-00264\n",
            "Exception in DataPreprocessor.remove_pending_graphs:\n",
            "[Errno 2] No such file or directory: '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-00264'\n",
            "Removing pending graph: /Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-00719\n",
            "Exception in DataPreprocessor.remove_pending_graphs:\n",
            "[Errno 2] No such file or directory: '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-00719'\n",
            "Removing pending graph: /Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01718\n",
            "Exception in DataPreprocessor.remove_pending_graphs:\n",
            "[Errno 2] No such file or directory: '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01718'\n",
            "Removing pending graph: /Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01767\n",
            "Exception in DataPreprocessor.remove_pending_graphs:\n",
            "[Errno 2] No such file or directory: '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01767'\n",
            "Removing pending graph: /Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01733\n",
            "Exception in DataPreprocessor.remove_pending_graphs:\n",
            "[Errno 2] No such file or directory: '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01733'\n",
            "Removing pending graph: /Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01705\n",
            "Exception in DataPreprocessor.remove_pending_graphs:\n",
            "[Errno 2] No such file or directory: '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01705'\n",
            "Removing pending graph: /Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01776\n",
            "Exception in DataPreprocessor.remove_pending_graphs:\n",
            "[Errno 2] No such file or directory: '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01776'\n",
            "Removing pending graph: /Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01710\n",
            "Exception in DataPreprocessor.remove_pending_graphs:\n",
            "[Errno 2] No such file or directory: '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01710'\n",
            "Removing pending graph: /Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01683\n",
            "Exception in DataPreprocessor.remove_pending_graphs:\n",
            "[Errno 2] No such file or directory: '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01683'\n",
            "Removing pending graph: /Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01768\n",
            "Exception in DataPreprocessor.remove_pending_graphs:\n",
            "[Errno 2] No such file or directory: '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01768'\n",
            "Removing pending graph: /Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-00535\n",
            "Exception in DataPreprocessor.remove_pending_graphs:\n",
            "[Errno 2] No such file or directory: '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-00535'\n",
            "Removing pending graph: /Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01675\n",
            "Exception in DataPreprocessor.remove_pending_graphs:\n",
            "[Errno 2] No such file or directory: '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01675'\n",
            "Removing pending graph: /Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01691\n",
            "Exception in DataPreprocessor.remove_pending_graphs:\n",
            "[Errno 2] No such file or directory: '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01691'\n",
            "Removing pending graph: /Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01790\n",
            "Exception in DataPreprocessor.remove_pending_graphs:\n",
            "[Errno 2] No such file or directory: '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01790'\n",
            "Removing pending graph: /Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01763\n",
            "Exception in DataPreprocessor.remove_pending_graphs:\n",
            "[Errno 2] No such file or directory: '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01763'\n",
            "Removing pending graph: /Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-00460\n",
            "Exception in DataPreprocessor.remove_pending_graphs:\n",
            "[Errno 2] No such file or directory: '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-00460'\n",
            "Removing pending graph: /Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-00213\n",
            "Exception in DataPreprocessor.remove_pending_graphs:\n",
            "[Errno 2] No such file or directory: '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-00213'\n",
            "Removing pending graph: /Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01760\n",
            "Exception in DataPreprocessor.remove_pending_graphs:\n",
            "[Errno 2] No such file or directory: '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01760'\n",
            "Removing pending graph: /Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-00553\n",
            "Exception in DataPreprocessor.remove_pending_graphs:\n",
            "[Errno 2] No such file or directory: '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-00553'\n",
            "Removing pending graph: /Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01678\n",
            "Exception in DataPreprocessor.remove_pending_graphs:\n",
            "[Errno 2] No such file or directory: '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01678'\n",
            "Removing pending graph: /Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01706\n",
            "Exception in DataPreprocessor.remove_pending_graphs:\n",
            "[Errno 2] No such file or directory: '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/processed_5000_0.5_10/BraTS2023-ValidationData/BraTS-GLI-01706'\n",
            "Converting BraTS-GLI-01775-000\n",
            "Creating saving path...\n",
            "Set up Threads, starting execution\n",
            "Converting BraTS-GLI-01729-000\n",
            "Creating saving path...\n",
            "Converting BraTS-GLI-01733-000\n",
            "Creating saving path...\n",
            "Converting BraTS-GLI-01689-000\n",
            "Creating saving path...\n",
            "Converting BraTS-GLI-00182-000\n",
            "Creating saving path...\n",
            "Converting BraTS-GLI-00460-000\n",
            "Creating saving path...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/Roberto/opt/anaconda3/envs/brats/lib/python3.11/site-packages/scipy/ndimage/_measurements.py:1535: RuntimeWarning: invalid value encountered in divide\n",
            "  results = [sum(input * grids[dir].astype(float), labels, index) / normalizer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished BraTS-GLI-01733-000\n",
            "Converting BraTS-GLI-00447-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00460-000\n",
            "Converting BraTS-GLI-01736-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01689-000\n",
            "Converting BraTS-GLI-01715-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00182-000\n",
            "Converting BraTS-GLI-00037-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01729-000\n",
            "Converting BraTS-GLI-00535-001\n",
            "Creating saving path...\n",
            "Converting BraTS-GLI-01683-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01775-000\n",
            "Converting BraTS-GLI-00333-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01736-000\n",
            "Finished BraTS-GLI-01715-000\n",
            "Converting BraTS-GLI-00492-000\n",
            "Creating saving path...\n",
            "Converting BraTS-GLI-00719-001\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00447-000\n",
            "Finished BraTS-GLI-00037-000\n",
            "Converting BraTS-GLI-00762-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01683-000\n",
            "Converting BraTS-GLI-01704-000\n",
            "Creating saving path...\n",
            "Converting BraTS-GLI-00450-000\n",
            "Finished BraTS-GLI-00535-001\n",
            "Creating saving path...\n",
            "Converting BraTS-GLI-01671-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00333-000\n",
            "Finished BraTS-GLI-00492-000\n",
            "Converting BraTS-GLI-01676-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00719-001\n",
            "Converting BraTS-GLI-00129-000\n",
            "Creating saving path...\n",
            "Converting BraTS-GLI-01750-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00450-000\n",
            "Finished BraTS-GLI-00762-000\n",
            "Converting BraTS-GLI-00721-001\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01704-000\n",
            "Converting BraTS-GLI-01755-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01671-000\n",
            "Converting BraTS-GLI-01776-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00129-000\n",
            "Finished BraTS-GLI-01676-000\n",
            "Converting BraTS-GLI-01731-000\n",
            "Creating saving path...\n",
            "Converting BraTS-GLI-01672-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01750-000\n",
            "Converting BraTS-GLI-01692-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00721-001\n",
            "Converting BraTS-GLI-00474-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01755-000\n",
            "Converting BraTS-GLI-01698-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01731-000\n",
            "Converting BraTS-GLI-00712-000\n",
            "Creating saving path...\n",
            "Converting BraTS-GLI-01711-000\n",
            "Finished BraTS-GLI-01776-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01672-000\n",
            "Converting BraTS-GLI-00047-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01692-000\n",
            "Converting BraTS-GLI-01735-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01698-000\n",
            "Converting BraTS-GLI-01744-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00474-000\n",
            "Converting BraTS-GLI-00200-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00712-000Converting BraTS-GLI-00135-000\n",
            "Creating saving path...\n",
            "\n",
            "Finished BraTS-GLI-01711-000\n",
            "Converting BraTS-GLI-01677-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00047-000\n",
            "Converting BraTS-GLI-01707-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00200-000\n",
            "Converting BraTS-GLI-01754-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01735-000\n",
            "Converting BraTS-GLI-00161-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01744-000\n",
            "Converting BraTS-GLI-00467-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01707-000\n",
            "Converting BraTS-GLI-00015-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00135-000\n",
            "Converting BraTS-GLI-00462-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01677-000\n",
            "Converting BraTS-GLI-01752-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01754-000\n",
            "Converting BraTS-GLI-01756-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00161-000\n",
            "Converting BraTS-GLI-00826-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00467-000\n",
            "Converting BraTS-GLI-01679-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00015-000\n",
            "Converting BraTS-GLI-00647-000\n",
            "Creating saving path...\n",
            "Converting BraTS-GLI-01758-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00462-000\n",
            "Converting BraTS-GLI-01699-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01752-000\n",
            "Finished BraTS-GLI-00826-000\n",
            "Converting BraTS-GLI-00681-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01756-000\n",
            "Converting BraTS-GLI-00082-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01679-000\n",
            "Converting BraTS-GLI-00372-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01699-000\n",
            "Converting BraTS-GLI-00428-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01758-000\n",
            "Converting BraTS-GLI-00434-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00647-000\n",
            "Converting BraTS-GLI-00458-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00681-000\n",
            "Converting BraTS-GLI-00503-001\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00372-000\n",
            "Converting BraTS-GLI-01724-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00082-000\n",
            "Converting BraTS-GLI-00422-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00428-000\n",
            "Converting BraTS-GLI-01760-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00434-000\n",
            "Converting BraTS-GLI-00337-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00458-000\n",
            "Converting BraTS-GLI-00829-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00503-001\n",
            "Converting BraTS-GLI-00560-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00422-000\n",
            "Converting BraTS-GLI-00213-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01724-000\n",
            "Converting BraTS-GLI-01709-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01760-000\n",
            "Converting BraTS-GLI-01688-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00337-000\n",
            "Converting BraTS-GLI-01680-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00829-000\n",
            "Converting BraTS-GLI-00592-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00560-000\n",
            "Converting BraTS-GLI-01687-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01709-000\n",
            "Converting BraTS-GLI-01690-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00213-000\n",
            "Converting BraTS-GLI-01762-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01688-000\n",
            "Converting BraTS-GLI-01753-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01680-000\n",
            "Converting BraTS-GLI-01751-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00592-000\n",
            "Converting BraTS-GLI-00702-001\n",
            "Creating saving path...\n",
            "Converting BraTS-GLI-01706-000Finished BraTS-GLI-01690-000\n",
            "\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01687-000\n",
            "Converting BraTS-GLI-01757-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01762-000\n",
            "Converting BraTS-GLI-00721-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01751-000\n",
            "Converting BraTS-GLI-01772-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01753-000\n",
            "Converting BraTS-GLI-01668-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00702-001\n",
            "Converting BraTS-GLI-00560-001\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01757-000Converting BraTS-GLI-00822-000\n",
            "\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00721-000\n",
            "Finished BraTS-GLI-01706-000\n",
            "Converting BraTS-GLI-00307-000\n",
            "Creating saving path...\n",
            "Converting BraTS-GLI-00647-001\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01668-000\n",
            "Converting BraTS-GLI-01774-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01772-000\n",
            "Converting BraTS-GLI-00229-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00560-001\n",
            "Converting BraTS-GLI-01728-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00307-000\n",
            "Converting BraTS-GLI-01675-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00822-000\n",
            "Converting BraTS-GLI-00535-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00647-001\n",
            "Converting BraTS-GLI-00335-000\n",
            "Creating saving path...\n",
            "Converting BraTS-GLI-01713-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00229-000\n",
            "Finished BraTS-GLI-01774-000\n",
            "Converting BraTS-GLI-00091-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01728-000\n",
            "Converting BraTS-GLI-00671-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00535-000\n",
            "Converting BraTS-GLI-00762-001\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00335-000\n",
            "Converting BraTS-GLI-01718-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01675-000\n",
            "Converting BraTS-GLI-01765-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01713-000\n",
            "Converting BraTS-GLI-01764-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00671-000\n",
            "Converting BraTS-GLI-01684-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00091-000\n",
            "Converting BraTS-GLI-01769-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01718-000\n",
            "Converting BraTS-GLI-01749-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00762-001\n",
            "Converting BraTS-GLI-00153-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01765-000\n",
            "Converting BraTS-GLI-00585-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01684-000\n",
            "Converting BraTS-GLI-01768-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01764-000\n",
            "Converting BraTS-GLI-01702-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01769-000\n",
            "Converting BraTS-GLI-00208-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00153-000\n",
            "Converting BraTS-GLI-01694-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00585-000\n",
            "Converting BraTS-GLI-01725-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01749-000\n",
            "Converting BraTS-GLI-00079-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01768-000\n",
            "Converting BraTS-GLI-01705-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01702-000\n",
            "Converting BraTS-GLI-01766-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00208-000\n",
            "Converting BraTS-GLI-01696-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01694-000\n",
            "Converting BraTS-GLI-01789-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00079-000Converting BraTS-GLI-00712-001\n",
            "Creating saving path...\n",
            "\n",
            "Finished BraTS-GLI-01725-000\n",
            "Converting BraTS-GLI-01720-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01705-000\n",
            "Converting BraTS-GLI-01723-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01766-000\n",
            "Converting BraTS-GLI-01695-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01696-000\n",
            "Converting BraTS-GLI-01686-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01789-000\n",
            "Converting BraTS-GLI-01732-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01720-000\n",
            "Converting BraTS-GLI-01741-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00712-001\n",
            "Converting BraTS-GLI-00662-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01723-000\n",
            "Converting BraTS-GLI-00719-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01695-000\n",
            "Converting BraTS-GLI-00114-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01686-000\n",
            "Converting BraTS-GLI-01712-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01732-000\n",
            "Converting BraTS-GLI-00699-001\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01741-000\n",
            "Converting BraTS-GLI-01734-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00662-000\n",
            "Converting BraTS-GLI-00489-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00719-000\n",
            "Converting BraTS-GLI-00190-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00114-000\n",
            "Converting BraTS-GLI-00256-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01712-000\n",
            "Converting BraTS-GLI-01738-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01734-000\n",
            "Converting BraTS-GLI-01667-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00699-001\n",
            "Converting BraTS-GLI-01697-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00489-000\n",
            "Converting BraTS-GLI-00001-000\n",
            "Creating saving path...\n",
            "Converting BraTS-GLI-01740-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00190-000\n",
            "Finished BraTS-GLI-00256-000\n",
            "Converting BraTS-GLI-00013-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01738-000\n",
            "Converting BraTS-GLI-00264-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01667-000\n",
            "Converting BraTS-GLI-00779-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01697-000\n",
            "Converting BraTS-GLI-01722-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00001-000\n",
            "Converting BraTS-GLI-01716-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01740-000\n",
            "Converting BraTS-GLI-00521-001\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00013-000\n",
            "Converting BraTS-GLI-01763-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00264-000\n",
            "Converting BraTS-GLI-00384-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00779-000\n",
            "Finished BraTS-GLI-01722-000\n",
            "Converting BraTS-GLI-00833-000\n",
            "Creating saving path...\n",
            "Converting BraTS-GLI-00644-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01716-000\n",
            "Converting BraTS-GLI-00463-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00521-001\n",
            "Converting BraTS-GLI-00821-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01763-000\n",
            "Converting BraTS-GLI-01726-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00384-000\n",
            "Converting BraTS-GLI-00027-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00644-000\n",
            "Converting BraTS-GLI-00573-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00833-000\n",
            "Converting BraTS-GLI-00323-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00463-000\n",
            "Converting BraTS-GLI-00699-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00821-000\n",
            "Converting BraTS-GLI-00015-001\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01726-000\n",
            "Converting BraTS-GLI-01700-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00027-000\n",
            "Converting BraTS-GLI-00769-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00573-000\n",
            "Converting BraTS-GLI-01678-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00323-000\n",
            "Converting BraTS-GLI-01747-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00699-000\n",
            "Converting BraTS-GLI-00001-001\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00015-001\n",
            "Converting BraTS-GLI-00779-001\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01700-000\n",
            "Converting BraTS-GLI-00749-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00769-000\n",
            "Converting BraTS-GLI-00163-000\n",
            "Creating saving path...\n",
            "Converting BraTS-GLI-00997-000Finished BraTS-GLI-01678-000\n",
            "\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01747-000\n",
            "Converting BraTS-GLI-00503-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00001-001\n",
            "Converting BraTS-GLI-01682-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00779-001\n",
            "Converting BraTS-GLI-01719-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00749-000\n",
            "Converting BraTS-GLI-00603-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00163-000\n",
            "Converting BraTS-GLI-01670-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00997-000\n",
            "Converting BraTS-GLI-00381-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00503-000\n",
            "Converting BraTS-GLI-01727-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01682-000\n",
            "Converting BraTS-GLI-01761-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01719-000\n",
            "Converting BraTS-GLI-01771-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00603-000\n",
            "Converting BraTS-GLI-00474-001\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01670-000\n",
            "Converting BraTS-GLI-01710-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00381-000\n",
            "Converting BraTS-GLI-01746-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01727-000\n",
            "Converting BraTS-GLI-00174-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01761-000\n",
            "Converting BraTS-GLI-01759-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01771-000\n",
            "Converting BraTS-GLI-01708-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00474-001\n",
            "Converting BraTS-GLI-01669-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01710-000\n",
            "Converting BraTS-GLI-01742-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01746-000\n",
            "Converting BraTS-GLI-01721-000\n",
            "Creating saving path...\n",
            "Converting BraTS-GLI-00252-000Finished BraTS-GLI-00174-000\n",
            "\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01759-000\n",
            "Converting BraTS-GLI-01701-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01708-000\n",
            "Converting BraTS-GLI-01773-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01669-000\n",
            "Converting BraTS-GLI-01717-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01742-000\n",
            "Converting BraTS-GLI-01737-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01721-000\n",
            "Converting BraTS-GLI-01743-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00252-000\n",
            "Converting BraTS-GLI-01745-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01701-000\n",
            "Converting BraTS-GLI-00141-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01773-000\n",
            "Converting BraTS-GLI-00013-001\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01717-000\n",
            "Converting BraTS-GLI-00145-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01737-000\n",
            "Converting BraTS-GLI-01790-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01743-000\n",
            "Converting BraTS-GLI-00462-001\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01745-000\n",
            "Converting BraTS-GLI-00119-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00141-000\n",
            "Converting BraTS-GLI-01691-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00013-001\n",
            "Converting BraTS-GLI-00467-001\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00145-000\n",
            "Converting BraTS-GLI-01703-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01790-000\n",
            "Converting BraTS-GLI-00438-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00462-001\n",
            "Converting BraTS-GLI-00287-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00119-000\n",
            "Converting BraTS-GLI-00125-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01691-000\n",
            "Converting BraTS-GLI-01693-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00467-001\n",
            "Converting BraTS-GLI-00521-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01703-000\n",
            "Converting BraTS-GLI-00080-001\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00438-000\n",
            "Converting BraTS-GLI-01685-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00287-000\n",
            "Converting BraTS-GLI-01714-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00125-000\n",
            "Converting BraTS-GLI-01673-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01693-000\n",
            "Converting BraTS-GLI-01748-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00521-000\n",
            "Converting BraTS-GLI-01006-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00080-001\n",
            "Converting BraTS-GLI-00080-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01685-000\n",
            "Converting BraTS-GLI-00181-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01714-000\n",
            "Converting BraTS-GLI-00825-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01673-000\n",
            "Converting BraTS-GLI-00595-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01748-000\n",
            "Converting BraTS-GLI-00355-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01006-000\n",
            "Converting BraTS-GLI-00553-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00080-000\n",
            "Converting BraTS-GLI-01739-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00181-000\n",
            "Converting BraTS-GLI-01770-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00825-000\n",
            "Converting BraTS-GLI-01674-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00595-000\n",
            "Converting BraTS-GLI-00553-001\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00355-000\n",
            "Converting BraTS-GLI-01681-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-00553-000\n",
            "Converting BraTS-GLI-00702-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01739-000\n",
            "Converting BraTS-GLI-01730-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01770-000\n",
            "Converting BraTS-GLI-01767-000\n",
            "Creating saving path...\n",
            "Finished BraTS-GLI-01674-000\n",
            "Finished BraTS-GLI-00553-001\n",
            "Finished BraTS-GLI-01681-000\n",
            "Finished BraTS-GLI-00702-000\n",
            "Finished BraTS-GLI-01730-000\n",
            "Finished BraTS-GLI-01767-000\n"
          ]
        }
      ],
      "source": [
        "IMG2GRAPH = True\n",
        "dataset = DataPreprocessor(INPUT_PATH = '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/raw/BraTS2023-ValidationData', label_extension = None,  mri_prefix = 'BraTS-GLI-', modality_extensions = ['-t1c.nii.gz', '-t1n.nii.gz', '-t2f.nii.gz', '-t2w.nii.gz'], force_conversion = True)\n",
        "#dataset = DataPreprocessor(INPUT_PATH = '/Users/Roberto/Desktop/UniversitÃ /Magistrale/Tesi/BraTS/data/raw/brats', force_conversion = True)\n",
        "\n",
        "if(IMG2GRAPH):\n",
        "    if(not set(dataset.get_status_ids()['Finished']).issuperset(set(dataset.all_ids))):\n",
        "        ids_to_convert = list(set(dataset.all_ids).difference(set(dataset.get_status_ids()['Finished'])))\n",
        "        print('MRIs to convert:'+ str(len(ids_to_convert)))\n",
        "        dataset.all_ids = ids_to_convert\n",
        "        dataset.run()\n",
        "        dataset.all_ids,_ = dataset.get_all_mris_in_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1_TRMmsm6jY"
      },
      "source": [
        "# TESTING SECTION ðŸš§"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJUctzmLazd9"
      },
      "source": [
        "## Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHHzhDDF_3G9"
      },
      "outputs": [],
      "source": [
        "\n",
        "TEST_MODE = False\n",
        "\n",
        "\n",
        "if(TEST_MODE):\n",
        "\n",
        "    INPUT_PATH = '/content/drive/MyDrive/Lorusso/BraTS/data/interim/sampled'\n",
        "    INPUT_PATH_PARENT = '/'.join(INPUT_PATH.split('/')[:-1])\n",
        "    TRAIN_PATH = os.path.join(INPUT_PATH_PARENT,'train')\n",
        "    VAL_PATH = os.path.join(INPUT_PATH_PARENT,'val')\n",
        "    TEST_PATH = os.path.join(INPUT_PATH_PARENT,'test')\n",
        "\n",
        "    TRAIN_MODEL = False\n",
        "    LOAD_MODEL = True # resume training\n",
        "\n",
        "    num_workers = 0\n",
        "    batch_size = 1\n",
        "    num_epochs = 2\n",
        "    lr = 0.01\n",
        "    supervised = False\n",
        "    eval_metrics = [nn.MSELoss()]\n",
        "\n",
        "  # MONAI AUTOENCODER\n",
        "    model = AutoEncoder(\n",
        "           spatial_dims=3,\n",
        "           kernel_size = 3,\n",
        "           up_kernel_size = 3,\n",
        "           in_channels=4,\n",
        "           out_channels=4,\n",
        "           channels=(5,),\n",
        "           strides=(2,),\n",
        "           inter_channels=(8, 16, 32),\n",
        "           inter_dilations=(1, 2, 4),\n",
        "           num_inter_units=2\n",
        "       )\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=1e-10)\n",
        "    loss_fn = nn.MSELoss() #SSIMLoss(spatial_dims=3)\n",
        "\n",
        "    wrapper = ModelWrapper(model = model,\n",
        "                              loss_fn = loss_fn,\n",
        "                              optimizer = optimizer,\n",
        "                              supervised = supervised,\n",
        "                              num_epochs = num_epochs,\n",
        "                              LOAD_MODEL = LOAD_MODEL,\n",
        "                              eval_metrics = eval_metrics\n",
        "                          )\n",
        "\n",
        "    dataset = DataPreprocessor(INPUT_PATH = INPUT_PATH)\n",
        "\n",
        "    # Split dataset if it's not\n",
        "    if(not os.path.exists(TRAIN_PATH)):\n",
        "      dataset.split_dataset()\n",
        "\n",
        "\n",
        "    train_dataset = DataPreprocessor(INPUT_PATH = TRAIN_PATH)\n",
        "    val_dataset = DataPreprocessor(INPUT_PATH = VAL_PATH)\n",
        "    test_dataset = DataPreprocessor(INPUT_PATH = TEST_PATH)\n",
        "\n",
        "    train_loader = DataLoader(dataset = train_dataset,\n",
        "                             sampler = SeqSampler(train_dataset),\n",
        "                             batch_size = batch_size,\n",
        "                             num_workers = num_workers)\n",
        "\n",
        "    val_loader = DataLoader(dataset = val_dataset,\n",
        "                             sampler = SeqSampler(val_dataset),\n",
        "                             batch_size = batch_size,\n",
        "                             num_workers = num_workers)\n",
        "\n",
        "    test_loader = DataLoader(dataset = test_dataset,\n",
        "                             sampler = SeqSampler(test_dataset),\n",
        "                             batch_size = batch_size,\n",
        "                             num_workers = num_workers)\n",
        "\n",
        "\n",
        "    print('Elapsed epochs: ' + str(wrapper.elapsed_epochs))\n",
        "\n",
        "    if(TRAIN_MODEL):\n",
        "        training_loss, validation_loss = wrapper.train(train_loader = train_loader, val_loader = val_loader, experiment_prefix = 'Test' )\n",
        "        torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcuxwsmW9OYS"
      },
      "outputs": [],
      "source": [
        "if(TRAIN_MODEL or LOAD_MODEL):\n",
        "  xx = range(1,wrapper.elapsed_epochs+1)\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.plot(xx, wrapper.training_loss, '-o', label = 'Train')\n",
        "  plt.plot(xx, wrapper.validation_loss,'-o', label = 'Val')\n",
        "  plt.legend(loc='lower left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3TKi4A9O4NA"
      },
      "outputs": [],
      "source": [
        "if(False):\n",
        "\n",
        "  slice_index = 90\n",
        "  ax = 0\n",
        "\n",
        "  im_test, lab = next(iter(test_loader))\n",
        "  output = wrapper.predict(data = im_test)\n",
        "  out = output[0]\n",
        "  out_numpy = out.cpu().detach().numpy()\n",
        "  im_test_numpy = im_test.cpu().detach().numpy()\n",
        "\n",
        "  plot_reconstruction(im_orig = np.sum(im_test_numpy[0], axis=0), im_rec = np.sum(out_numpy, axis = 0), ax = ax, slice_index = slice_index)\n",
        "  plot_brain_sections([im_test[0], lab[0]], ax = ax, slice_index = slice_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5fwjWaWOhXN"
      },
      "outputs": [],
      "source": [
        "if(False):\n",
        "  ker = wrapper.model.decode[0][0][0].weight.detach().clone()\n",
        "  print(ker.size())\n",
        "  #\n",
        "  visTensor(ker[1], allkernels=True)\n",
        "\n",
        "  ker = wrapper.model.decode[0][0][0].weight.detach().clone()\n",
        "  print(ker.size())\n",
        "  #\n",
        "  visTensor(torch.sum(ker, dim=(0)), allkernels=True)\n",
        "\n",
        "  kk = torch.sum(ker, dim= 0)\n",
        "  kk = torch.sum(kk, dim = 0)\n",
        "  plt.imshow(kk[0,:,:].cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-lpiQp3XNxn"
      },
      "source": [
        "## GNN training â›½"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVWsu1gEXV9j"
      },
      "outputs": [],
      "source": [
        "\n",
        "TEST_MODE = False\n",
        "\n",
        "\n",
        "if(TEST_MODE):\n",
        "\n",
        "    INPUT_PATH = '/content/drive/MyDrive/Lorusso/BraTS/data/processed_5000_0.5_10'\n",
        "    TRAIN_PATH = os.path.join(INPUT_PATH,'train')\n",
        "    VAL_PATH = os.path.join(INPUT_PATH,'val')\n",
        "    TEST_PATH = os.path.join(INPUT_PATH,'val') # set again to 'test' in production\n",
        "\n",
        "    TRAIN_MODEL = True\n",
        "    LOAD_MODEL = False # resume training\n",
        "\n",
        "    num_workers = 0\n",
        "    batch_size = 1\n",
        "    num_epochs = 2\n",
        "    lr = 0.005\n",
        "    supervised = True\n",
        "    eval_metrics = []\n",
        "\n",
        "    dropout = 0\n",
        "    input_feats = 20\n",
        "    class_weights = torch.Tensor([0.1,1,2,2])\n",
        "    layer_sizes=[256]*4\n",
        "    n_classes=4\n",
        "    aggregator_type='pool'\n",
        "\n",
        "    dict_params = {k:eval(k) for k in ['input_feats', 'class_weights', 'layer_sizes', 'n_classes', 'aggregator_type', 'n_classes']}\n",
        "\n",
        "    model = GraphSage(in_feats=input_feats,layer_sizes=layer_sizes,n_classes=n_classes,aggregator_type=aggregator_type,dropout=dropout)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(),lr=lr,weight_decay=1e-10)\n",
        "    loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "    wrapper = ModelWrapper(model = model,\n",
        "                            loss_fn = loss_fn,\n",
        "                            optimizer = optimizer,\n",
        "                            supervised = supervised,\n",
        "                            dict_params = dict_params,\n",
        "                            isgnn = True,\n",
        "                            num_epochs = num_epochs,\n",
        "                            LOAD_MODEL = LOAD_MODEL,\n",
        "                            eval_metrics = eval_metrics\n",
        "                          )\n",
        "\n",
        "\n",
        "    train_dataset = ImageGraphDataset(VAL_PATH,'BraTS2021',read_image=False,read_graph=True,read_label=True)\n",
        "    #val_dataset = ImageGraphDataset(VAL_PATH,'BraTS2021',read_image=False,read_graph=True,read_label=True)\n",
        "    #test_dataset = ImageGraphDataset(TEST_PATH,'BraTS2021',read_image=False,read_graph=True,read_label=True)\n",
        "\n",
        "    train_loader = DataLoader(dataset = train_dataset,\n",
        "                             batch_size = batch_size,\n",
        "                             num_workers = num_workers,\n",
        "                              collate_fn=minibatch_graphs)\n",
        "\n",
        "\n",
        "    print('Elapsed epochs: ' + str(wrapper.elapsed_epochs))\n",
        "\n",
        "    if(TRAIN_MODEL):\n",
        "        training_loss, validation_loss = wrapper.train(train_loader = train_loader, val_loader = train_loader, experiment_prefix = 'Test_GNN' )\n",
        "        torch.cuda.empty_cache()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "mwFJcAuef07T",
        "wE7OwGBES7sa",
        "q7ygOSsiEAWs",
        "cgINpL8BK3hL",
        "0u3q4OhjYyGq",
        "he-C8aZXQkry",
        "vsRN0nOwDif5",
        "mz-6k-tLLDbh",
        "pwDBKoXvkno1",
        "dle5EmF9LXms",
        "UNn9uFyniXlr",
        "n1_TRMmsm6jY",
        "T-lpiQp3XNxn",
        "kVH1teeglI4t"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
